{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T01:49:04.915340Z",
     "start_time": "2025-12-05T01:48:47.231068Z"
    }
   },
   "source": [
    "# level64_regime_portfolio.py\n",
    "#\n",
    "# Level-64: Unsupervised Regime Clustering + Regime-Dependent Multi-Asset Portfolio\n",
    "#\n",
    "# Idea:\n",
    "#   1) Load daily prices for a multi-asset ETF universe.\n",
    "#   2) Build rolling features:\n",
    "#        - short- and medium-horizon SPY vol\n",
    "#        - recent SPY return\n",
    "#        - SPY drawdown\n",
    "#        - cross-asset average correlation\n",
    "#   3) Cluster days into K regimes using KMeans on standardized features.\n",
    "#   4) Order regimes by volatility => 0 = calm, ..., K-1 = stressed.\n",
    "#   5) For each regime, apply different portfolio weights:\n",
    "#        - calm   → risk-on (overweight equities)\n",
    "#        - middle → balanced\n",
    "#        - stressed → risk-off (overweight bonds/gold)\n",
    "#   6) Backtest daily returns using regime_t decided from info up to t-1\n",
    "#      (no look-ahead), and evaluate performance and regime stats.\n",
    "#\n",
    "# Usage examples:\n",
    "#   python level64_regime_portfolio.py\n",
    "#   python level64_regime_portfolio.py --start 2010-01-01 --n-clusters 3\n",
    "#\n",
    "# Outputs:\n",
    "#   - level64_regime_portfolio.csv\n",
    "#   - level64_regime_portfolio_summary.json\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# ----------------------------- Config ----------------------------- #\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # Feature lookbacks\n",
    "    lookback_vol_short: int = 20\n",
    "    lookback_vol_long: int = 60\n",
    "    lookback_dd: int = 60\n",
    "    lookback_corr: int = 60\n",
    "\n",
    "    n_clusters: int = 3  # regimes\n",
    "    min_history: int = 252  # minimum days before we start using features\n",
    "\n",
    "    out_csv: str = \"level64_regime_portfolio.csv\"\n",
    "    out_json: str = \"level64_regime_portfolio_summary.json\"\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# ----------------------------- Data Loading ----------------------------- #\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily adjusted close prices for each symbol.\n",
    "    Handles both Series and DataFrame returns from yfinance.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No data returned for symbol {s}. Check ticker or internet.\")\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"'Close' column missing for {s}.\")\n",
    "\n",
    "        close_obj = px[\"Close\"]\n",
    "        if isinstance(close_obj, pd.Series):\n",
    "            close = close_obj.rename(s)\n",
    "        else:\n",
    "            # DataFrame (can happen with some APIs); take first column\n",
    "            col0 = close_obj.columns[0]\n",
    "            close = pd.Series(close_obj[col0].values, index=close_obj.index, name=s)\n",
    "\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Daily log returns.\"\"\"\n",
    "    return np.log(prices).diff().dropna()\n",
    "\n",
    "\n",
    "# ----------------------------- Feature Engineering ----------------------------- #\n",
    "\n",
    "def rolling_equity_and_dd(series: pd.Series, window: int) -> Tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    For a single asset (e.g., SPY), compute rolling equity (starting at 1)\n",
    "    and rolling drawdown relative to rolling peak over a trailing window.\n",
    "    \"\"\"\n",
    "    # Build full equity curve first\n",
    "    equity_full = (series + 1.0).cumprod()\n",
    "    roll_max = equity_full.rolling(window, min_periods=1).max()\n",
    "    dd = equity_full / roll_max - 1.0\n",
    "    return equity_full, dd\n",
    "\n",
    "\n",
    "def avg_offdiag_corr(mat: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Average off-diagonal correlation of a correlation matrix.\n",
    "    \"\"\"\n",
    "    n = mat.shape[0]\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    mask = ~np.eye(n, dtype=bool)\n",
    "    vals = mat[mask]\n",
    "    if vals.size == 0:\n",
    "        return 0.0\n",
    "    return float(np.nanmean(vals))\n",
    "\n",
    "\n",
    "def build_features(rets: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build daily regime features from rolling windows:\n",
    "      - vol_20: 20d SPY vol (annualized)\n",
    "      - vol_60: 60d SPY vol (annualized)\n",
    "      - ret_20: 20d SPY cumulative return\n",
    "      - dd_60:  60d SPY drawdown\n",
    "      - avg_corr_60: mean pairwise corr over last 60d across all assets\n",
    "    All features aligned on the rets index and dropping leading NaNs.\n",
    "    \"\"\"\n",
    "    idx = rets.index\n",
    "    spy = rets[\"SPY\"]\n",
    "\n",
    "    # Volatilities\n",
    "    vol_20 = spy.rolling(cfg.lookback_vol_short).std(ddof=0) * math.sqrt(252.0)\n",
    "    vol_60 = spy.rolling(cfg.lookback_vol_long).std(ddof=0) * math.sqrt(252.0)\n",
    "\n",
    "    # 20-day cumulative return\n",
    "    ret_20 = spy.rolling(cfg.lookback_vol_short).sum()\n",
    "\n",
    "    # Drawdown on SPY equity\n",
    "    _, dd_60_full = rolling_equity_and_dd(spy, window=cfg.lookback_dd)\n",
    "\n",
    "    # Average correlation (60d) across the universe\n",
    "    avg_corr_list = []\n",
    "    for dt in idx:\n",
    "        window = rets.loc[:dt].tail(cfg.lookback_corr)\n",
    "        if len(window) < cfg.lookback_corr:\n",
    "            avg_corr_list.append(np.nan)\n",
    "            continue\n",
    "        corr = window.corr().values\n",
    "        avg_corr_list.append(avg_offdiag_corr(corr))\n",
    "    avg_corr_60 = pd.Series(avg_corr_list, index=idx, name=\"avg_corr_60\")\n",
    "\n",
    "    feats = pd.DataFrame({\n",
    "        \"vol_20\": vol_20,\n",
    "        \"vol_60\": vol_60,\n",
    "        \"ret_20\": ret_20,\n",
    "        \"dd_60\": dd_60_full,\n",
    "        \"avg_corr_60\": avg_corr_60,\n",
    "    }, index=idx)\n",
    "\n",
    "    # Drop rows until we have enough history\n",
    "    feats = feats.dropna()\n",
    "    # Require at least min_history days before first usable feature date\n",
    "    if len(feats) == 0 or (feats.index[0] - idx[0]).days < 0:\n",
    "        pass  # nothing special needed beyond dropna\n",
    "\n",
    "    # Enforce minimum overall history\n",
    "    if len(rets.loc[:feats.index[0]]) < cfg.min_history:\n",
    "        # shift start further until min_history satisfied\n",
    "        valid_idx = feats.index\n",
    "        for dt in valid_idx:\n",
    "            if len(rets.loc[:dt]) >= cfg.min_history:\n",
    "                feats = feats.loc[dt:]\n",
    "                break\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "# ----------------------------- Regime Clustering ----------------------------- #\n",
    "\n",
    "def standardize_features(feats: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Z-score standardization per column, with safe handling for zero std.\"\"\"\n",
    "    X = feats.copy()\n",
    "    for col in X.columns:\n",
    "        mu = float(X[col].mean())\n",
    "        sigma = float(X[col].std(ddof=0))\n",
    "        if sigma <= 0:\n",
    "            X[col] = 0.0\n",
    "        else:\n",
    "            X[col] = (X[col] - mu) / sigma\n",
    "    return X\n",
    "\n",
    "\n",
    "def cluster_regimes(feats: pd.DataFrame, cfg: Config) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cluster feature rows into K regimes using KMeans.\n",
    "    Then order regimes by vol_20 (ascending) so that:\n",
    "      0 = calm, ..., K-1 = stressed.\n",
    "    Returns: regime_id Series aligned with feats.index.\n",
    "    \"\"\"\n",
    "    X = standardize_features(feats)\n",
    "    km = KMeans(\n",
    "        n_clusters=cfg.n_clusters,\n",
    "        random_state=cfg.seed,\n",
    "        n_init=20,\n",
    "    )\n",
    "    labels_raw = km.fit_predict(X.values)\n",
    "    labels_raw = pd.Series(labels_raw, index=feats.index, name=\"regime_raw\")\n",
    "\n",
    "    # Order regimes by increasing vol_20\n",
    "    vol_by_cluster = (\n",
    "        feats[\"vol_20\"]\n",
    "        .groupby(labels_raw)\n",
    "        .mean()\n",
    "        .sort_values()\n",
    "    )\n",
    "    ordered_clusters = list(vol_by_cluster.index)  # from calm to stressed\n",
    "    mapping = {raw: i for i, raw in enumerate(ordered_clusters)}\n",
    "\n",
    "    regime_id = labels_raw.map(mapping)\n",
    "    regime_id.name = \"regime_id\"\n",
    "    return regime_id\n",
    "\n",
    "\n",
    "def regime_names_from_ids(regime_id: pd.Series) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Map regime ids to human-readable names based on rank:\n",
    "      0 -> \"calm\"\n",
    "      1 -> \"neutral\"\n",
    "      2 -> \"stressed\"\n",
    "      ...\n",
    "      If more than 3 clusters, middle ones are numbered.\n",
    "    \"\"\"\n",
    "    unique_ids = sorted(regime_id.dropna().unique())\n",
    "    names = {}\n",
    "    if len(unique_ids) == 1:\n",
    "        names[unique_ids[0]] = \"single_regime\"\n",
    "        return names\n",
    "\n",
    "    for i in unique_ids:\n",
    "        if i == 0:\n",
    "            names[i] = \"calm\"\n",
    "        elif i == max(unique_ids):\n",
    "            names[i] = \"stressed\"\n",
    "        elif i == 1:\n",
    "            names[i] = \"neutral\"\n",
    "        else:\n",
    "            names[i] = f\"regime_{i}\"\n",
    "    return names\n",
    "\n",
    "\n",
    "# ----------------------------- Regime-Dependent Weights ----------------------------- #\n",
    "\n",
    "def risk_on_template(symbols: Tuple[str, ...]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Risk-on template: overweight equities, some bonds, a bit of gold.\n",
    "    \"\"\"\n",
    "    w = pd.Series(0.0, index=list(symbols))\n",
    "    # Equities\n",
    "    w[\"SPY\"] = 0.25\n",
    "    w[\"QQQ\"] = 0.20\n",
    "    w[\"IWM\"] = 0.10\n",
    "    w[\"EFA\"] = 0.10\n",
    "    w[\"EEM\"] = 0.05\n",
    "    # Defensives\n",
    "    w[\"TLT\"] = 0.15\n",
    "    w[\"LQD\"] = 0.10\n",
    "    w[\"GLD\"] = 0.05\n",
    "    w /= w.sum()\n",
    "    return w\n",
    "\n",
    "\n",
    "def risk_off_template(symbols: Tuple[str, ...]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Risk-off template: underweight equities, overweight bonds and gold.\n",
    "    \"\"\"\n",
    "    w = pd.Series(0.0, index=list(symbols))\n",
    "    # Equities (small allocations)\n",
    "    w[\"SPY\"] = 0.10\n",
    "    w[\"QQQ\"] = 0.05\n",
    "    w[\"IWM\"] = 0.05\n",
    "    w[\"EFA\"] = 0.05\n",
    "    w[\"EEM\"] = 0.05\n",
    "    # Defensives\n",
    "    w[\"TLT\"] = 0.35\n",
    "    w[\"LQD\"] = 0.25\n",
    "    w[\"GLD\"] = 0.10\n",
    "    w /= w.sum()\n",
    "    return w\n",
    "\n",
    "\n",
    "def weights_for_regime(regime_id: int,\n",
    "                       n_clusters: int,\n",
    "                       symbols: Tuple[str, ...]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given an ordered regime id (0=calm ... K-1=stressed), linearly mix\n",
    "    between a risk-on and risk-off template.\n",
    "    For K=3:\n",
    "      0 => mostly risk-on\n",
    "      1 => balanced\n",
    "      2 => mostly risk-off\n",
    "    For larger K, we smoothly interpolate.\n",
    "    \"\"\"\n",
    "    w_on = risk_on_template(symbols)\n",
    "    w_off = risk_off_template(symbols)\n",
    "\n",
    "    if n_clusters <= 1:\n",
    "        return w_on\n",
    "\n",
    "    # Mixing parameter: 0 -> purely risk-on, 1 -> purely risk-off\n",
    "    mix = float(regime_id) / float(max(n_clusters - 1, 1))\n",
    "\n",
    "    w = (1.0 - mix) * w_on + mix * w_off\n",
    "    w = np.maximum(w, 0.0)\n",
    "    s = float(w.sum())\n",
    "    if s <= 0:\n",
    "        w = w_on\n",
    "    else:\n",
    "        w /= s\n",
    "    return w\n",
    "\n",
    "\n",
    "# ----------------------------- Portfolio Construction ----------------------------- #\n",
    "\n",
    "def build_portfolio(rets: pd.DataFrame,\n",
    "                    feats: pd.DataFrame,\n",
    "                    regime_id: pd.Series,\n",
    "                    cfg: Config) -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Construct daily portfolio using regime-dependent weights.\n",
    "    Use regime_t based on information up to t-1 (no look-ahead).\n",
    "    \"\"\"\n",
    "    # Align regime IDs with returns index\n",
    "    ret_idx = rets.index\n",
    "    reg_full = regime_id.reindex(ret_idx).ffill()\n",
    "    reg_for_ret = reg_full.shift(1)  # weight_t uses regime_{t-1}\n",
    "\n",
    "    port_ret_list = []\n",
    "    eq_list = []\n",
    "    dd_list = []\n",
    "    lev_list = []  # here leverage is always 1, but kept for consistency\n",
    "    regime_used = []\n",
    "    regime_name_list = []\n",
    "    weight_rows = []\n",
    "\n",
    "    names_map = regime_names_from_ids(regime_id)\n",
    "    eq = 1.0\n",
    "    peak = 1.0\n",
    "\n",
    "    for dt in ret_idx:\n",
    "        rid = reg_for_ret.loc[dt]\n",
    "        if np.isnan(rid):\n",
    "            # Not enough history yet; skip until we get a valid regime\n",
    "            port_ret_list.append(np.nan)\n",
    "            eq_list.append(np.nan)\n",
    "            dd_list.append(np.nan)\n",
    "            lev_list.append(1.0)\n",
    "            regime_used.append(np.nan)\n",
    "            regime_name_list.append(None)\n",
    "            weight_rows.append(pd.Series(np.nan, index=list(cfg.symbols)))\n",
    "            continue\n",
    "\n",
    "        rid_int = int(rid)\n",
    "        w_t = weights_for_regime(rid_int, cfg.n_clusters, cfg.symbols)\n",
    "\n",
    "        r_vec = rets.loc[dt, w_t.index]\n",
    "        r_p = float((w_t * r_vec).sum())\n",
    "\n",
    "        eq *= (1.0 + r_p)\n",
    "        peak = max(peak, eq)\n",
    "        dd = eq / peak - 1.0\n",
    "\n",
    "        port_ret_list.append(r_p)\n",
    "        eq_list.append(eq)\n",
    "        dd_list.append(dd)\n",
    "        lev_list.append(1.0)\n",
    "        regime_used.append(rid_int)\n",
    "        regime_name_list.append(names_map.get(rid_int, f\"regime_{rid_int}\"))\n",
    "        weight_rows.append(w_t)\n",
    "\n",
    "    port_ret = pd.Series(port_ret_list, index=ret_idx, name=\"ret_port\")\n",
    "    equity = pd.Series(eq_list, index=ret_idx, name=\"equity\")\n",
    "    drawdown = pd.Series(dd_list, index=ret_idx, name=\"drawdown\")\n",
    "    leverage = pd.Series(lev_list, index=ret_idx, name=\"leverage\")\n",
    "    regime_used = pd.Series(regime_used, index=ret_idx, name=\"regime_id_used\")\n",
    "    regime_name_used = pd.Series(regime_name_list, index=ret_idx, name=\"regime_name\")\n",
    "\n",
    "    W_daily = pd.DataFrame(weight_rows, index=ret_idx)\n",
    "    W_daily.columns = [f\"w_{s}\" for s in cfg.symbols]\n",
    "\n",
    "    return {\n",
    "        \"ret_port\": port_ret,\n",
    "        \"equity\": equity,\n",
    "        \"drawdown\": drawdown,\n",
    "        \"leverage\": leverage,\n",
    "        \"regime_id_used\": regime_used,\n",
    "        \"regime_name\": regime_name_used,\n",
    "        \"weights\": W_daily,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Metrics & I/O ----------------------------- #\n",
    "\n",
    "def summary_stats(rets: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"Annualized performance stats (no RF).\"\"\"\n",
    "    rets = rets.dropna()\n",
    "    if len(rets) == 0:\n",
    "        return {\"ann_ret\": 0.0, \"ann_vol\": 0.0, \"sharpe\": 0.0}\n",
    "\n",
    "    mu_daily = float(rets.mean())\n",
    "    vol_daily = float(rets.std(ddof=0))\n",
    "    ann_ret = (1.0 + mu_daily) ** 252 - 1.0\n",
    "    ann_vol = vol_daily * math.sqrt(252.0)\n",
    "    sharpe = ann_ret / ann_vol if ann_vol > 0 else 0.0\n",
    "    return {\"ann_ret\": ann_ret, \"ann_vol\": ann_vol, \"sharpe\": sharpe}\n",
    "\n",
    "\n",
    "def regime_stats(port_rets: pd.Series,\n",
    "                 regime_used: pd.Series) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Stats per regime (based on the regime actually used for each day).\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    common_idx = port_rets.index.intersection(regime_used.index)\n",
    "    r = port_rets.loc[common_idx].dropna()\n",
    "    reg = regime_used.loc[r.index].dropna()\n",
    "    if len(r) == 0:\n",
    "        return stats\n",
    "\n",
    "    for rid in sorted(reg.dropna().unique()):\n",
    "        mask = reg == rid\n",
    "        r_sub = r[mask]\n",
    "        label = f\"regime_{int(rid)}\"\n",
    "        stats[label] = summary_stats(r_sub)\n",
    "        stats[label][\"days\"] = int(mask.sum())\n",
    "    return stats\n",
    "\n",
    "\n",
    "def save_outputs(df: pd.DataFrame,\n",
    "                 stats_all: Dict[str, float],\n",
    "                 max_dd: float,\n",
    "                 reg_stats: Dict[str, Dict[str, float]],\n",
    "                 cfg: Config) -> None:\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    df.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"portfolio\": {\n",
    "            \"ann_ret\": stats_all[\"ann_ret\"],\n",
    "            \"ann_vol\": stats_all[\"ann_vol\"],\n",
    "            \"sharpe\": stats_all[\"sharpe\"],\n",
    "            \"max_drawdown\": max_dd,\n",
    "        },\n",
    "        \"by_regime\": reg_stats,\n",
    "    }\n",
    "\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    print(\n",
    "        \"Portfolio: AnnRet={:.2%}, AnnVol={:.2%}, Sharpe={:.2f}, MaxDD={:.2%}\".format(\n",
    "            summary[\"portfolio\"][\"ann_ret\"],\n",
    "            summary[\"portfolio\"][\"ann_vol\"],\n",
    "            summary[\"portfolio\"][\"sharpe\"],\n",
    "            summary[\"portfolio\"][\"max_drawdown\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline ----------------------------- #\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows.\")\n",
    "\n",
    "    # 1) Features and regimes\n",
    "    feats = build_features(rets, cfg)\n",
    "    print(f\"[INFO] Built features from {feats.index.min().date()} to {feats.index.max().date()} \"\n",
    "          f\"(n={len(feats)})\")\n",
    "    regime_id = cluster_regimes(feats, cfg)\n",
    "    names_map = regime_names_from_ids(regime_id)\n",
    "    print(\"[INFO] Regimes discovered:\")\n",
    "    for k in sorted(names_map):\n",
    "        print(f\"  Regime {k}: {names_map[k]}\")\n",
    "\n",
    "    # 2) Build portfolio using regime-dependent weights\n",
    "    port = build_portfolio(rets, feats, regime_id, cfg)\n",
    "    ret_port = port[\"ret_port\"]\n",
    "    eq = port[\"equity\"]\n",
    "    dd = port[\"drawdown\"]\n",
    "\n",
    "    # 3) Stats\n",
    "    stats_all = summary_stats(ret_port)\n",
    "    max_dd = float(dd.min(skipna=True)) if len(dd) else 0.0\n",
    "    reg_stats = regime_stats(ret_port, port[\"regime_id_used\"])\n",
    "\n",
    "    # 4) Assemble output DataFrame\n",
    "    out_idx = rets.index\n",
    "    out = pd.DataFrame(index=out_idx)\n",
    "    out[prices.columns] = prices.reindex(out_idx)\n",
    "    out[[f\"ret_{c}\" for c in rets.columns]] = rets.add_prefix(\"ret_\")\n",
    "    # Features aligned / ffilled\n",
    "    feats_aligned = feats.reindex(out_idx).ffill()\n",
    "    for col in feats_aligned.columns:\n",
    "        out[col] = feats_aligned[col]\n",
    "    out[\"regime_id\"] = regime_id.reindex(out_idx)\n",
    "    out[\"regime_name\"] = port[\"regime_name\"]\n",
    "    out[port[\"weights\"].columns] = port[\"weights\"]\n",
    "    out[\"ret_port\"] = ret_port\n",
    "    out[\"equity\"] = eq\n",
    "    out[\"drawdown\"] = dd\n",
    "    out[\"leverage\"] = port[\"leverage\"]\n",
    "\n",
    "    save_outputs(out, stats_all, max_dd, reg_stats, cfg)\n",
    "\n",
    "\n",
    "# ----------------------------- CLI ----------------------------- #\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-64: KMeans regime clustering + regime-dependent multi-asset portfolio\"\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--n-clusters\", type=int, default=3)\n",
    "    p.add_argument(\"--min-history\", type=int, default=252)\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level64_regime_portfolio.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level64_regime_portfolio_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    a = p.parse_args()\n",
    "\n",
    "    return Config(\n",
    "        start=a.start,\n",
    "        n_clusters=a.n_clusters,\n",
    "        min_history=a.min_history,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / IPython shim to strip kernel args like \"-f kernel-xxxx.json\"\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4006 price rows, 4005 return rows.\n",
      "[INFO] Built features from 2011-01-03 to 2025-12-04 (n=3754)\n",
      "[INFO] Regimes discovered:\n",
      "  Regime 0: calm\n",
      "  Regime 1: neutral\n",
      "  Regime 2: stressed\n",
      "[OK] Saved daily series → level64_regime_portfolio.csv\n",
      "[OK] Saved summary → level64_regime_portfolio_summary.json\n",
      "Portfolio: AnnRet=6.80%, AnnVol=10.12%, Sharpe=0.67, MaxDD=-31.23%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
