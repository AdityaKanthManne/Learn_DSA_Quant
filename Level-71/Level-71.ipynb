{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T03:44:33.361861Z",
     "start_time": "2025-12-05T03:44:26.717972Z"
    }
   },
   "source": [
    "# level71_mom_tilt_portfolio.py\n",
    "# Momentum-Tilted HRP/EW Portfolio:\n",
    "#   - Base portfolio: HRP or Equal-Weight, rebalanced monthly.\n",
    "#   - Overlay: Time-series + Cross-sectional momentum tilt.\n",
    "#\n",
    "# Universe: SPY, QQQ, IWM, EFA, EEM, TLT, LQD, GLD\n",
    "#\n",
    "# Outputs:\n",
    "#   - level71_mom_tilt_portfolio.csv\n",
    "#   - level71_mom_tilt_portfolio_summary.json\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Sequence, Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# --------------------------- Config ---------------------------\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # Base portfolio construction\n",
    "    base_mode: str = \"hrp\"        # \"hrp\" or \"ew\"\n",
    "    cov_lookback: int = 252       # days for covariance estimation\n",
    "    min_lookback: int = 126       # minimum history before using HRP/EW\n",
    "    rebalance_freq: str = \"ME\"    # month-end\n",
    "\n",
    "    # Momentum overlay\n",
    "    lookback_ts: int = 126        # time-series momentum lookback (days)\n",
    "    lookback_cs: int = 252        # cross-sectional momentum lookback (days)\n",
    "    cs_top_frac: float = 0.3      # top fraction for winners (e.g. 0.3 → top 30%)\n",
    "    cs_bottom_frac: float = 0.3   # bottom fraction for losers\n",
    "    cs_tilt_strength: float = 0.5 # winners ×(1+0.5), losers ×(1-0.5)\n",
    "    ts_scale_neg: float = 0.2     # scale factor for assets with negative TS momentum\n",
    "\n",
    "    # Outputs\n",
    "    out_csv: str = \"level71_mom_tilt_portfolio.csv\"\n",
    "    out_json: str = \"level71_mom_tilt_portfolio_summary.json\"\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# --------------------------- Data Loader ---------------------------\n",
    "\n",
    "def load_prices(symbols: Sequence[str], start: str) -> pd.DataFrame:\n",
    "    \"\"\"Download adjusted close prices for a list of symbols from yfinance.\"\"\"\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No price data downloaded for {s}.\")\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"'Close' column missing for {s}.\")\n",
    "        close = px[\"Close\"].copy()\n",
    "        close.name = s\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"all\")\n",
    "    prices = prices.ffill().dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Daily log returns.\"\"\"\n",
    "    rets = np.log(prices).diff()\n",
    "    rets = rets.dropna(how=\"all\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# --------------------------- HRP Helpers ---------------------------\n",
    "\n",
    "def equal_weight(symbols: Sequence[str]) -> pd.Series:\n",
    "    n = len(symbols)\n",
    "    w = np.ones(n) / n\n",
    "    return pd.Series(w, index=list(symbols))\n",
    "\n",
    "\n",
    "def cov_to_corr(cov: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(cov, pd.DataFrame):\n",
    "        cov = pd.DataFrame(cov)\n",
    "    diag = np.diag(cov.values)\n",
    "    diag = np.where(diag <= 0, 1e-12, diag)\n",
    "    std = np.sqrt(diag)\n",
    "    denom = np.outer(std, std)\n",
    "    corr = cov.values / denom\n",
    "    corr[~np.isfinite(corr)] = 0.0\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    return pd.DataFrame(corr, index=cov.index, columns=cov.columns)\n",
    "\n",
    "\n",
    "def correl_to_dist(corr: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(corr, pd.DataFrame):\n",
    "        corr = pd.DataFrame(corr)\n",
    "    d = np.sqrt(0.5 * (1.0 - corr.values))\n",
    "    np.fill_diagonal(d, 0.0)\n",
    "    return pd.DataFrame(d, index=corr.index, columns=corr.columns)\n",
    "\n",
    "\n",
    "def single_linkage_order(dist: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"\n",
    "    Naive single-linkage clustering to get a leaf ordering\n",
    "    (no external libraries).\n",
    "    \"\"\"\n",
    "    n = dist.shape[0]\n",
    "    D = dist.values.astype(float)\n",
    "    np.fill_diagonal(D, np.inf)\n",
    "\n",
    "    clusters: Dict[int, List[int]] = {i: [i] for i in range(n)}\n",
    "    next_id = n\n",
    "\n",
    "    while len(clusters) > 1:\n",
    "        ids = list(clusters.keys())\n",
    "        best = None\n",
    "        best_pair = None\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i + 1, len(ids)):\n",
    "                ci = ids[i]\n",
    "                cj = ids[j]\n",
    "                members_i = clusters[ci]\n",
    "                members_j = clusters[cj]\n",
    "                sub = D[np.ix_(members_i, members_j)]\n",
    "                d_ij = float(np.min(sub))\n",
    "                if (best is None) or (d_ij < best):\n",
    "                    best = d_ij\n",
    "                    best_pair = (ci, cj)\n",
    "\n",
    "        if best_pair is None:\n",
    "            break\n",
    "\n",
    "        a, b = best_pair\n",
    "        new_members = clusters[a] + clusters[b]\n",
    "        del clusters[a]\n",
    "        del clusters[b]\n",
    "        clusters[next_id] = new_members\n",
    "        next_id += 1\n",
    "\n",
    "    final_members = list(clusters.values())[0]\n",
    "    return final_members\n",
    "\n",
    "\n",
    "def hrp_weights(cov: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Hierarchical Risk Parity long-only weights.\"\"\"\n",
    "    if not isinstance(cov, pd.DataFrame):\n",
    "        cov = pd.DataFrame(cov)\n",
    "    cols = list(cov.columns)\n",
    "    n = len(cols)\n",
    "\n",
    "    corr = cov_to_corr(cov)\n",
    "    dist = correl_to_dist(corr)\n",
    "    order = single_linkage_order(dist)\n",
    "\n",
    "    cov_reordered = cov.values[order][:, order]\n",
    "    diag = np.diag(cov_reordered)\n",
    "    diag = np.where(diag <= 0, 1e-8, diag)\n",
    "    inv_var = 1.0 / diag\n",
    "\n",
    "    weights = np.ones(n)\n",
    "    clusters = [np.arange(n)]\n",
    "\n",
    "    while clusters:\n",
    "        cluster = clusters.pop(0)\n",
    "        if len(cluster) <= 1:\n",
    "            continue\n",
    "\n",
    "        split = len(cluster) // 2\n",
    "        left = cluster[:split]\n",
    "        right = cluster[split:]\n",
    "\n",
    "        inv_var_left = inv_var[left]\n",
    "        inv_var_right = inv_var[right]\n",
    "\n",
    "        w_left = inv_var_left / inv_var_left.sum()\n",
    "        w_right = inv_var_right / inv_var_right.sum()\n",
    "\n",
    "        cov_left = cov_reordered[np.ix_(left, left)]\n",
    "        cov_right = cov_reordered[np.ix_(right, right)]\n",
    "\n",
    "        var_left = float(w_left @ cov_left @ w_left)\n",
    "        var_right = float(w_right @ cov_right @ w_right)\n",
    "\n",
    "        if var_left + var_right == 0:\n",
    "            alpha = 0.5\n",
    "        else:\n",
    "            alpha = 1.0 - var_left / (var_left + var_right)\n",
    "\n",
    "        weights[left] *= alpha\n",
    "        weights[right] *= (1.0 - alpha)\n",
    "\n",
    "        clusters.append(left)\n",
    "        clusters.append(right)\n",
    "\n",
    "    w_final = np.zeros(n)\n",
    "    for pos, asset_idx in enumerate(order):\n",
    "        w_final[asset_idx] = weights[pos]\n",
    "\n",
    "    return pd.Series(w_final, index=cols)\n",
    "\n",
    "\n",
    "def compute_rebalance_dates(rets: pd.DataFrame, freq: str) -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Rebalance dates; here, we expect 'ME' for month-end.\n",
    "    \"\"\"\n",
    "    if freq != \"ME\":\n",
    "        raise ValueError(\"This script expects rebalance_freq 'ME' (month-end).\")\n",
    "    return rets.resample(\"ME\").last().index\n",
    "\n",
    "\n",
    "# --------------------------- Momentum Overlay ---------------------------\n",
    "\n",
    "def compute_base_and_tilt_weights(rets: pd.DataFrame, cfg: Config):\n",
    "    \"\"\"\n",
    "    Build base weights (HRP/EW) and momentum-tilted weights on month-end dates,\n",
    "    then forward-fill to daily.\n",
    "    \"\"\"\n",
    "    symbols = list(cfg.symbols)\n",
    "    idx = rets.index\n",
    "    w_base = pd.DataFrame(index=idx, columns=symbols, dtype=float)\n",
    "    w_tilt = pd.DataFrame(index=idx, columns=symbols, dtype=float)\n",
    "\n",
    "    rebal_dates = compute_rebalance_dates(rets, cfg.rebalance_freq)\n",
    "\n",
    "    for d in rebal_dates:\n",
    "        window_cs = rets.loc[:d].tail(cfg.lookback_cs)\n",
    "        if window_cs.shape[0] < cfg.min_lookback:\n",
    "            continue\n",
    "\n",
    "        # Base weights\n",
    "        if cfg.base_mode.lower() == \"ew\":\n",
    "            w_b = equal_weight(symbols)\n",
    "        elif cfg.base_mode.lower() == \"hrp\":\n",
    "            cov = window_cs.tail(cfg.cov_lookback).cov()\n",
    "            if cov.isnull().any().any():\n",
    "                continue\n",
    "            w_b = hrp_weights(cov).reindex(symbols)\n",
    "        else:\n",
    "            raise ValueError(\"base_mode must be 'hrp' or 'ew'\")\n",
    "\n",
    "        if w_b.isnull().any():\n",
    "            continue\n",
    "\n",
    "        # Time-series momentum (recent trend)\n",
    "        window_ts = rets.loc[:d].tail(cfg.lookback_ts)\n",
    "        if window_ts.shape[0] == 0:\n",
    "            continue\n",
    "        ts_mom = window_ts.sum()   # sum of log returns ~ cumulative log return\n",
    "\n",
    "        # Cross-sectional momentum: cumulative over lookback_cs\n",
    "        cs_mom = window_cs.sum()\n",
    "\n",
    "        # Cross-sectional ranks (higher mom → better rank)\n",
    "        cs_rank = cs_mom.rank(ascending=False, method=\"first\")\n",
    "        n = len(symbols)\n",
    "        top_n = max(1, int(np.floor(cfg.cs_top_frac * n)))\n",
    "        bottom_n = max(1, int(np.floor(cfg.cs_bottom_frac * n)))\n",
    "\n",
    "        top_assets = cs_rank.nsmallest(top_n).index\n",
    "        bottom_assets = cs_rank.nlargest(bottom_n).index\n",
    "\n",
    "        w_t = w_b.copy()\n",
    "\n",
    "        # Cross-sectional tilt\n",
    "        if cfg.cs_tilt_strength != 0.0:\n",
    "            # winners: amplify\n",
    "            w_t.loc[top_assets] *= (1.0 + cfg.cs_tilt_strength)\n",
    "            # losers: de-emphasize but keep non-negative\n",
    "            loser_scale = max(0.0, 1.0 - cfg.cs_tilt_strength)\n",
    "            w_t.loc[bottom_assets] *= loser_scale\n",
    "\n",
    "        # Time-series gating: assets with negative TS momentum get scaled down\n",
    "        if cfg.ts_scale_neg < 1.0:\n",
    "            neg_assets = ts_mom[ts_mom <= 0].index\n",
    "            w_t.loc[neg_assets] *= cfg.ts_scale_neg\n",
    "\n",
    "        # Renormalize\n",
    "        total = float(w_t.sum())\n",
    "        if total <= 0:\n",
    "            w_t = w_b.copy()\n",
    "        else:\n",
    "            w_t /= total\n",
    "\n",
    "        w_base.loc[d] = w_b\n",
    "        w_tilt.loc[d] = w_t\n",
    "\n",
    "    w_base = w_base.ffill().dropna()\n",
    "    w_tilt = w_tilt.ffill().dropna()\n",
    "\n",
    "    common_idx = w_base.index.intersection(w_tilt.index)\n",
    "    w_base = w_base.reindex(common_idx)\n",
    "    w_tilt = w_tilt.reindex(common_idx)\n",
    "    return w_base, w_tilt\n",
    "\n",
    "\n",
    "# --------------------------- Performance Stats ---------------------------\n",
    "\n",
    "def stats_from_returns(r: pd.Series) -> dict:\n",
    "    r = r.dropna()\n",
    "    if r.empty:\n",
    "        return dict(ann_ret=np.nan, ann_vol=np.nan, sharpe=np.nan, max_dd=np.nan)\n",
    "\n",
    "    mu = float(r.mean())\n",
    "    sig = float(r.std())\n",
    "\n",
    "    ann_ret = (1.0 + mu) ** 252 - 1.0\n",
    "    ann_vol = sig * np.sqrt(252.0)\n",
    "    sharpe = ann_ret / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "    eq = (1.0 + r).cumprod()\n",
    "    peak = eq.cummax()\n",
    "    dd = eq / peak - 1.0\n",
    "    max_dd = float(dd.min()) if not dd.empty else np.nan\n",
    "\n",
    "    return dict(\n",
    "        ann_ret=float(ann_ret),\n",
    "        ann_vol=float(ann_vol),\n",
    "        sharpe=float(sharpe),\n",
    "        max_dd=float(max_dd),\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------- Pipeline ---------------------------\n",
    "\n",
    "def run_pipeline(cfg: Config):\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "\n",
    "    w_base, w_tilt = compute_base_and_tilt_weights(rets, cfg)\n",
    "\n",
    "    # Align everything\n",
    "    common_idx = rets.index.intersection(w_base.index).intersection(w_tilt.index)\n",
    "    prices = prices.reindex(common_idx)\n",
    "    rets = rets.reindex(common_idx)\n",
    "    w_base = w_base.reindex(common_idx)\n",
    "    w_tilt = w_tilt.reindex(common_idx)\n",
    "\n",
    "    # Portfolio returns\n",
    "    ret_base = (w_base * rets).sum(axis=1).rename(\"ret_base\")\n",
    "    ret_tilt = (w_tilt * rets).sum(axis=1).rename(\"ret_tilt\")\n",
    "\n",
    "    eq_base = (1.0 + ret_base).cumprod()\n",
    "    eq_tilt = (1.0 + ret_tilt).cumprod()\n",
    "\n",
    "    out = pd.DataFrame(index=common_idx)\n",
    "    # Prices and asset returns\n",
    "    out[list(cfg.symbols)] = prices\n",
    "    out[[f\"ret_{s}\" for s in cfg.symbols]] = rets.add_prefix(\"ret_\")\n",
    "\n",
    "    # Weights\n",
    "    out[[f\"w_base_{s}\" for s in cfg.symbols]] = w_base.add_prefix(\"w_base_\")\n",
    "    out[[f\"w_tilt_{s}\" for s in cfg.symbols]] = w_tilt.add_prefix(\"w_tilt_\")\n",
    "\n",
    "    # Portfolio series\n",
    "    out[\"ret_base\"] = ret_base\n",
    "    out[\"ret_tilt\"] = ret_tilt\n",
    "    out[\"eq_base\"] = eq_base\n",
    "    out[\"eq_tilt\"] = eq_tilt\n",
    "\n",
    "    # Summary stats\n",
    "    idx = out.index\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"start_date\": str(idx.min().date()) if len(idx) else None,\n",
    "        \"end_date\": str(idx.max().date()) if len(idx) else None,\n",
    "        \"n_days\": int(len(idx)),\n",
    "        \"Base\": stats_from_returns(ret_base),\n",
    "        \"MomentumTilt\": stats_from_returns(ret_tilt),\n",
    "    }\n",
    "\n",
    "    # Correlation between base and tilted returns\n",
    "    aligned = pd.concat([ret_base, ret_tilt], axis=1).dropna()\n",
    "    if aligned.shape[0] > 1:\n",
    "        corr = float(aligned.iloc[:, 0].corr(aligned.iloc[:, 1]))\n",
    "    else:\n",
    "        corr = np.nan\n",
    "    summary[\"corr_base_tilt\"] = corr\n",
    "\n",
    "    return out, summary\n",
    "\n",
    "\n",
    "# --------------------------- I/O ---------------------------\n",
    "\n",
    "def save_outputs(out: pd.DataFrame, summary: dict, cfg: Config) -> None:\n",
    "    out.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    if summary[\"start_date\"] and summary[\"end_date\"]:\n",
    "        print(\n",
    "            f\"Period {summary['start_date']} → {summary['end_date']}, \"\n",
    "            f\"n_days={summary['n_days']}\"\n",
    "        )\n",
    "\n",
    "    for name in [\"Base\", \"MomentumTilt\"]:\n",
    "        s = summary[name]\n",
    "        print(\n",
    "            f\"{name}: AnnRet={s['ann_ret']*100:.2f}%, \"\n",
    "            f\"AnnVol={s['ann_vol']*100:.2f}%, \"\n",
    "            f\"Sharpe={s['sharpe']:.2f}, \"\n",
    "            f\"MaxDD={s['max_dd']*100:.2f}%\"\n",
    "        )\n",
    "    print(f\"Correlation(Base, MomentumTilt) = {summary['corr_base_tilt']:.3f}\")\n",
    "\n",
    "\n",
    "# --------------------------- CLI ---------------------------\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-71: Momentum-Tilted HRP/EW Multi-Asset Portfolio\"\n",
    "    )\n",
    "    p.add_argument(\n",
    "        \"--symbols\",\n",
    "        type=str,\n",
    "        default=\"SPY,QQQ,IWM,EFA,EEM,TLT,LQD,GLD\",\n",
    "        help=\"Comma-separated tickers.\",\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "\n",
    "    p.add_argument(\n",
    "        \"--base-mode\",\n",
    "        type=str,\n",
    "        default=\"hrp\",\n",
    "        choices=[\"hrp\", \"ew\"],\n",
    "        help=\"Base portfolio type: 'hrp' or 'ew'.\",\n",
    "    )\n",
    "    p.add_argument(\"--cov-lookback\", type=int, default=252)\n",
    "    p.add_argument(\"--min-lookback\", type=int, default=126)\n",
    "    p.add_argument(\n",
    "        \"--rebalance-freq\",\n",
    "        type=str,\n",
    "        default=\"ME\",\n",
    "        help=\"Rebalance frequency (use 'ME' for month-end).\",\n",
    "    )\n",
    "\n",
    "    p.add_argument(\"--lookback-ts\", type=int, default=126)\n",
    "    p.add_argument(\"--lookback-cs\", type=int, default=252)\n",
    "    p.add_argument(\"--cs-top-frac\", type=float, default=0.3)\n",
    "    p.add_argument(\"--cs-bottom-frac\", type=float, default=0.3)\n",
    "    p.add_argument(\"--cs-tilt-strength\", type=float, default=0.5)\n",
    "    p.add_argument(\"--ts-scale-neg\", type=float, default=0.2)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level71_mom_tilt_portfolio.csv\")\n",
    "    p.add_argument(\n",
    "        \"--json\", type=str, default=\"level71_mom_tilt_portfolio_summary.json\"\n",
    "    )\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    symbols = tuple(s.strip() for s in a.symbols.split(\",\") if s.strip())\n",
    "\n",
    "    return Config(\n",
    "        symbols=symbols,\n",
    "        start=a.start,\n",
    "        base_mode=a.base_mode,\n",
    "        cov_lookback=a.cov_lookback,\n",
    "        min_lookback=a.min_lookback,\n",
    "        rebalance_freq=a.rebalance_freq,\n",
    "        lookback_ts=a.lookback_ts,\n",
    "        lookback_cs=a.lookback_cs,\n",
    "        cs_top_frac=a.cs_top_frac,\n",
    "        cs_bottom_frac=a.cs_bottom_frac,\n",
    "        cs_tilt_strength=a.cs_tilt_strength,\n",
    "        ts_scale_neg=a.ts_scale_neg,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------- Main ---------------------------\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    out, summary = run_pipeline(cfg)\n",
    "    save_outputs(out, summary, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / PyCharm shim\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[OK] Saved daily series → level71_mom_tilt_portfolio.csv\n",
      "[OK] Saved summary → level71_mom_tilt_portfolio_summary.json\n",
      "Period 2010-08-31 → 2025-12-04, n_days=3840\n",
      "Base: AnnRet=5.87%, AnnVol=7.99%, Sharpe=0.73, MaxDD=-25.93%\n",
      "MomentumTilt: AnnRet=7.07%, AnnVol=9.00%, Sharpe=0.79, MaxDD=-25.30%\n",
      "Correlation(Base, MomentumTilt) = 0.905\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
