{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T01:53:49.276627Z",
     "start_time": "2025-12-05T01:53:41.303102Z"
    }
   },
   "source": [
    "# level65_hrp_portfolio.py\n",
    "#\n",
    "# Level-65: Hierarchical Risk Parity (HRP) with Ledoit–Wolf shrinkage covariance\n",
    "#           and monthly out-of-sample rebalancing on a multi-asset ETF universe.\n",
    "#\n",
    "# Usage:\n",
    "#   python level65_hrp_portfolio.py\n",
    "#   python level65_hrp_portfolio.py --start 2010-01-01 --lookback 252\n",
    "#\n",
    "# Outputs:\n",
    "#   - level65_hrp_portfolio.csv\n",
    "#   - level65_hrp_portfolio_summary.json\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "\n",
    "# ----------------------------- Config ----------------------------- #\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "    lookback: int = 252           # trading days for covariance estimation\n",
    "    rebalance_freq: str = \"ME\"    # month-end; use 'ME' to avoid pandas 'M' warning\n",
    "\n",
    "    out_csv: str = \"level65_hrp_portfolio.csv\"\n",
    "    out_json: str = \"level65_hrp_portfolio_summary.json\"\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# ----------------------------- Data Loading ----------------------------- #\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily adjusted close prices for each symbol.\n",
    "    Handles both Series and DataFrame returns from yfinance.\n",
    "    \"\"\"\n",
    "    frames: List[pd.Series] = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No data returned for symbol {s}. Check ticker or internet.\")\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"'Close' column missing for {s}.\")\n",
    "\n",
    "        close_obj = px[\"Close\"]\n",
    "        if isinstance(close_obj, pd.Series):\n",
    "            close = close_obj.rename(s)\n",
    "        else:\n",
    "            # DataFrame (some APIs); take first column\n",
    "            col0 = close_obj.columns[0]\n",
    "            close = pd.Series(close_obj[col0].values, index=close_obj.index, name=s)\n",
    "\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Daily log returns.\"\"\"\n",
    "    return np.log(prices).diff().dropna()\n",
    "\n",
    "\n",
    "# ----------------------------- HRP Utilities ----------------------------- #\n",
    "\n",
    "def cov_to_corr(cov: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert covariance matrix to correlation matrix.\"\"\"\n",
    "    std = np.sqrt(np.diag(cov.values))\n",
    "    denom = np.outer(std, std)\n",
    "    corr = cov.values / denom\n",
    "    corr = np.nan_to_num(corr)\n",
    "    return pd.DataFrame(corr, index=cov.index, columns=cov.columns)\n",
    "\n",
    "\n",
    "def correl_distance(corr: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lopez de Prado correlation distance:\n",
    "        d_ij = sqrt(0.5 * (1 - corr_ij))\n",
    "    \"\"\"\n",
    "    corr_clip = corr.clip(-1.0, 1.0)\n",
    "    dist = np.sqrt(0.5 * (1.0 - corr_clip))\n",
    "    return dist\n",
    "\n",
    "\n",
    "def get_ivp(cov_sub: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse-variance portfolio for a covariance sub-matrix.\n",
    "    \"\"\"\n",
    "    var = np.diag(cov_sub)\n",
    "    var = np.where(var <= 0, 1e-8, var)\n",
    "    inv_var = 1.0 / var\n",
    "    inv_var /= inv_var.sum()\n",
    "    return inv_var\n",
    "\n",
    "\n",
    "def get_cluster_var(cov: pd.DataFrame, cluster_items: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Cluster variance: w' Σ w using inverse-variance weights within the cluster.\n",
    "    \"\"\"\n",
    "    cov_ = cov.loc[cluster_items, cluster_items].values\n",
    "    w_ = get_ivp(cov_)\n",
    "    return float(w_.T @ cov_ @ w_)\n",
    "\n",
    "\n",
    "def get_quasi_diag(cov: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering on correlation distance and return\n",
    "    the ordered list of tickers (quasi-diagonalization).\n",
    "    \"\"\"\n",
    "    corr = cov_to_corr(cov)\n",
    "    dist = correl_distance(corr)\n",
    "    # Condensed distance matrix for linkage\n",
    "    dist_condensed = squareform(dist.values, checks=False)\n",
    "    link = linkage(dist_condensed, method=\"single\")\n",
    "    sort_idx = leaves_list(link)\n",
    "    ordered = corr.index[sort_idx].tolist()\n",
    "    return ordered\n",
    "\n",
    "\n",
    "def hrp_weights(cov: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hierarchical Risk Parity weights based on Lopez de Prado (2016).\n",
    "    \"\"\"\n",
    "    if cov.shape[0] == 1:\n",
    "        return pd.Series([1.0], index=cov.index)\n",
    "\n",
    "    ordered_tickers = get_quasi_diag(cov)\n",
    "    cov_ord = cov.loc[ordered_tickers, ordered_tickers]\n",
    "\n",
    "    w = pd.Series(1.0, index=ordered_tickers)\n",
    "    clusters: List[List[str]] = [ordered_tickers]\n",
    "\n",
    "    while clusters:\n",
    "        new_clusters: List[List[str]] = []\n",
    "        for cluster in clusters:\n",
    "            if len(cluster) <= 1:\n",
    "                continue\n",
    "            split = len(cluster) // 2\n",
    "            c1 = cluster[:split]\n",
    "            c2 = cluster[split:]\n",
    "\n",
    "            var1 = get_cluster_var(cov_ord, c1)\n",
    "            var2 = get_cluster_var(cov_ord, c2)\n",
    "            if var1 + var2 == 0:\n",
    "                alpha1 = 0.5\n",
    "            else:\n",
    "                alpha1 = 1.0 - var1 / (var1 + var2)\n",
    "            alpha2 = 1.0 - alpha1\n",
    "\n",
    "            w[c1] *= alpha1\n",
    "            w[c2] *= alpha2\n",
    "\n",
    "            new_clusters.append(c1)\n",
    "            new_clusters.append(c2)\n",
    "\n",
    "        clusters = new_clusters\n",
    "\n",
    "    # Reindex to full covariance index\n",
    "    w = w.reindex(cov.index).fillna(0.0)\n",
    "    s = float(w.sum())\n",
    "    if s > 0:\n",
    "        w /= s\n",
    "    return w\n",
    "\n",
    "\n",
    "# ----------------------------- Portfolio Construction ----------------------------- #\n",
    "\n",
    "def build_hrp_weights_rolling(\n",
    "    rets: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute HRP weights on a rolling basis, rebalancing at month-end.\n",
    "    Weights become effective from the first trading day *after* the\n",
    "    month-end rebal date (no look-ahead).\n",
    "    \"\"\"\n",
    "    idx = rets.index\n",
    "    # Month-end dates based on returns index\n",
    "    month_ends = rets.resample(cfg.rebalance_freq).last().index\n",
    "\n",
    "    # Ledoit-Wolf estimator\n",
    "    lw = LedoitWolf()\n",
    "\n",
    "    eff_dates: List[pd.Timestamp] = []\n",
    "    eff_weights: List[pd.Series] = []\n",
    "\n",
    "    for me in month_ends:\n",
    "        # Only use data up to (and including) month-end\n",
    "        hist = rets.loc[:me].tail(cfg.lookback)\n",
    "        if len(hist) < cfg.lookback:\n",
    "            continue\n",
    "\n",
    "        # Fit Ledoit–Wolf covariance\n",
    "        lw.fit(hist.values)\n",
    "        cov = pd.DataFrame(\n",
    "            lw.covariance_,\n",
    "            index=hist.columns,\n",
    "            columns=hist.columns,\n",
    "        )\n",
    "\n",
    "        w_hrp = hrp_weights(cov)\n",
    "\n",
    "        # Effective from next trading day after month-end\n",
    "        pos = idx.searchsorted(me, side=\"right\")\n",
    "        if pos >= len(idx):\n",
    "            continue\n",
    "        eff_date = idx[pos]\n",
    "\n",
    "        eff_dates.append(eff_date)\n",
    "        eff_weights.append(w_hrp)\n",
    "\n",
    "    if not eff_dates:\n",
    "        raise RuntimeError(\"No effective rebalance dates found (not enough history?).\")\n",
    "\n",
    "    weights_rebal = pd.DataFrame(eff_weights, index=pd.Index(eff_dates, name=\"date\"))\n",
    "    weights_rebal = weights_rebal.sort_index()\n",
    "\n",
    "    # Reindex daily: forward-fill from each effective date onward\n",
    "    weights_daily = weights_rebal.reindex(idx).ffill()\n",
    "    weights_daily = weights_daily.reindex(columns=list(cfg.symbols))\n",
    "    return weights_daily\n",
    "\n",
    "\n",
    "def compute_turnover(weights: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Daily turnover (0.5 * sum |w_t - w_{t-1}|).\n",
    "    \"\"\"\n",
    "    W = weights.fillna(0.0)\n",
    "    diff = W.diff().abs()\n",
    "    turnover = 0.5 * diff.sum(axis=1)\n",
    "    return turnover\n",
    "\n",
    "\n",
    "def build_portfolio(prices: pd.DataFrame, rets: pd.DataFrame, cfg: Config) -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Build HRP portfolio, returning daily series for:\n",
    "      - ret_port\n",
    "      - equity\n",
    "      - drawdown\n",
    "      - leverage\n",
    "      - turnover\n",
    "    plus the daily weights DataFrame.\n",
    "    \"\"\"\n",
    "    weights_daily = build_hrp_weights_rolling(rets, cfg)\n",
    "\n",
    "    # Portfolio returns\n",
    "    port_ret = (weights_daily * rets).sum(axis=1)\n",
    "    port_ret.name = \"ret_port\"\n",
    "\n",
    "    # Equity curve\n",
    "    eq = (1.0 + port_ret).cumprod()\n",
    "    eq.name = \"equity\"\n",
    "\n",
    "    # Drawdown\n",
    "    peak = eq.cummax()\n",
    "    dd = eq / peak - 1.0\n",
    "    dd.name = \"drawdown\"\n",
    "\n",
    "    # Leverage (weights sum; should be ~1)\n",
    "    lev = weights_daily.sum(axis=1)\n",
    "    lev.name = \"leverage\"\n",
    "\n",
    "    # Turnover\n",
    "    turnover = compute_turnover(weights_daily)\n",
    "    turnover.name = \"turnover\"\n",
    "\n",
    "    return {\n",
    "        \"ret_port\": port_ret,\n",
    "        \"equity\": eq,\n",
    "        \"drawdown\": dd,\n",
    "        \"leverage\": lev,\n",
    "        \"turnover\": turnover,\n",
    "        \"weights\": weights_daily,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Metrics & I/O ----------------------------- #\n",
    "\n",
    "def summary_stats(rets: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"Annualized performance stats (no RF).\"\"\"\n",
    "    r = rets.dropna()\n",
    "    if len(r) == 0:\n",
    "        return {\"ann_ret\": 0.0, \"ann_vol\": 0.0, \"sharpe\": 0.0}\n",
    "\n",
    "    mu_daily = float(r.mean())\n",
    "    vol_daily = float(r.std(ddof=0))\n",
    "    ann_ret = (1.0 + mu_daily) ** 252 - 1.0\n",
    "    ann_vol = vol_daily * math.sqrt(252.0)\n",
    "    sharpe = ann_ret / ann_vol if ann_vol > 0 else 0.0\n",
    "    return {\"ann_ret\": ann_ret, \"ann_vol\": ann_vol, \"sharpe\": sharpe}\n",
    "\n",
    "\n",
    "def save_outputs(\n",
    "    out_df: pd.DataFrame,\n",
    "    stats_all: Dict[str, float],\n",
    "    max_dd: float,\n",
    "    avg_turnover_daily: float,\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    out_df.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"portfolio\": {\n",
    "            \"ann_ret\": stats_all[\"ann_ret\"],\n",
    "            \"ann_vol\": stats_all[\"ann_vol\"],\n",
    "            \"sharpe\": stats_all[\"sharpe\"],\n",
    "            \"max_drawdown\": max_dd,\n",
    "            \"avg_turnover_daily\": avg_turnover_daily,\n",
    "            \"avg_turnover_annualized\": avg_turnover_daily * 252.0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    print(\n",
    "        \"HRP Portfolio: AnnRet={:.2%}, AnnVol={:.2%}, Sharpe={:.2f}, \"\n",
    "        \"MaxDD={:.2%}, AvgDailyTurnover={:.2%}\".format(\n",
    "            summary[\"portfolio\"][\"ann_ret\"],\n",
    "            summary[\"portfolio\"][\"ann_vol\"],\n",
    "            summary[\"portfolio\"][\"sharpe\"],\n",
    "            summary[\"portfolio\"][\"max_drawdown\"],\n",
    "            summary[\"portfolio\"][\"avg_turnover_daily\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline ----------------------------- #\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows.\")\n",
    "\n",
    "    port = build_portfolio(prices, rets, cfg)\n",
    "    ret_port = port[\"ret_port\"]\n",
    "    eq = port[\"equity\"]\n",
    "    dd = port[\"drawdown\"]\n",
    "    lev = port[\"leverage\"]\n",
    "    turnover = port[\"turnover\"]\n",
    "\n",
    "    stats_all = summary_stats(ret_port)\n",
    "    max_dd = float(dd.min(skipna=True)) if len(dd) else 0.0\n",
    "    avg_turnover_daily = float(turnover.dropna().mean()) if len(turnover.dropna()) else 0.0\n",
    "\n",
    "    out_idx = rets.index\n",
    "    out = pd.DataFrame(index=out_idx)\n",
    "    out[prices.columns] = prices.reindex(out_idx)\n",
    "    out[[f\"ret_{c}\" for c in rets.columns]] = rets.add_prefix(\"ret_\")\n",
    "    out[\"ret_port\"] = ret_port\n",
    "    out[\"equity\"] = eq\n",
    "    out[\"drawdown\"] = dd\n",
    "    out[\"leverage\"] = lev\n",
    "    out[\"turnover\"] = turnover\n",
    "    out[port[\"weights\"].columns] = port[\"weights\"].add_prefix(\"w_\").reindex(out_idx)\n",
    "\n",
    "    save_outputs(out, stats_all, max_dd, avg_turnover_daily, cfg)\n",
    "\n",
    "\n",
    "# ----------------------------- CLI ----------------------------- #\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-65: Hierarchical Risk Parity (HRP) with Ledoit–Wolf and monthly rebalancing\"\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--lookback\", type=int, default=252)\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level65_hrp_portfolio.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level65_hrp_portfolio_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    a = p.parse_args()\n",
    "\n",
    "    return Config(\n",
    "        start=a.start,\n",
    "        lookback=a.lookback,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / IPython shim to strip kernel args like \"-f kernel-xxxx.json\"\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4006 price rows, 4005 return rows.\n",
      "[OK] Saved daily series → level65_hrp_portfolio.csv\n",
      "[OK] Saved summary → level65_hrp_portfolio_summary.json\n",
      "HRP Portfolio: AnnRet=5.97%, AnnVol=7.84%, Sharpe=0.76, MaxDD=-25.28%, AvgDailyTurnover=0.18%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
