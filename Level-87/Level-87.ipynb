{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T16:38:43.975980Z",
     "start_time": "2025-12-27T16:38:27.338929Z"
    }
   },
   "source": [
    "# level87_network_spillover_dy.py\n",
    "# Level-87: Diebold–Yilmaz Network Spillover Index (VAR + Generalized FEVD) using free-data\n",
    "#\n",
    "# Outputs:\n",
    "#   - level87_spillover_matrix.csv      (NxN normalized spillover matrix)\n",
    "#   - level87_spillover_metrics.csv     (TO/FROM/NET + totals)\n",
    "#   - level87_spillover_summary.json\n",
    "#\n",
    "# Run:\n",
    "#   python level87_network_spillover_dy.py\n",
    "#   python level87_network_spillover_dy.py --symbols SPY QQQ IWM EFA EEM TLT LQD GLD --start 2010-01-01\n",
    "#   python level87_network_spillover_dy.py --p 2 --h 10\n",
    "#   python level87_network_spillover_dy.py --rolling --window 756 --step 21\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    p: int = 2              # VAR lags\n",
    "    h: int = 10             # FEVD horizon\n",
    "    ridge: float = 1e-10    # tiny ridge for numerical stability on covariance inversion\n",
    "\n",
    "    min_obs: int = 800      # need enough history for stable VAR\n",
    "\n",
    "    rolling: bool = False\n",
    "    window: int = 756       # ~3y of trading days\n",
    "    step: int = 21          # monthly step\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "    out_mat_csv: str = \"level87_spillover_matrix.csv\"\n",
    "    out_metrics_csv: str = \"level87_spillover_metrics.csv\"\n",
    "    out_json: str = \"level87_spillover_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- yfinance loader -----------------------------\n",
    "def _safe_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        if (\"Close\", symbol) in px.columns:\n",
    "            s = px[(\"Close\", symbol)].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        if (\"Adj Close\", symbol) in px.columns:\n",
    "            s = px[(\"Adj Close\", symbol)].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        if (symbol, \"Close\") in px.columns:\n",
    "            s = px[(symbol, \"Close\")].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        if (symbol, \"Adj Close\") in px.columns:\n",
    "            s = px[(symbol, \"Adj Close\")].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        candidates = [\n",
    "            c for c in px.columns\n",
    "            if isinstance(c, tuple) and (symbol in c) and (\"Close\" in c or \"Adj Close\" in c)\n",
    "        ]\n",
    "        if candidates:\n",
    "            s = px[candidates[0]].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        raise RuntimeError(f\"Could not locate Close/Adj Close for {symbol} in MultiIndex columns.\")\n",
    "\n",
    "    if \"Close\" in px.columns:\n",
    "        s = px[\"Close\"].copy()\n",
    "        s.name = symbol\n",
    "        return s\n",
    "    if \"Adj Close\" in px.columns:\n",
    "        s = px[\"Adj Close\"].copy()\n",
    "        s.name = symbol\n",
    "        return s\n",
    "    raise RuntimeError(f\"'Close' missing for {symbol}. Columns={list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    px = yf.download(\n",
    "        list(symbols),\n",
    "        start=start,\n",
    "        auto_adjust=True,\n",
    "        progress=False,\n",
    "        group_by=\"column\",\n",
    "        threads=True,\n",
    "    )\n",
    "    if px is None or px.empty:\n",
    "        raise RuntimeError(\"No price data returned from yfinance.\")\n",
    "    frames = [_safe_close_series(px, s) for s in symbols]\n",
    "    prices = pd.concat(frames, axis=1).sort_index().dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    rets = np.log(prices).diff().dropna()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- VAR -> MA (Psi) recursion -----------------------------\n",
    "def var_to_psi_mats(A: np.ndarray, h: int) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert VAR(p) coefficient matrices A (p x N x N) to MA coefficient matrices Psi[0..h-1].\n",
    "    Psi_0 = I\n",
    "    Psi_k = sum_{j=1..p} Psi_{k-j} A_j  for k>=1 with Psi_{<0}=0\n",
    "    \"\"\"\n",
    "    p, N, _ = A.shape\n",
    "    Psi = [np.eye(N)]\n",
    "    for k in range(1, h):\n",
    "        acc = np.zeros((N, N))\n",
    "        for j in range(1, p + 1):\n",
    "            if k - j >= 0:\n",
    "                acc += Psi[k - j] @ A[j - 1]\n",
    "        Psi.append(acc)\n",
    "    return Psi\n",
    "\n",
    "\n",
    "# ----------------------------- Generalized FEVD (KPS) -----------------------------\n",
    "def generalized_fevd(Psi: List[np.ndarray], Sigma: np.ndarray, ridge: float = 1e-10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generalized FEVD (Koop–Pesaran–Shin):\n",
    "      theta_ij(H) = (sigma_jj^{-1} * sum_{h=0..H-1} (e_i' Psi_h Sigma e_j)^2)\n",
    "                    / (sum_{h=0..H-1} e_i' Psi_h Sigma Psi_h' e_i)\n",
    "    Then row-normalize so rows sum to 1.\n",
    "    \"\"\"\n",
    "    N = Sigma.shape[0]\n",
    "    Sigma = Sigma.copy()\n",
    "    Sigma.flat[:: N + 1] += ridge\n",
    "\n",
    "    denom = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        s = 0.0\n",
    "        ei = np.zeros(N); ei[i] = 1.0\n",
    "        for Ph in Psi:\n",
    "            v = ei @ (Ph @ Sigma @ Ph.T) @ ei\n",
    "            s += float(v)\n",
    "        denom[i] = max(s, 1e-18)\n",
    "\n",
    "    theta = np.zeros((N, N))\n",
    "    sig_diag = np.clip(np.diag(Sigma), 1e-18, np.inf)\n",
    "\n",
    "    for i in range(N):\n",
    "        ei = np.zeros(N); ei[i] = 1.0\n",
    "        for j in range(N):\n",
    "            ej = np.zeros(N); ej[j] = 1.0\n",
    "            num = 0.0\n",
    "            for Ph in Psi:\n",
    "                x = ei @ (Ph @ Sigma) @ ej\n",
    "                num += float(x * x)\n",
    "            theta[i, j] = (num / sig_diag[j]) / denom[i]\n",
    "\n",
    "    row_sums = theta.sum(axis=1, keepdims=True)\n",
    "    row_sums = np.where(row_sums <= 0, 1.0, row_sums)\n",
    "    theta = theta / row_sums\n",
    "    return theta\n",
    "\n",
    "\n",
    "# ----------------------------- Spillover metrics -----------------------------\n",
    "def spillover_metrics(theta: np.ndarray, symbols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Diebold–Yilmaz spillover table from normalized FEVD theta.\n",
    "    - FROM_i = sum_{j!=i} theta_{i,j}\n",
    "    - TO_i   = sum_{j!=i} theta_{j,i}\n",
    "    - NET_i  = TO_i - FROM_i\n",
    "    Total spillover index = (sum off-diagonal theta) / N * 100\n",
    "    \"\"\"\n",
    "    N = theta.shape[0]\n",
    "    off = theta.copy()\n",
    "    np.fill_diagonal(off, 0.0)\n",
    "\n",
    "    from_i = off.sum(axis=1)\n",
    "    to_i = off.sum(axis=0)\n",
    "    net_i = to_i - from_i\n",
    "\n",
    "    total = off.sum() / N * 100.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"FROM\": from_i,\n",
    "        \"TO\": to_i,\n",
    "        \"NET\": net_i,\n",
    "    }, index=symbols)\n",
    "\n",
    "    df.loc[\"TOTAL_SPILLOVER_%\", \"FROM\"] = total\n",
    "    df.loc[\"TOTAL_SPILLOVER_%\", \"TO\"] = np.nan\n",
    "    df.loc[\"TOTAL_SPILLOVER_%\", \"NET\"] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------- One-shot fit -----------------------------\n",
    "def fit_spillover(rets: pd.DataFrame, cfg: Config) -> Dict[str, object]:\n",
    "    if len(rets) < cfg.min_obs:\n",
    "        raise RuntimeError(f\"Not enough observations: {len(rets)} < min_obs={cfg.min_obs}\")\n",
    "\n",
    "    model = VAR(rets)\n",
    "    res = model.fit(cfg.p)\n",
    "\n",
    "    # A: (p, N, N) in statsmodels order (lag1..lagp)\n",
    "    A = np.array(res.coefs)  # shape (p, N, N)\n",
    "    Sigma = np.array(res.sigma_u)  # shape (N, N)\n",
    "\n",
    "    Psi = var_to_psi_mats(A, cfg.h)\n",
    "    theta = generalized_fevd(Psi, Sigma, ridge=cfg.ridge)\n",
    "\n",
    "    symbols = list(rets.columns)\n",
    "    mat = pd.DataFrame(theta, index=symbols, columns=symbols)\n",
    "    metrics = spillover_metrics(theta, symbols)\n",
    "\n",
    "    return {\n",
    "        \"theta\": theta,\n",
    "        \"matrix\": mat,\n",
    "        \"metrics\": metrics,\n",
    "        \"var_lags\": cfg.p,\n",
    "        \"fevd_h\": cfg.h,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Rolling mode -----------------------------\n",
    "def rolling_spillover(rets: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rolling total spillover index series.\n",
    "    \"\"\"\n",
    "    idx = rets.index\n",
    "    totals = []\n",
    "    dates = []\n",
    "\n",
    "    for start_i in range(0, len(rets) - cfg.window + 1, cfg.step):\n",
    "        end_i = start_i + cfg.window\n",
    "        sub = rets.iloc[start_i:end_i]\n",
    "        out = fit_spillover(sub, cfg)\n",
    "        total = float(out[\"metrics\"].loc[\"TOTAL_SPILLOVER_%\", \"FROM\"])\n",
    "        dates.append(idx[end_i - 1])\n",
    "        totals.append(total)\n",
    "\n",
    "    return pd.DataFrame({\"TOTAL_SPILLOVER_%\": totals}, index=pd.DatetimeIndex(dates))\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_log_returns(prices)\n",
    "\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, assets={rets.shape[1]}\")\n",
    "\n",
    "    one = fit_spillover(rets, cfg)\n",
    "\n",
    "    roll_df = None\n",
    "    if cfg.rolling:\n",
    "        print(f\"[INFO] Rolling spillover: window={cfg.window}, step={cfg.step} ...\")\n",
    "        roll_df = rolling_spillover(rets, cfg)\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"assets\": int(rets.shape[1]),\n",
    "        },\n",
    "        \"var\": {\"lags\": int(cfg.p)},\n",
    "        \"fevd\": {\"horizon\": int(cfg.h)},\n",
    "        \"total_spillover_percent\": float(one[\"metrics\"].loc[\"TOTAL_SPILLOVER_%\", \"FROM\"]),\n",
    "        \"ranking_net_spillover_high_to_low\": (\n",
    "            one[\"metrics\"]\n",
    "            .drop(index=\"TOTAL_SPILLOVER_%\", errors=\"ignore\")\n",
    "            .sort_values(\"NET\", ascending=False)\n",
    "            .index.tolist()\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"returns\": rets,\n",
    "        \"matrix\": one[\"matrix\"],\n",
    "        \"metrics\": one[\"metrics\"],\n",
    "        \"summary\": summary,\n",
    "        \"rolling_total\": roll_df,\n",
    "    }\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    mat: pd.DataFrame = result[\"matrix\"]  # type: ignore\n",
    "    metrics: pd.DataFrame = result[\"metrics\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]  # type: ignore\n",
    "    roll_df = result.get(\"rolling_total\", None)\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_mat_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_metrics_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    mat.to_csv(cfg.out_mat_csv)\n",
    "    metrics.to_csv(cfg.out_metrics_csv)\n",
    "\n",
    "    if roll_df is not None:\n",
    "        roll_path = cfg.out_mat_csv.replace(\".csv\", \"_rolling_total.csv\")\n",
    "        roll_df.to_csv(roll_path)\n",
    "        summary[\"rolling_total_csv\"] = roll_path\n",
    "        print(f\"[OK] Saved rolling total → {roll_path}\")\n",
    "\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved spillover matrix → {cfg.out_mat_csv}\")\n",
    "    print(f\"[OK] Saved metrics          → {cfg.out_metrics_csv}\")\n",
    "    print(f\"[OK] Saved summary          → {cfg.out_json}\")\n",
    "\n",
    "    total = metrics.loc[\"TOTAL_SPILLOVER_%\", \"FROM\"]\n",
    "    print(f\"[RESULT] Total Spillover Index = {float(total):.2f}%\")\n",
    "\n",
    "    print(\"[TOP] Net spillover (TO - FROM), highest emitters first:\")\n",
    "    ranked = (\n",
    "        metrics.drop(index=\"TOTAL_SPILLOVER_%\", errors=\"ignore\")\n",
    "        .sort_values(\"NET\", ascending=False)\n",
    "        .head(min(10, len(metrics) - 1))\n",
    "    )\n",
    "    for sym, r in ranked.iterrows():\n",
    "        print(f\"  {sym:>5s}  NET={r['NET']:.4f}  TO={r['TO']:.4f}  FROM={r['FROM']:.4f}\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-87: Diebold–Yilmaz Spillover Index (VAR-GFEVD)\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--p\", type=int, default=2)\n",
    "    p.add_argument(\"--h\", type=int, default=10)\n",
    "    p.add_argument(\"--ridge\", type=float, default=1e-10)\n",
    "    p.add_argument(\"--min-obs\", type=int, default=800)\n",
    "\n",
    "    p.add_argument(\"--rolling\", action=\"store_true\")\n",
    "    p.add_argument(\"--window\", type=int, default=756)\n",
    "    p.add_argument(\"--step\", type=int, default=21)\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    p.add_argument(\"--mat-csv\", type=str, default=\"level87_spillover_matrix.csv\")\n",
    "    p.add_argument(\"--metrics-csv\", type=str, default=\"level87_spillover_metrics.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level87_spillover_summary.json\")\n",
    "\n",
    "    a = p.parse_args()\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        p=int(a.p),\n",
    "        h=int(a.h),\n",
    "        ridge=float(a.ridge),\n",
    "        min_obs=int(a.min_obs),\n",
    "        rolling=bool(a.rolling),\n",
    "        window=int(a.window),\n",
    "        step=int(a.step),\n",
    "        seed=int(a.seed),\n",
    "        out_mat_csv=a.mat_csv,\n",
    "        out_metrics_csv=a.metrics_csv,\n",
    "        out_json=a.json\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4021 price rows, 4020 return rows, assets=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved spillover matrix → level87_spillover_matrix.csv\n",
      "[OK] Saved metrics          → level87_spillover_metrics.csv\n",
      "[OK] Saved summary          → level87_spillover_summary.json\n",
      "[RESULT] Total Spillover Index = 59.14%\n",
      "[TOP] Net spillover (TO - FROM), highest emitters first:\n",
      "    SPY  NET=0.1323  TO=0.8895  FROM=0.7572\n",
      "    EFA  NET=0.0624  TO=0.8005  FROM=0.7381\n",
      "    IWM  NET=0.0110  TO=0.7411  FROM=0.7300\n",
      "    QQQ  NET=0.0084  TO=0.7389  FROM=0.7305\n",
      "    EEM  NET=-0.0132  TO=0.7051  FROM=0.7182\n",
      "    LQD  NET=-0.0598  TO=0.3654  FROM=0.4252\n",
      "    TLT  NET=-0.0665  TO=0.4038  FROM=0.4704\n",
      "    GLD  NET=-0.0747  TO=0.0865  FROM=0.1612\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
