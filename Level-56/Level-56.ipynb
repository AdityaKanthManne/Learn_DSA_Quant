{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-02T01:03:15.644182Z",
     "start_time": "2025-12-02T01:02:43.263162Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Level-56 — Regime-Aware Volatility-Targeted SPY/TLT/SHY Overlay\n",
    "\n",
    "What this script does\n",
    "---------------------\n",
    "- Downloads daily prices for SPY, TLT, SHY (or builds synthetic data if download fails).\n",
    "- Builds simple market regime labels (“risk_off” vs “normal”) from SPY drawdowns / vol.\n",
    "- Creates features from trailing returns, volatility, correlation, and drawdown.\n",
    "- Trains a RandomForest classifier to predict next-day risk_off probability.\n",
    "- Converts regime probabilities into dynamic SPY/TLT/SHY weights.\n",
    "- Applies volatility targeting (e.g., 10% annualized) with leverage cap.\n",
    "- Computes portfolio equity curve, drawdowns, and a static 60/40 SPY/TLT benchmark.\n",
    "- Saves:\n",
    "    - level56_regime_portfolio.csv  (daily data, weights, returns)\n",
    "    - level56_regime_summary.json   (CAGR, vol, Sharpe, max DD, etc.)\n",
    "\n",
    "Run it in PyCharm or a Jupyter cell as-is.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "# ---------------------------- Config ---------------------------- #\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, str, str] = (\"SPY\", \"TLT\", \"SHY\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # Regime labelling thresholds (for SPY)\n",
    "    lookback_ret_days: int = 21      # ~1 month\n",
    "    lookback_dd_days: int = 63      # ~3 months\n",
    "    lookback_vol_days: int = 21\n",
    "\n",
    "    ret_thresh: float = -0.05       # -5% over 1 month\n",
    "    dd_thresh: float = -0.10        # -10% drawdown over 3 months\n",
    "    vol_thresh: float = 0.25        # 25% annualized realized vol\n",
    "\n",
    "    # ML model hyperparameters\n",
    "    rf_estimators: int = 200\n",
    "    rf_max_depth: int | None = 5\n",
    "    rf_min_samples_leaf: int = 5\n",
    "    rf_random_state: int = 56\n",
    "\n",
    "    # Train/val/test split (by time)\n",
    "    train_frac: float = 0.6\n",
    "    val_frac: float = 0.2  # test_frac implied as 1 - train_frac - val_frac\n",
    "\n",
    "    # Vol-targeting and allocation\n",
    "    target_vol: float = 0.10        # 10% annual vol\n",
    "    vol_lookback: int = 21\n",
    "    max_leverage: float = 1.5\n",
    "\n",
    "    # Regime-based base weights (before vol targeting)\n",
    "    # (p = predicted probability of risk_off)\n",
    "    p_low: float = 0.4\n",
    "    p_high: float = 0.7\n",
    "\n",
    "    # Output paths\n",
    "    out_csv: str = \"level56_regime_portfolio.csv\"\n",
    "    out_json: str = \"level56_regime_summary.json\"\n",
    "\n",
    "\n",
    "# ---------------------- Data utilities -------------------------- #\n",
    "\n",
    "\n",
    "def build_synthetic_prices(cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If yfinance download fails, build synthetic correlated price series\n",
    "    for SPY, TLT, SHY using a simple multi-asset GBM.\n",
    "    \"\"\"\n",
    "    print(\"[WARN] Falling back to synthetic prices.\")\n",
    "    rng = np.random.default_rng(56)\n",
    "    n_days = 4000\n",
    "\n",
    "    dates = pd.bdate_range(\"2010-01-04\", periods=n_days, freq=\"B\")\n",
    "\n",
    "    # Correlation structure: SPY risk, TLT defensive, SHY ~ cash\n",
    "    corr = np.array(\n",
    "        [\n",
    "            [1.0, -0.3, 0.0],\n",
    "            [-0.3, 1.0, 0.1],\n",
    "            [0.0, 0.1, 1.0],\n",
    "        ]\n",
    "    )\n",
    "    chol = np.linalg.cholesky(corr)\n",
    "\n",
    "    # Annualized vol assumptions\n",
    "    vols = np.array([0.18, 0.12, 0.01])\n",
    "    mus = np.array([0.07, 0.04, 0.02])\n",
    "\n",
    "    dt = 1.0 / 252.0\n",
    "    z = rng.standard_normal((n_days, 3))\n",
    "    eps = z @ chol.T\n",
    "\n",
    "    rets = (mus - 0.5 * vols**2) * dt + vols * math.sqrt(dt) * eps\n",
    "    prices = 100.0 * np.exp(np.cumsum(rets, axis=0))\n",
    "\n",
    "    df = pd.DataFrame(prices, index=dates, columns=list(cfg.symbols))\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_price_series(cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily adjusted close prices for the symbols from yfinance.\n",
    "    Handles MultiIndex columns and falls back to synthetic if needed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            list(cfg.symbols),\n",
    "            start=cfg.start,\n",
    "            auto_adjust=True,\n",
    "            progress=False,\n",
    "        )\n",
    "    except Exception:\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "    if data is None or data.empty:\n",
    "        return build_synthetic_prices(cfg)\n",
    "\n",
    "    # yfinance: if MultiIndex, pick \"Close\" (or \"Adj Close\" if using raw)\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        if (\"Adj Close\" in data.columns.get_level_values(0)) and (\n",
    "            \"Close\" not in data.columns.get_level_values(0)\n",
    "        ):\n",
    "            close = data[\"Adj Close\"].copy()\n",
    "        else:\n",
    "            close = data[\"Close\"].copy()\n",
    "    else:\n",
    "        # Single level columns: assume all are prices of different tickers\n",
    "        close = data.copy()\n",
    "\n",
    "    # Keep only requested symbols if present\n",
    "    cols = [c for c in close.columns if c in cfg.symbols]\n",
    "    if not cols:\n",
    "        return build_synthetic_prices(cfg)\n",
    "\n",
    "    close = close[cols].sort_index()\n",
    "    close = close.dropna(how=\"any\").copy()\n",
    "\n",
    "    # If we are missing some symbol, create flat 1.0 series (placeholder)\n",
    "    for sym in cfg.symbols:\n",
    "        if sym not in close.columns:\n",
    "            close[sym] = 1.0\n",
    "\n",
    "    close = close[list(cfg.symbols)]\n",
    "    return close\n",
    "\n",
    "\n",
    "# ------------------- Label & feature engineering ---------------- #\n",
    "\n",
    "\n",
    "def compute_drawdown(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling maximum drawdown over 'window' days:\n",
    "        dd_t = price_t / max(price_{t-window+1 ... t}) - 1\n",
    "    \"\"\"\n",
    "    roll_max = series.rolling(window, min_periods=1).max()\n",
    "    dd = series / roll_max - 1.0\n",
    "    return dd\n",
    "\n",
    "\n",
    "def make_regime_labels(cfg: Config, prices: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build a \"risk_off\" boolean label from SPY time series using\n",
    "    trailing returns, drawdowns, and realized volatility.\n",
    "    \"\"\"\n",
    "    spy = prices[cfg.symbols[0]].copy()\n",
    "\n",
    "    ret_21 = spy.pct_change(cfg.lookback_ret_days)\n",
    "    dd_63 = compute_drawdown(spy, cfg.lookback_dd_days)\n",
    "    vol_21 = spy.pct_change().rolling(cfg.lookback_vol_days).std() * math.sqrt(252.0)\n",
    "\n",
    "    risk_off_now = (\n",
    "        (ret_21 <= cfg.ret_thresh)\n",
    "        | (dd_63 <= cfg.dd_thresh)\n",
    "        | (vol_21 >= cfg.vol_thresh)\n",
    "    )\n",
    "\n",
    "    # Label for t+1: if tomorrow is risk_off, today's label is 1\n",
    "    y = risk_off_now.shift(-1).astype(float)\n",
    "    y = y.reindex(prices.index)\n",
    "    # Convert NaNs (due to last row shift) to 0\n",
    "    y = y.fillna(0.0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def make_features(cfg: Config, prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build daily features from trailing returns, volatility, correlation, and drawdown.\n",
    "    Features use only information up to time t (no look-ahead).\n",
    "    \"\"\"\n",
    "    sym_spy, sym_tlt, sym_shy = cfg.symbols\n",
    "    ret = prices.pct_change().fillna(0.0)\n",
    "\n",
    "    # Trailing returns\n",
    "    ret_spy_5 = ret[sym_spy].rolling(5, min_periods=3).sum()\n",
    "    ret_spy_21 = ret[sym_spy].rolling(21, min_periods=10).sum()\n",
    "    ret_tlt_5 = ret[sym_tlt].rolling(5, min_periods=3).sum()\n",
    "    ret_tlt_21 = ret[sym_tlt].rolling(21, min_periods=10).sum()\n",
    "\n",
    "    # Realized vol (annualized)\n",
    "    vol_spy_21 = ret[sym_spy].rolling(21, min_periods=10).std() * math.sqrt(252.0)\n",
    "    vol_tlt_21 = ret[sym_tlt].rolling(21, min_periods=10).std() * math.sqrt(252.0)\n",
    "\n",
    "    # Correlation between SPY & TLT\n",
    "    corr_21 = (\n",
    "        ret[[sym_spy, sym_tlt]]\n",
    "        .rolling(21, min_periods=10)\n",
    "        .corr()\n",
    "        .unstack()\n",
    "        .get((sym_spy, sym_tlt))\n",
    "    )\n",
    "    corr_21 = corr_21.reindex(prices.index)\n",
    "\n",
    "    # Drawdown\n",
    "    dd_spy_63 = compute_drawdown(prices[sym_spy], 63)\n",
    "    dd_tlt_63 = compute_drawdown(prices[sym_tlt], 63)\n",
    "\n",
    "    feats = pd.DataFrame(\n",
    "        {\n",
    "            \"ret_spy_5\": ret_spy_5,\n",
    "            \"ret_spy_21\": ret_spy_21,\n",
    "            \"ret_tlt_5\": ret_tlt_5,\n",
    "            \"ret_tlt_21\": ret_tlt_21,\n",
    "            \"vol_spy_21\": vol_spy_21,\n",
    "            \"vol_tlt_21\": vol_tlt_21,\n",
    "            \"corr_spy_tlt_21\": corr_21,\n",
    "            \"dd_spy_63\": dd_spy_63,\n",
    "            \"dd_tlt_63\": dd_tlt_63,\n",
    "        },\n",
    "        index=prices.index,\n",
    "    )\n",
    "\n",
    "    feats = feats.dropna().copy()\n",
    "    return feats\n",
    "\n",
    "\n",
    "# --------------------- Model training utils --------------------- #\n",
    "\n",
    "\n",
    "def split_train_val_test(\n",
    "    cfg: Config, X: pd.DataFrame, y: pd.Series\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split by time into train/val/test according to fractions in cfg.\n",
    "    \"\"\"\n",
    "    df = X.copy()\n",
    "    df[\"y\"] = y.reindex(X.index)\n",
    "\n",
    "    df = df.dropna().copy()\n",
    "\n",
    "    n = len(df)\n",
    "    n_train = int(cfg.train_frac * n)\n",
    "    n_val = int(cfg.val_frac * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_df = df.iloc[:n_train].copy()\n",
    "    val_df = df.iloc[n_train : n_train + n_val].copy()\n",
    "    test_df = df.iloc[n_train + n_val :].copy()\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"y\"])\n",
    "    y_train = train_df[\"y\"].astype(int)\n",
    "    X_val = val_df.drop(columns=[\"y\"])\n",
    "    y_val = val_df[\"y\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"y\"])\n",
    "    y_test = test_df[\"y\"].astype(int)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def train_rf(\n",
    "    cfg: Config, X_train: pd.DataFrame, y_train: pd.Series\n",
    ") -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Train a RandomForest classifier to predict risk_off probability.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=cfg.rf_estimators,\n",
    "        max_depth=cfg.rf_max_depth,\n",
    "        min_samples_leaf=cfg.rf_min_samples_leaf,\n",
    "        random_state=cfg.rf_random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    rf.fit(X_train.values, y_train.values)\n",
    "    return rf\n",
    "\n",
    "\n",
    "# ------------------- Allocation & backtest ---------------------- #\n",
    "\n",
    "\n",
    "def annualized_stats(ret: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute basic performance statistics from daily returns.\n",
    "    \"\"\"\n",
    "    ret = ret.dropna()\n",
    "    if len(ret) == 0:\n",
    "        return {\n",
    "            \"cagr\": 0.0,\n",
    "            \"vol\": 0.0,\n",
    "            \"sharpe\": 0.0,\n",
    "            \"max_drawdown\": 0.0,\n",
    "        }\n",
    "\n",
    "    # CAGR\n",
    "    total_return = (1.0 + ret).prod()\n",
    "    years = len(ret) / 252.0\n",
    "    cagr = total_return ** (1.0 / years) - 1.0 if years > 0 else 0.0\n",
    "\n",
    "    # Vol & Sharpe\n",
    "    vol = ret.std() * math.sqrt(252.0)\n",
    "    sharpe = cagr / vol if vol > 0 else 0.0\n",
    "\n",
    "    # Max drawdown\n",
    "    equity = (1.0 + ret).cumprod()\n",
    "    roll_max = equity.cummax()\n",
    "    dd = equity / roll_max - 1.0\n",
    "    max_dd = dd.min()\n",
    "\n",
    "    return {\n",
    "        \"cagr\": float(cagr),\n",
    "        \"vol\": float(vol),\n",
    "        \"sharpe\": float(sharpe),\n",
    "        \"max_drawdown\": float(max_dd),\n",
    "    }\n",
    "\n",
    "\n",
    "def regime_weights(cfg: Config, p_risk_off: float) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Map risk_off probability to base SPY/TLT/SHY weights (before vol targeting).\n",
    "    - p < p_low: aggressive (risk-on).\n",
    "    - p_low <= p < p_high: neutral.\n",
    "    - p >= p_high: defensive (more TLT, some SHY).\n",
    "    \"\"\"\n",
    "    if p_risk_off < cfg.p_low:\n",
    "        # Aggressive: 80% SPY, 20% TLT\n",
    "        return 0.80, 0.20, 0.0\n",
    "    elif p_risk_off < cfg.p_high:\n",
    "        # Neutral: 50% SPY, 50% TLT\n",
    "        return 0.50, 0.50, 0.0\n",
    "    else:\n",
    "        # Defensive: 20% SPY, 60% TLT, 20% SHY (cash-like)\n",
    "        return 0.20, 0.60, 0.20\n",
    "\n",
    "\n",
    "def apply_vol_targeting(\n",
    "    cfg: Config,\n",
    "    base_w: pd.DataFrame,\n",
    "    asset_ret: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given base weights and asset returns, apply rolling vol targeting.\n",
    "    We:\n",
    "      - Compute realized vol of the base-weight portfolio.\n",
    "      - Set gross leverage = target_vol / realized_vol (clipped to max_leverage).\n",
    "      - Final weights = leverage * base weights.\n",
    "    \"\"\"\n",
    "    # Portfolio daily returns using base weights (lag weights by 1 day)\n",
    "    base_ret = (base_w.shift(1) * asset_ret).sum(axis=1)\n",
    "    base_ret = base_ret.fillna(0.0)\n",
    "\n",
    "    # Rolling realized vol\n",
    "    roll_vol = base_ret.rolling(cfg.vol_lookback, min_periods=5).std() * math.sqrt(252.0)\n",
    "\n",
    "    # Leverage factor\n",
    "    lev = cfg.target_vol / (roll_vol + 1e-8)\n",
    "    lev = lev.clip(lower=0.0, upper=cfg.max_leverage)\n",
    "    lev = lev.reindex(base_ret.index).fillna(0.0)\n",
    "\n",
    "    # Apply leverage\n",
    "    w_final = base_w.mul(lev, axis=0)\n",
    "    return w_final\n",
    "\n",
    "\n",
    "def build_regime_portfolio(\n",
    "    cfg: Config,\n",
    "    prices: pd.DataFrame,\n",
    "    rf: RandomForestClassifier,\n",
    "    X_all: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Build the regime-aware portfolio weights and returns using the trained RF model.\n",
    "    Also build a 60/40 SPY/TLT benchmark (with vol targeting).\n",
    "    \"\"\"\n",
    "    sym_spy, sym_tlt, sym_shy = cfg.symbols\n",
    "\n",
    "    # Predict risk_off probability for all dates in X_all\n",
    "    p_risk_all = rf.predict_proba(X_all.values)[:, 1]\n",
    "    p_risk_series = pd.Series(p_risk_all, index=X_all.index, name=\"p_risk_off\")\n",
    "\n",
    "    # Base regime weights\n",
    "    base_w = pd.DataFrame(0.0, index=X_all.index, columns=[sym_spy, sym_tlt, sym_shy])\n",
    "    for dt, p in p_risk_series.items():\n",
    "        w_spy, w_tlt, w_shy = regime_weights(cfg, float(p))\n",
    "        base_w.loc[dt, sym_spy] = w_spy\n",
    "        base_w.loc[dt, sym_tlt] = w_tlt\n",
    "        base_w.loc[dt, sym_shy] = w_shy\n",
    "\n",
    "    # Align asset returns\n",
    "    prices = prices.reindex(X_all.index).dropna()\n",
    "    asset_ret = prices.pct_change().fillna(0.0)\n",
    "\n",
    "    # Apply vol targeting\n",
    "    w_regime = apply_vol_targeting(cfg, base_w, asset_ret)\n",
    "\n",
    "    # Portfolio returns (use 1-day lag on weights)\n",
    "    port_ret = (w_regime.shift(1) * asset_ret).sum(axis=1)\n",
    "    port_ret.name = \"ret_regime\"\n",
    "\n",
    "    # Benchmark: static 60/40 SPY/TLT (no SHY), but vol-targeted\n",
    "    w_bench_base = pd.DataFrame(\n",
    "        {\n",
    "            sym_spy: np.full(len(X_all), 0.60),\n",
    "            sym_tlt: np.full(len(X_all), 0.40),\n",
    "            sym_shy: np.zeros(len(X_all)),\n",
    "        },\n",
    "        index=X_all.index,\n",
    "    )\n",
    "    w_bench = apply_vol_targeting(cfg, w_bench_base, asset_ret)\n",
    "    bench_ret = (w_bench.shift(1) * asset_ret).sum(axis=1)\n",
    "    bench_ret.name = \"ret_benchmark\"\n",
    "\n",
    "    # Combine into one DataFrame for export\n",
    "    out_df = pd.concat(\n",
    "        [\n",
    "            prices,\n",
    "            asset_ret.add_prefix(\"ret_\"),\n",
    "            p_risk_series,\n",
    "            w_regime.add_prefix(\"w_regime_\"),\n",
    "            w_bench.add_prefix(\"w_bench_\"),\n",
    "            port_ret,\n",
    "            bench_ret,\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).dropna()\n",
    "\n",
    "    return out_df, port_ret.reindex(out_df.index), bench_ret.reindex(out_df.index)\n",
    "\n",
    "\n",
    "# ----------------------------- Main ----------------------------- #\n",
    "\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    # 1) Load prices\n",
    "    prices = load_price_series(cfg)\n",
    "    print(f\"[INFO] Loaded prices for {cfg.symbols} from {prices.index.min().date()} \"\n",
    "          f\"to {prices.index.max().date()} (n={len(prices)})\")\n",
    "\n",
    "    # 2) Labels and features\n",
    "    y_all = make_regime_labels(cfg, prices)\n",
    "    X_all = make_features(cfg, prices)\n",
    "\n",
    "    # Align X and y\n",
    "    y_all = y_all.reindex(X_all.index).fillna(0.0)\n",
    "\n",
    "    # 3) Time-based split\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test(cfg, X_all, y_all)\n",
    "\n",
    "    print(f\"[INFO] Split sizes — train: {len(X_train)}, val: {len(X_val)}, test: {len(X_test)}\")\n",
    "\n",
    "    # 4) Train RF\n",
    "    rf = train_rf(cfg, X_train, y_train)\n",
    "\n",
    "    # 5) Evaluate classification performance\n",
    "    def eval_split(X: pd.DataFrame, y: pd.Series, name: str) -> Dict[str, float]:\n",
    "        if len(X) == 0:\n",
    "            return {\"auc\": float(\"nan\"), \"acc\": float(\"nan\")}\n",
    "        p = rf.predict_proba(X.values)[:, 1]\n",
    "        try:\n",
    "            auc = roc_auc_score(y, p)\n",
    "        except ValueError:\n",
    "            auc = float(\"nan\")\n",
    "        acc = accuracy_score(y, (p >= 0.5).astype(int))\n",
    "        print(f\"[INFO] {name} AUC={auc:.4f}, ACC={acc:.4f}\")\n",
    "        return {\"auc\": float(auc), \"acc\": float(acc)}\n",
    "\n",
    "    perf_train = eval_split(X_train, y_train, \"Train\")\n",
    "    perf_val = eval_split(X_val, y_val, \"Val\")\n",
    "    perf_test = eval_split(X_test, y_test, \"Test\")\n",
    "\n",
    "    # 6) Build regime portfolio and benchmark\n",
    "    out_df, port_ret, bench_ret = build_regime_portfolio(cfg, prices, rf, X_all)\n",
    "\n",
    "    # 7) Performance stats (full sample and test-only)\n",
    "    stats_full = {\n",
    "        \"regime\": annualized_stats(port_ret),\n",
    "        \"benchmark\": annualized_stats(bench_ret),\n",
    "    }\n",
    "\n",
    "    # Restrict to test window for fair comparison\n",
    "    test_index = X_test.index\n",
    "    port_ret_test = port_ret.reindex(test_index)\n",
    "    bench_ret_test = bench_ret.reindex(test_index)\n",
    "\n",
    "    stats_test = {\n",
    "        \"regime\": annualized_stats(port_ret_test),\n",
    "        \"benchmark\": annualized_stats(bench_ret_test),\n",
    "    }\n",
    "\n",
    "    # 8) Save outputs\n",
    "    out_df.to_csv(cfg.out_csv)\n",
    "    print(f\"[OK] Saved daily data → {cfg.out_csv}\")\n",
    "\n",
    "    summary = {\n",
    "        \"clf_train\": perf_train,\n",
    "        \"clf_val\": perf_val,\n",
    "        \"clf_test\": perf_test,\n",
    "        \"stats_full\": stats_full,\n",
    "        \"stats_test\": stats_test,\n",
    "        \"symbols\": list(cfg.symbols),\n",
    "        \"start\": str(prices.index.min().date()),\n",
    "        \"end\": str(prices.index.max().date()),\n",
    "    }\n",
    "\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    print(\"\\n[SUMMARY — Full sample]\")\n",
    "    for k, v in stats_full.items():\n",
    "        print(\n",
    "            f\"  {k:10s}: CAGR={v['cagr']:.2%}, Vol={v['vol']:.2%}, \"\n",
    "            f\"Sharpe={v['sharpe']:.2f}, MaxDD={v['max_drawdown']:.2%}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n[SUMMARY — Test window]\")\n",
    "    for k, v in stats_test.items():\n",
    "        print(\n",
    "            f\"  {k:10s}: CAGR={v['cagr']:.2%}, Vol={v['vol']:.2%}, \"\n",
    "            f\"Sharpe={v['sharpe']:.2f}, MaxDD={v['max_drawdown']:.2%}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter-safe: strip out any '-f kernel.json' noise\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded prices for ('SPY', 'TLT', 'SHY') from 2010-01-04 to 2025-12-01 (n=4003)\n",
      "[INFO] Split sizes — train: 2396, val: 798, test: 800\n",
      "[INFO] Train AUC=0.9976, ACC=0.9821\n",
      "[INFO] Val AUC=0.9904, ACC=0.9612\n",
      "[INFO] Test AUC=0.9928, ACC=0.9762\n",
      "[OK] Saved daily data → level56_regime_portfolio.csv\n",
      "[OK] Saved summary → level56_regime_summary.json\n",
      "\n",
      "[SUMMARY — Full sample]\n",
      "  regime    : CAGR=11.86%, Vol=10.59%, Sharpe=1.12, MaxDD=-22.93%\n",
      "  benchmark : CAGR=12.28%, Vol=10.00%, Sharpe=1.23, MaxDD=-19.51%\n",
      "\n",
      "[SUMMARY — Test window]\n",
      "  regime    : CAGR=10.62%, Vol=10.75%, Sharpe=0.99, MaxDD=-13.67%\n",
      "  benchmark : CAGR=10.34%, Vol=10.65%, Sharpe=0.97, MaxDD=-11.87%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
