{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-03T01:40:34.747761Z",
     "start_time": "2025-12-03T01:40:28.721251Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Level-60 — Hierarchical Risk Parity (HRP) Multi-Asset Portfolio\n",
    "\n",
    "Concept focus\n",
    "-------------\n",
    "Quant model:\n",
    "    - Universe: multiple liquid ETFs (default:\n",
    "      SPY, QQQ, IWM, EFA, EEM, TLT, LQD, GLD).\n",
    "    - Use historical daily returns to estimate covariance and correlation.\n",
    "    - Build a correlation-based ordering of assets (a cheap stand-in for\n",
    "      full hierarchical clustering).\n",
    "    - Apply a Hierarchical Risk Parity style recursive bisection:\n",
    "        * At each split, divide the ordered asset list into two clusters.\n",
    "        * Compute inverse-variance weights inside each cluster.\n",
    "        * Allocate capital between clusters in inverse proportion to their\n",
    "          variances (low-vol cluster gets more weight).\n",
    "    - Rebalance monthly and hold weights between rebalances.\n",
    "    - Compare to a simple equal-weight (EW) long-only benchmark.\n",
    "\n",
    "DSA concept:\n",
    "    - Divide-and-conquer recursion on a list of assets:\n",
    "        * Recursively split a sorted list into halves.\n",
    "        * Combine results by adjusting weights top-down.\n",
    "    - Greedy nearest-neighbor ordering on a correlation matrix:\n",
    "        * Start from a \"seed\" asset, then repeatedly append the asset that\n",
    "          is most correlated with the current set, grouping similar assets.\n",
    "    - Matrix operations for covariance and portfolio variance calculations.\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "CSV: level60_hrp_portfolio.csv\n",
    "    - px_<sym>         : prices\n",
    "    - ret_<sym>        : daily returns\n",
    "    - w_<sym>          : HRP weights\n",
    "    - port_ret_hrp     : HRP portfolio daily returns\n",
    "    - port_ret_ew      : equal-weight benchmark daily returns\n",
    "\n",
    "JSON: level60_hrp_summary.json\n",
    "    - universe, sample start/end\n",
    "    - rebalance frequency and lookback window\n",
    "    - latest HRP weights (by symbol)\n",
    "    - performance stats for HRP vs equal-weight:\n",
    "        * CAGR, volatility, Sharpe, max drawdown\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ---------------------------- Config ---------------------------- #\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Multi-asset ETF universe\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\",  # US large-cap\n",
    "        \"QQQ\",  # US tech-heavy\n",
    "        \"IWM\",  # US small-cap\n",
    "        \"EFA\",  # Developed ex-US\n",
    "        \"EEM\",  # Emerging markets\n",
    "        \"TLT\",  # Long UST\n",
    "        \"LQD\",  # Investment-grade credit\n",
    "        \"GLD\",  # Gold\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # HRP settings\n",
    "    lookback_days: int = 252     # covariance lookback for each rebalance\n",
    "    min_lookback_days: int = 150 # minimum required to compute weights\n",
    "    rebalance_freq: str = \"M\"    # monthly rebalance\n",
    "\n",
    "    # Output files\n",
    "    out_csv: str = \"level60_hrp_portfolio.csv\"\n",
    "    out_json: str = \"level60_hrp_summary.json\"\n",
    "\n",
    "\n",
    "# ---------------------- Data utilities -------------------------- #\n",
    "\n",
    "\n",
    "def build_synthetic_prices(cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Synthetic multi-asset GBM with a simple correlation structure.\n",
    "    Used if yfinance download fails.\n",
    "    \"\"\"\n",
    "    print(\"[WARN] Falling back to synthetic prices (Level-60).\")\n",
    "    rng = np.random.default_rng(60)\n",
    "    n_assets = len(cfg.symbols)\n",
    "    n_days = 4000\n",
    "\n",
    "    dates = pd.bdate_range(\"2010-01-04\", periods=n_days, freq=\"B\")\n",
    "\n",
    "    base_corr = np.array(\n",
    "        [\n",
    "            [1.0, 0.85, 0.7, 0.5, 0.4, -0.2, -0.1, 0.1],\n",
    "            [0.85, 1.0, 0.7, 0.5, 0.4, -0.2, -0.1, 0.1],\n",
    "            [0.7, 0.7, 1.0, 0.4, 0.3, -0.1, -0.1, 0.0],\n",
    "            [0.5, 0.5, 0.4, 1.0, 0.6, -0.2, -0.1, 0.0],\n",
    "            [0.4, 0.4, 0.3, 0.6, 1.0, -0.3, -0.2, 0.0],\n",
    "            [-0.2, -0.2, -0.1, -0.2, -0.3, 1.0, 0.6, -0.1],\n",
    "            [-0.1, -0.1, -0.1, -0.1, -0.2, 0.6, 1.0, -0.1],\n",
    "            [0.1, 0.1, 0.0, 0.0, 0.0, -0.1, -0.1, 1.0],\n",
    "        ]\n",
    "    )\n",
    "    if n_assets != base_corr.shape[0]:\n",
    "        corr = np.eye(n_assets)\n",
    "    else:\n",
    "        corr = base_corr\n",
    "\n",
    "    chol = np.linalg.cholesky(corr)\n",
    "\n",
    "    vols = np.array([0.18, 0.22, 0.20, 0.17, 0.22, 0.12, 0.10, 0.15])[:n_assets]\n",
    "    mus = np.array([0.07, 0.09, 0.08, 0.06, 0.09, 0.04, 0.03, 0.05])[:n_assets]\n",
    "\n",
    "    dt = 1.0 / 252.0\n",
    "    z = rng.standard_normal((n_days, n_assets))\n",
    "    eps = z @ chol.T\n",
    "\n",
    "    rets = (mus - 0.5 * vols**2) * dt + vols * math.sqrt(dt) * eps\n",
    "    prices = 100.0 * np.exp(np.cumsum(rets, axis=0))\n",
    "\n",
    "    df = pd.DataFrame(prices, index=dates, columns=list(cfg.symbols))\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_price_series(cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily adjusted close prices for the symbols from yfinance.\n",
    "    Handles MultiIndex columns and falls back to synthetic if needed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns = cfg.symbols, index = dates, dtype=float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw = yf.download(\n",
    "            list(cfg.symbols),\n",
    "            start=cfg.start,\n",
    "            auto_adjust=True,\n",
    "            progress=False,\n",
    "        )\n",
    "    except Exception:\n",
    "        raw = pd.DataFrame()\n",
    "\n",
    "    if raw is None or raw.empty:\n",
    "        return build_synthetic_prices(cfg)\n",
    "\n",
    "    if isinstance(raw.columns, pd.MultiIndex):\n",
    "        top = raw.columns.get_level_values(0)\n",
    "        if \"Adj Close\" in top and \"Close\" not in top:\n",
    "            px = raw[\"Adj Close\"].copy()\n",
    "        else:\n",
    "            px = raw[\"Close\"].copy()\n",
    "    else:\n",
    "        px = raw.copy()\n",
    "\n",
    "    cols = [c for c in px.columns if c in cfg.symbols]\n",
    "    if not cols:\n",
    "        return build_synthetic_prices(cfg)\n",
    "\n",
    "    px = px[cols].sort_index().dropna(how=\"any\").copy()\n",
    "\n",
    "    # Ensure all symbols exist; if missing, plug trivial series\n",
    "    for sym in cfg.symbols:\n",
    "        if sym not in px.columns:\n",
    "            px[sym] = 1.0\n",
    "\n",
    "    px = px[list(cfg.symbols)].astype(float)\n",
    "    return px\n",
    "\n",
    "\n",
    "# -------------------- Performance utilities --------------------- #\n",
    "\n",
    "\n",
    "def annualized_stats(ret: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute CAGR, vol, Sharpe, and max drawdown for daily returns.\n",
    "    \"\"\"\n",
    "    ret = ret.dropna()\n",
    "    if len(ret) == 0:\n",
    "        return {\n",
    "            \"cagr\": 0.0,\n",
    "            \"vol\": 0.0,\n",
    "            \"sharpe\": 0.0,\n",
    "            \"max_drawdown\": 0.0,\n",
    "        }\n",
    "\n",
    "    total_return = float((1.0 + ret).prod())\n",
    "    years = len(ret) / 252.0\n",
    "    cagr = total_return ** (1.0 / years) - 1.0 if years > 0 else 0.0\n",
    "\n",
    "    vol = float(ret.std() * math.sqrt(252.0))\n",
    "    sharpe = cagr / vol if vol > 0 else 0.0\n",
    "\n",
    "    equity = (1.0 + ret).cumprod()\n",
    "    roll_max = equity.cummax()\n",
    "    dd = equity / roll_max - 1.0\n",
    "    max_dd = float(dd.min())\n",
    "\n",
    "    return {\n",
    "        \"cagr\": float(cagr),\n",
    "        \"vol\": float(vol),\n",
    "        \"sharpe\": float(sharpe),\n",
    "        \"max_drawdown\": max_dd,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------- Greedy correlation ordering ------------------ #\n",
    "\n",
    "\n",
    "def greedy_correlation_sort(corr: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Build a correlation-based ordering of assets.\n",
    "\n",
    "    Idea:\n",
    "        - Compute each asset's average correlation to others.\n",
    "        - Start from the asset with highest average correlation.\n",
    "        - Repeatedly append the remaining asset that is most correlated\n",
    "          with the already ordered set.\n",
    "\n",
    "    This is a cheap approximation to full hierarchical clustering but\n",
    "    is good enough to illustrate HRP's recursive bisection on a\n",
    "    cluster-like ordering.\n",
    "    \"\"\"\n",
    "    symbols = list(corr.columns)\n",
    "    if len(symbols) <= 1:\n",
    "        return symbols\n",
    "\n",
    "    # Replace self-correlation with NaN so it does not dominate the average\n",
    "    corr_no_diag = corr.copy()\n",
    "    np.fill_diagonal(corr_no_diag.values, np.nan)\n",
    "    avg_corr = corr_no_diag.mean(axis=1)\n",
    "    seed = avg_corr.idxmax()\n",
    "\n",
    "    ordered: List[str] = [seed]\n",
    "    remaining = set(symbols)\n",
    "    remaining.remove(seed)\n",
    "\n",
    "    while remaining:\n",
    "        best_sym = None\n",
    "        best_score = -np.inf\n",
    "        for sym in remaining:\n",
    "            # Correlation of candidate with current ordered set\n",
    "            vals = corr.loc[sym, ordered]\n",
    "            max_corr = float(vals.max())\n",
    "            if max_corr > best_score:\n",
    "                best_score = max_corr\n",
    "                best_sym = sym\n",
    "        ordered.append(best_sym)\n",
    "        remaining.remove(best_sym)\n",
    "\n",
    "    return ordered\n",
    "\n",
    "\n",
    "# ---------------------- HRP weighting --------------------------- #\n",
    "\n",
    "\n",
    "def inverse_variance_weights(cov: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse-variance portfolio weights for a cluster covariance matrix.\n",
    "    \"\"\"\n",
    "    diag = np.diag(cov.values)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        inv_var = 1.0 / diag\n",
    "    inv_var[~np.isfinite(inv_var)] = 0.0\n",
    "    s = inv_var.sum()\n",
    "    if s <= 0:\n",
    "        return np.ones_like(inv_var) / len(inv_var)\n",
    "    return inv_var / s\n",
    "\n",
    "\n",
    "def hrp_weights(cov: pd.DataFrame, order: List[str]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute Hierarchical Risk Parity style weights given a covariance\n",
    "    matrix and a correlation-based asset ordering.\n",
    "\n",
    "    Steps:\n",
    "        - Reorder covariance matrix according to `order`.\n",
    "        - Initialize all weights to 1.\n",
    "        - Recursively split the ordered list into halves:\n",
    "            * compute cluster variances using inverse-variance weights\n",
    "            * allocate capital between clusters in inverse proportion\n",
    "              to their variances\n",
    "        - Normalize weights to sum to 1.\n",
    "    \"\"\"\n",
    "    cov_ord = cov.loc[order, order]\n",
    "    weights = pd.Series(1.0, index=cov_ord.index)\n",
    "\n",
    "    def _split(cluster: List[str]) -> None:\n",
    "        n = len(cluster)\n",
    "        if n <= 1:\n",
    "            return\n",
    "\n",
    "        split = n // 2\n",
    "        left = cluster[:split]\n",
    "        right = cluster[split:]\n",
    "\n",
    "        cov_l = cov_ord.loc[left, left]\n",
    "        cov_r = cov_ord.loc[right, right]\n",
    "\n",
    "        w_l = inverse_variance_weights(cov_l)\n",
    "        w_r = inverse_variance_weights(cov_r)\n",
    "\n",
    "        var_l = float(w_l @ cov_l.values @ w_l)\n",
    "        var_r = float(w_r @ cov_r.values @ w_r)\n",
    "\n",
    "        if not np.isfinite(var_l):\n",
    "            var_l = 0.0\n",
    "        if not np.isfinite(var_r):\n",
    "            var_r = 0.0\n",
    "\n",
    "        if var_l + var_r > 0:\n",
    "            alpha_l = 1.0 - var_l / (var_l + var_r)\n",
    "            alpha_r = 1.0 - var_r / (var_l + var_r)\n",
    "        else:\n",
    "            alpha_l = alpha_r = 0.5\n",
    "\n",
    "        weights[left] *= alpha_l\n",
    "        weights[right] *= alpha_r\n",
    "\n",
    "        _split(left)\n",
    "        _split(right)\n",
    "\n",
    "    _split(order)\n",
    "    weights = weights / weights.sum()\n",
    "    return weights\n",
    "\n",
    "\n",
    "def compute_hrp_weight_path(\n",
    "    cfg: Config,\n",
    "    rets: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute a time series of HRP weights with a given rebalance frequency.\n",
    "\n",
    "    Args:\n",
    "        cfg  : config with lookback_days, min_lookback_days, rebalance_freq\n",
    "        rets : DataFrame of daily returns (index = dates, columns = symbols)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of weights, same index and columns as `rets`.\n",
    "    \"\"\"\n",
    "    dates = rets.index\n",
    "    symbols = list(rets.columns)\n",
    "\n",
    "    periods = dates.to_period(cfg.rebalance_freq)\n",
    "    first_in_period = ~periods.duplicated()\n",
    "    rebalance_days = dates[first_in_period]\n",
    "\n",
    "    weight_records = []\n",
    "    weight_dates = []\n",
    "\n",
    "    for d in rebalance_days:\n",
    "        # Use data strictly before the rebalance date\n",
    "        hist = rets.loc[:d].iloc[:-1]\n",
    "        if len(hist) < cfg.min_lookback_days:\n",
    "            continue\n",
    "\n",
    "        # Use the last lookback_days history if available\n",
    "        hist_window = hist.tail(cfg.lookback_days)\n",
    "        if hist_window.isnull().all().all():\n",
    "            continue\n",
    "\n",
    "        cov = hist_window.cov()\n",
    "        corr = hist_window.corr()\n",
    "\n",
    "        order = greedy_correlation_sort(corr)\n",
    "        w = hrp_weights(cov, order)\n",
    "        # Ensure all symbols present\n",
    "        w_full = pd.Series(0.0, index=symbols)\n",
    "        for sym in w.index:\n",
    "            w_full[sym] = float(w[sym])\n",
    "        weight_records.append(w_full.values)\n",
    "        weight_dates.append(d)\n",
    "\n",
    "    if not weight_records:\n",
    "        # Fallback: equal-weight if HRP never computed\n",
    "        print(\"[WARN] No HRP rebalances computed; defaulting to equal-weight.\")\n",
    "        w_eq = np.ones(len(symbols)) / len(symbols)\n",
    "        W = pd.DataFrame([w_eq], index=[dates[0]], columns=symbols)\n",
    "        W = W.reindex(dates).ffill()\n",
    "        return W\n",
    "\n",
    "    W_reb = pd.DataFrame(weight_records, index=weight_dates, columns=symbols)\n",
    "    # Forward-fill between rebalance dates\n",
    "    W = W_reb.reindex(dates).ffill()\n",
    "    return W\n",
    "\n",
    "\n",
    "# --------------------- Portfolio construction ------------------- #\n",
    "\n",
    "\n",
    "def build_portfolio(\n",
    "    cfg: Config,\n",
    "    prices: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Build HRP portfolio and equal-weight benchmark.\n",
    "\n",
    "    Returns:\n",
    "        out_df : combined DataFrame with prices, returns, weights, portfolio returns\n",
    "        summary: dict with HRP weights and performance metrics\n",
    "    \"\"\"\n",
    "    symbols = list(prices.columns)\n",
    "    rets = prices.pct_change().dropna()\n",
    "    aligned_prices = prices.reindex(rets.index)\n",
    "\n",
    "    # 1) HRP weights path\n",
    "    W_hrp = compute_hrp_weight_path(cfg, rets)\n",
    "\n",
    "    # 2) HRP portfolio returns\n",
    "    port_ret_hrp = (W_hrp * rets).sum(axis=1)\n",
    "    port_ret_hrp.name = \"port_ret_hrp\"\n",
    "\n",
    "    # 3) Equal-weight long-only benchmark (daily rebalanced)\n",
    "    ew_weights = np.full(len(symbols), 1.0 / len(symbols), dtype=float)\n",
    "    port_ret_ew = pd.Series(\n",
    "        rets.values @ ew_weights,\n",
    "        index=rets.index,\n",
    "        name=\"port_ret_ew\",\n",
    "    )\n",
    "\n",
    "    # 4) Build wide outputs\n",
    "    prices_wide = aligned_prices.add_prefix(\"px_\")\n",
    "    rets_wide = rets.add_prefix(\"ret_\")\n",
    "    weights_wide = W_hrp.add_prefix(\"w_\")\n",
    "\n",
    "    out_df = pd.concat(\n",
    "        [\n",
    "            prices_wide,\n",
    "            rets_wide,\n",
    "            weights_wide,\n",
    "            port_ret_hrp,\n",
    "            port_ret_ew,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # 5) Performance stats\n",
    "    perf_hrp = annualized_stats(port_ret_hrp)\n",
    "    perf_ew = annualized_stats(port_ret_ew)\n",
    "\n",
    "    latest_weights = W_hrp.iloc[-1].to_dict()\n",
    "\n",
    "    summary = {\n",
    "        \"universe\": symbols,\n",
    "        \"start\": str(out_df.index.min().date()),\n",
    "        \"end\": str(out_df.index.max().date()),\n",
    "        \"rebalance_freq\": cfg.rebalance_freq,\n",
    "        \"lookback_days\": cfg.lookback_days,\n",
    "        \"latest_hrp_weights\": latest_weights,\n",
    "        \"performance\": {\n",
    "            \"hrp\": perf_hrp,\n",
    "            \"equal_weight\": perf_ew,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return out_df, summary\n",
    "\n",
    "\n",
    "# ----------------------------- Main ----------------------------- #\n",
    "\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    # 1) Load prices\n",
    "    prices = load_price_series(cfg)\n",
    "    print(\n",
    "        f\"[INFO] Loaded prices for {cfg.symbols} from \"\n",
    "        f\"{prices.index.min().date()} to {prices.index.max().date()} \"\n",
    "        f\"(n={len(prices)})\"\n",
    "    )\n",
    "\n",
    "    # 2) Build portfolio\n",
    "    out_df, summary = build_portfolio(cfg, prices)\n",
    "\n",
    "    # 3) Save CSV\n",
    "    out_df.to_csv(cfg.out_csv)\n",
    "    print(f\"[OK] Saved daily portfolio data -> {cfg.out_csv}\")\n",
    "\n",
    "    # 4) Save JSON summary\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[OK] Saved summary -> {cfg.out_json}\")\n",
    "\n",
    "    # 5) Print quick stats\n",
    "    print(\"\\n[SUMMARY — Annualized stats]\")\n",
    "    hrp = summary[\"performance\"][\"hrp\"]\n",
    "    ew = summary[\"performance\"][\"equal_weight\"]\n",
    "    print(\n",
    "        \"  HRP: \"\n",
    "        f\"CAGR={hrp['cagr']:.2%}, Vol={hrp['vol']:.2%}, \"\n",
    "        f\"Sharpe={hrp['sharpe']:.2f}, MaxDD={hrp['max_drawdown']:.2%}\"\n",
    "    )\n",
    "    print(\n",
    "        \"  EW : \"\n",
    "        f\"CAGR={ew['cagr']:.2%}, Vol={ew['vol']:.2%}, \"\n",
    "        f\"Sharpe={ew['sharpe']:.2f}, MaxDD={ew['max_drawdown']:.2%}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter-safe: strip any unwanted args like \"-f kernel-xxxx.json\"\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-04 to 2025-12-02 (n=4004)\n",
      "[OK] Saved daily portfolio data -> level60_hrp_portfolio.csv\n",
      "[OK] Saved summary -> level60_hrp_summary.json\n",
      "\n",
      "[SUMMARY — Annualized stats]\n",
      "  HRP: CAGR=5.83%, Vol=7.81%, Sharpe=0.75, MaxDD=-24.77%\n",
      "  EW : CAGR=9.37%, Vol=11.93%, Sharpe=0.79, MaxDD=-26.28%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
