{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T02:30:06.531039Z",
     "start_time": "2025-11-10T02:30:05.422379Z"
    }
   },
   "source": [
    "# level40_pca_residuals_stat_arb.py\n",
    "# Python-only, free data (yfinance). PCA residual mean-reversion across a basket.\n",
    "# Outputs:\n",
    "#   - CSV:  level40_timeseries.csv  (prices, returns, residual_z, weights, returns_gross/net, etc.)\n",
    "#   - JSON: level40_metrics.json    (CAGR, Vol, Sharpe, MaxDD) + diagnostics (K, EVR)\n",
    "# Usage:\n",
    "#   python level40_pca_residuals_stat_arb.py\n",
    "\n",
    "import numpy as np\n",
    "#Update\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    start: str = \"2007-01-01\"\n",
    "    end: Optional[str] = None\n",
    "    # Liquid, diverse ETF basket by default; replace with your equities universe if desired.\n",
    "    tickers: Tuple[str, ...] = (\n",
    "        \"SPY\",\"QQQ\",\"IWM\",\"EFA\",\"EEM\",\n",
    "        \"XLB\",\"XLE\",\"XLF\",\"XLI\",\"XLK\",\"XLP\",\"XLU\",\"XLV\",\"XLY\",\"XLC\",\n",
    "        \"IYR\",\"IYT\",\"XME\",\"GDX\",\"USO\",\"UNG\",\"GLD\",\"SLV\"\n",
    "    )\n",
    "    auto_adjust: bool = True\n",
    "    rf_proxy: str = \"BIL\"               # optional, unused in returns but handy for expansions\n",
    "    win_pca: int = 252                  # PCA fit window (trading days)\n",
    "    refit_freq: str = \"M\"               # refit PCA monthly\n",
    "    evr_target: float = 0.75            # cumulative explained variance target\n",
    "    k_max: int = 8                      # cap number of PCs\n",
    "    z_enter: float = 1.0                # soft threshold: only trade names with |z| >= z_enter\n",
    "    gross_target: float = 1.0           # target gross exposure (sum |w_i|)\n",
    "    w_cap: float = 0.10                 # per-name absolute weight cap\n",
    "    vol_win: int = 60                   # lookback for per-asset vol scaling\n",
    "    tc_bps: float = 0.0002              # 2 bps per |Δw| per name when weights change\n",
    "    seed: int = 7\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# ----------------------------- Data Utils -----------------------------\n",
    "def load_adjusted_close(tickers, start, end=None, auto_adjust=True) -> pd.DataFrame:\n",
    "    raw = yf.download(tickers, start=start, end=end, auto_adjust=auto_adjust, progress=False)\n",
    "    price_key = \"Close\" if auto_adjust else \"Adj Close\"\n",
    "    if isinstance(raw.columns, pd.MultiIndex):\n",
    "        out = raw[price_key].copy()\n",
    "    else:\n",
    "        # single ticker shape -> normalize\n",
    "        name = tickers if isinstance(tickers, str) else tickers[0]\n",
    "        out = raw[[price_key]].rename(columns={price_key: name})\n",
    "    # keep only those that actually downloaded\n",
    "    have = [c for c in (tickers if isinstance(tickers, (list, tuple)) else [tickers]) if c in out.columns]\n",
    "    out = out.reindex(columns=have)\n",
    "    # drop columns that are all NaN\n",
    "    out = out.dropna(axis=1, how=\"all\")\n",
    "    return out\n",
    "\n",
    "def align_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # drop rows with all NaNs, forward-fill occasional gaps, then drop still-NaN rows\n",
    "    df = df.sort_index()\n",
    "    df = df.ffill().dropna(how=\"any\")  # require full panel for PCA window\n",
    "    return df\n",
    "\n",
    "# ----------------------------- Metrics -----------------------------\n",
    "def kpis(port_daily: pd.Series) -> Dict[str, float]:\n",
    "    x = port_daily.dropna()\n",
    "    if len(x) < 2:\n",
    "        return {\"CAGR\": np.nan, \"Vol\": np.nan, \"Sharpe\": np.nan, \"MaxDD\": np.nan}\n",
    "    eq = (1 + x).cumprod()\n",
    "    cagr = eq.iloc[-1]**(252/len(x)) - 1\n",
    "    vol = x.std()*np.sqrt(252)\n",
    "    sharpe = (x.mean()*252)/(vol + 1e-12)\n",
    "    mdd = (eq/eq.cummax() - 1).min()\n",
    "    return {\"CAGR\": float(cagr), \"Vol\": float(vol), \"Sharpe\": float(sharpe), \"MaxDD\": float(mdd)}\n",
    "\n",
    "# ----------------------------- PCA Helpers -----------------------------\n",
    "def fit_pca(window_rets: pd.DataFrame, evr_target: float, k_max: int) -> Dict:\n",
    "    \"\"\"Standardize columns, fit PCA, choose K by cumulative EVR or k_max.\"\"\"\n",
    "    # standardize across time: mean/σ per asset on the window\n",
    "    mu = window_rets.mean(axis=0)\n",
    "    sig = window_rets.std(axis=0).replace(0, np.nan)\n",
    "    Z = (window_rets - mu) / (sig + 1e-12)\n",
    "    Z = Z.fillna(0.0)\n",
    "\n",
    "    pca_full = PCA(n_components=min(k_max, Z.shape[1]))\n",
    "    pca_full.fit(Z.values)\n",
    "    evr = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    K = int(np.searchsorted(evr, evr_target) + 1)\n",
    "    K = int(np.clip(K, 1, min(k_max, Z.shape[1])))\n",
    "\n",
    "    # re-fit with K (scikit can just slice components/evr)\n",
    "    comps = pca_full.components_[:K, :]        # shape: (K, N)\n",
    "    evr_used = pca_full.explained_variance_ratio_[:K].sum()\n",
    "\n",
    "    return {\n",
    "        \"mu\": mu, \"sig\": sig,\n",
    "        \"components\": pd.DataFrame(comps, columns=window_rets.columns, index=[f\"PC{i+1}\" for i in range(K)]),\n",
    "        \"K\": K, \"evr_sum\": float(evr_used)\n",
    "    }\n",
    "\n",
    "def infer_residual_z(day_rets: pd.Series, model: Dict) -> pd.Series:\n",
    "    \"\"\"Standardize with stored (μ,σ), project to components, reconstruct, return residual z per asset.\"\"\"\n",
    "    cols = model[\"components\"].columns\n",
    "    # align\n",
    "    x = day_rets.reindex(cols)\n",
    "    z = (x - model[\"mu\"]) / (model[\"sig\"] + 1e-12)\n",
    "    z = z.fillna(0.0)\n",
    "\n",
    "    C = model[\"components\"].values            # (K, N)\n",
    "    scores = z.values @ C.T                   # (K,)\n",
    "    z_hat = scores @ C                        # (N,)\n",
    "    resid_z = z.values - z_hat\n",
    "    return pd.Series(resid_z, index=cols)\n",
    "\n",
    "# ----------------------------- Strategy Core -----------------------------\n",
    "def build_pca_stat_arb(cfg: Config):\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    # 1) Prices & returns\n",
    "    px = load_adjusted_close(list(cfg.tickers), start=cfg.start, end=cfg.end, auto_adjust=cfg.auto_adjust)\n",
    "    if px.shape[1] < 5:\n",
    "        raise ValueError(\"Too few tickers downloaded. Please supply a larger liquid universe.\")\n",
    "    px = align_index(px)\n",
    "    rets = np.log(px).diff().dropna()\n",
    "\n",
    "    # 2) Monthly fit points (refit PCA)\n",
    "    fit_dates = rets.resample(cfg.refit_freq).last().index\n",
    "    fit_dates = fit_dates[fit_dates >= (rets.index[0] + pd.tseries.offsets.BDay(cfg.win_pca))]\n",
    "\n",
    "    models = {}         # date -> PCA model dict\n",
    "    K_series = pd.Series(index=rets.index, dtype=float)\n",
    "    EVR_series = pd.Series(index=rets.index, dtype=float)\n",
    "\n",
    "    for d in fit_dates:\n",
    "        w_end = d\n",
    "        w_beg = rets.index[rets.index.get_loc(d, method=\"pad\") - cfg.win_pca + 1]\n",
    "        window = rets.loc[w_beg:w_end]\n",
    "        mdl = fit_pca(window, cfg.evr_target, cfg.k_max)\n",
    "        models[d] = mdl\n",
    "        # store diagnostics at fit timestamp\n",
    "        K_series.loc[d] = mdl[\"K\"]\n",
    "        EVR_series.loc[d] = mdl[\"evr_sum\"]\n",
    "\n",
    "    # 3) Forward daily inference using last available model\n",
    "    resid_z_all = pd.DataFrame(index=rets.index, columns=rets.columns, dtype=float)\n",
    "    last_fit = None\n",
    "    model_dates = sorted(models.keys())\n",
    "    m_idx = 0\n",
    "\n",
    "    for t in rets.index:\n",
    "        while m_idx < len(model_dates) and model_dates[m_idx] <= t:\n",
    "            last_fit = model_dates[m_idx]\n",
    "            m_idx += 1\n",
    "        if last_fit is None:\n",
    "            continue\n",
    "        mdl = models[last_fit]\n",
    "        resid_z_all.loc[t] = infer_residual_z(rets.loc[t], mdl)\n",
    "\n",
    "        # forward-fill diagnostics\n",
    "        if np.isnan(K_series.loc[t]) and not np.isnan(K_series.loc[last_fit]):\n",
    "            K_series.loc[t] = K_series.loc[last_fit]\n",
    "        if np.isnan(EVR_series.loc[t]) and not np.isnan(EVR_series.loc[last_fit]):\n",
    "            EVR_series.loc[t] = EVR_series.loc[last_fit]\n",
    "\n",
    "    resid_z_all = resid_z_all.dropna(how=\"all\")\n",
    "\n",
    "    # 4) Build weights from residual z (mean-reversion), with vol scaling and constraints\n",
    "    vol = rets.rolling(cfg.vol_win).std().replace(0, np.nan)\n",
    "    vol = vol.reindex_like(rets)\n",
    "\n",
    "    raw_w = (-resid_z_all / (vol + 1e-12)).replace([np.inf, -np.inf], 0.0)\n",
    "    # Soft threshold: zero-out small |z|\n",
    "    mask = resid_z_all.abs() >= cfg.z_enter\n",
    "    raw_w = raw_w.where(mask, 0.0)\n",
    "\n",
    "    # Dollar-neutralize per day: subtract cross-sectional mean\n",
    "    raw_w = raw_w.sub(raw_w.mean(axis=1), axis=0).fillna(0.0)\n",
    "\n",
    "    # Clip per-name weight\n",
    "    raw_w = raw_w.clip(lower=-cfg.w_cap, upper=cfg.w_cap)\n",
    "\n",
    "    # Normalize to target gross\n",
    "    gross = raw_w.abs().sum(axis=1).replace(0, np.nan)\n",
    "    scale = (cfg.gross_target / gross).clip(upper=5.0)  # guard huge scale\n",
    "    w = (raw_w.T * scale).T.fillna(0.0)\n",
    "\n",
    "    # 5) Portfolio returns & transaction costs\n",
    "    port_ret_gross = (w.shift().fillna(0.0) * rets.reindex_like(w)).sum(axis=1)\n",
    "    turn = (w - w.shift()).abs().sum(axis=1).fillna(0.0)\n",
    "    tc = cfg.tc_bps * turn\n",
    "    port_ret_net = port_ret_gross - tc\n",
    "\n",
    "    # 6) Outputs\n",
    "    metrics = {\"Strategy\": kpis(port_ret_net)}\n",
    "    diag = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"avg_K\": float(pd.Series(K_series).dropna().mean()) if len(pd.Series(K_series).dropna()) else None,\n",
    "        \"avg_EVR\": float(pd.Series(EVR_series).dropna().mean()) if len(pd.Series(EVR_series).dropna()) else None,\n",
    "        \"first_fit\": str(model_dates[0].date()) if model_dates else None,\n",
    "        \"last_fit\": str(model_dates[-1].date()) if model_dates else None\n",
    "    }\n",
    "\n",
    "    out = pd.concat({\n",
    "        \"price\": px.reindex(w.index),\n",
    "        \"ret\": rets.reindex(w.index),\n",
    "        \"resid_z\": resid_z_all.reindex(w.index),\n",
    "        \"weight\": w,\n",
    "        \"port\": pd.DataFrame({\"ret_gross\": port_ret_gross, \"turnover\": turn, \"tc\": tc, \"ret_net\": port_ret_net})\n",
    "    }, axis=1)\n",
    "\n",
    "    return out.dropna(how=\"all\"), metrics, diag\n",
    "\n",
    "def main():\n",
    "    out, metrics, diag = build_pca_stat_arb(CFG)\n",
    "\n",
    "    ts_path = \"level40_timeseries.csv\"\n",
    "    m_path  = \"level40_metrics.json\"\n",
    "    d_path  = \"level40_diagnostics.json\"\n",
    "\n",
    "    out.to_csv(ts_path)\n",
    "    with open(m_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    with open(d_path, \"w\") as f:\n",
    "        json.dump(diag, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved timeseries  → {ts_path}\")\n",
    "    print(f\"[OK] Saved metrics    → {m_path}\")\n",
    "    print(f\"[OK] Saved diagnostics→ {d_path}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: \", {kk: round(vv, 4) if vv==vv else None for kk, vv in v.items()})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8s/_qhns1b148d2wch_g7l_w5qh0000gn/T/ipykernel_12247/3971126927.py:130: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  fit_dates = rets.resample(cfg.refit_freq).last().index\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DatetimeIndex.get_loc() got an unexpected keyword argument 'method'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 236\u001B[0m\n\u001B[1;32m    233\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m, {kk: \u001B[38;5;28mround\u001B[39m(vv, \u001B[38;5;241m4\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m vv\u001B[38;5;241m==\u001B[39mvv \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m kk, vv \u001B[38;5;129;01min\u001B[39;00m v\u001B[38;5;241m.\u001B[39mitems()})\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 236\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 217\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmain\u001B[39m():\n\u001B[0;32m--> 217\u001B[0m     out, metrics, diag \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_pca_stat_arb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCFG\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m     ts_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlevel40_timeseries.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    220\u001B[0m     m_path  \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlevel40_metrics.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "Cell \u001B[0;32mIn[6], line 139\u001B[0m, in \u001B[0;36mbuild_pca_stat_arb\u001B[0;34m(cfg)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m fit_dates:\n\u001B[1;32m    138\u001B[0m     w_end \u001B[38;5;241m=\u001B[39m d\n\u001B[0;32m--> 139\u001B[0m     w_beg \u001B[38;5;241m=\u001B[39m rets\u001B[38;5;241m.\u001B[39mindex[\u001B[43mrets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m cfg\u001B[38;5;241m.\u001B[39mwin_pca \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    140\u001B[0m     window \u001B[38;5;241m=\u001B[39m rets\u001B[38;5;241m.\u001B[39mloc[w_beg:w_end]\n\u001B[1;32m    141\u001B[0m     mdl \u001B[38;5;241m=\u001B[39m fit_pca(window, cfg\u001B[38;5;241m.\u001B[39mevr_target, cfg\u001B[38;5;241m.\u001B[39mk_max)\n",
      "\u001B[0;31mTypeError\u001B[0m: DatetimeIndex.get_loc() got an unexpected keyword argument 'method'"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
