{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T01:45:14.481229Z",
     "start_time": "2025-12-05T01:45:06.372351Z"
    }
   },
   "source": [
    "# level63_dd_aware_leverage.py\n",
    "#\n",
    "# Level-63: Dynamic Drawdown-Aware Leverage Overlay\n",
    "#\n",
    "# Core idea:\n",
    "#   1) Build a shrinkage-based covariance matrix on rolling windows.\n",
    "#   2) Compute risk-parity + min-var blended weights for a multi-asset universe.\n",
    "#   3) Backtest a baseline (unlevered) portfolio.\n",
    "#   4) Apply a dynamic leverage overlay:\n",
    "#        - Vol targeting: scale exposure so that realized vol is near target_vol.\n",
    "#        - Drawdown brake: reduce leverage when drawdown exceeds thresholds.\n",
    "#\n",
    "# Universe: (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "# Data: yfinance daily, auto-adjusted close.\n",
    "#\n",
    "# Example usage:\n",
    "#   python level63_dd_aware_leverage.py\n",
    "#   python level63_dd_aware_leverage.py --start 2010-01-01 --target-vol 0.12\n",
    "#\n",
    "# Outputs:\n",
    "#   - level63_dd_leverage_series.csv\n",
    "#   - level63_dd_leverage_summary.json\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ------------------------- Config ------------------------- #\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "    rebalance_freq: str = \"ME\"          # month-end\n",
    "    cov_lookback: int = 252            # trading days for covariance\n",
    "    min_hist: int = 252                # minimum history before first weight\n",
    "    shrink_alpha: float = 0.30         # 0=no shrink; 1=diagonal only\n",
    "    alpha_minvar: float = 0.30         # blend: w = (1-a)*RP + a*MinVar\n",
    "\n",
    "    # Vol-target + drawdown overlay\n",
    "    vol_lookback: int = 60             # days for realized vol estimate\n",
    "    target_vol: float = 0.12           # annual vol target (e.g. 12%)\n",
    "    lev_min: float = 0.3               # minimum leverage\n",
    "    lev_max: float = 2.0               # maximum leverage\n",
    "\n",
    "    dd_threshold1: float = 0.10        # drawdown level 1 (10%)\n",
    "    dd_threshold2: float = 0.25        # drawdown level 2 (25%)\n",
    "    dd_min_scale: float = 0.3          # when dd >= dd_threshold2\n",
    "\n",
    "    out_csv: str = \"level63_dd_leverage_series.csv\"\n",
    "    out_json: str = \"level63_dd_leverage_summary.json\"\n",
    "    seed: int = 42                     # for reproducibility\n",
    "\n",
    "\n",
    "# ------------------------- Data Loading ------------------------- #\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily close prices per symbol as a clean wide DataFrame.\n",
    "    Handles both Series and DataFrame returns from yfinance (multi-index quirks).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No data returned for symbol {s}. Check ticker or internet.\")\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"'Close' column missing for {s}.\")\n",
    "\n",
    "        close_obj = px[\"Close\"]\n",
    "\n",
    "        # yfinance sometimes returns DataFrame for \"Close\" even for single ticker\n",
    "        if isinstance(close_obj, pd.Series):\n",
    "            close = close_obj.rename(s)\n",
    "        else:\n",
    "            # DataFrame: pick first column and convert to Series\n",
    "            col0 = close_obj.columns[0]\n",
    "            close = pd.Series(\n",
    "                close_obj[col0].values,\n",
    "                index=close_obj.index,\n",
    "                name=s,\n",
    "            )\n",
    "\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"any\")  # require all assets present each day\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Log returns for each asset.\"\"\"\n",
    "    return np.log(prices).diff().dropna()\n",
    "\n",
    "\n",
    "# ------------------------- Covariance & Weights ------------------------- #\n",
    "\n",
    "def shrinkage_cov(rets: pd.DataFrame, alpha: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simple shrinkage towards diagonal:\n",
    "        Sigma_shrunk = (1-alpha)*Sigma + alpha*diag(Sigma)\n",
    "    \"\"\"\n",
    "    sigma = rets.cov()\n",
    "    if alpha <= 0.0:\n",
    "        return sigma\n",
    "    diag_vals = np.diag(np.diag(sigma.values))\n",
    "    prior = pd.DataFrame(diag_vals, index=sigma.index, columns=sigma.columns)\n",
    "    shrunk = (1.0 - alpha) * sigma + alpha * prior\n",
    "    return shrunk\n",
    "\n",
    "\n",
    "def risk_parity_weights(cov: pd.DataFrame,\n",
    "                        max_iter: int = 1000,\n",
    "                        tol: float = 1e-8) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Approximate equal risk contribution (risk parity) weights.\n",
    "    \"\"\"\n",
    "    assets = list(cov.index)\n",
    "    n = len(assets)\n",
    "    C = cov.values\n",
    "    w = np.ones(n) / n\n",
    "    b = np.ones(n) / n  # equal risk budgets\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        port_var = float(w @ C @ w)\n",
    "        if port_var <= 0:\n",
    "            break\n",
    "        mrc = C @ w                  # marginal risk contributions\n",
    "        rc = w * mrc                 # component risk contributions\n",
    "        target_rc = b * port_var\n",
    "        diff = rc - target_rc\n",
    "        if np.max(np.abs(diff)) < tol:\n",
    "            break\n",
    "        # multiplicative update, avoid division by zero\n",
    "        w *= target_rc / (rc + 1e-12)\n",
    "        w = np.maximum(w, 0.0)\n",
    "        s = w.sum()\n",
    "        if s <= 0:\n",
    "            w = np.ones(n) / n\n",
    "        else:\n",
    "            w /= s\n",
    "\n",
    "    return pd.Series(w, index=assets, name=\"w_rp\")\n",
    "\n",
    "\n",
    "def minvar_weights(cov: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Minimum variance weights under sum=1, w>=0, using pseudo-inverse (no constraints).\n",
    "    Negative weights are floored and re-normalized.\n",
    "    \"\"\"\n",
    "    assets = list(cov.index)\n",
    "    C = cov.values\n",
    "    n = len(assets)\n",
    "    inv = np.linalg.pinv(C)\n",
    "    ones = np.ones((n, 1))\n",
    "    raw = inv @ ones\n",
    "    w = raw[:, 0]\n",
    "    w = np.maximum(w, 0.0)\n",
    "    s = w.sum()\n",
    "    if s <= 0:\n",
    "        w = np.ones(n) / n\n",
    "    else:\n",
    "        w /= s\n",
    "    return pd.Series(w, index=assets, name=\"w_minvar\")\n",
    "\n",
    "\n",
    "def build_rebalance_schedule(rets: pd.DataFrame, cfg: Config) -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Rebalance at freq (month-end by default).\n",
    "    \"\"\"\n",
    "    freq = cfg.rebalance_freq\n",
    "    # Backwards-compat shim: treat \"M\" as \"ME\"\n",
    "    if freq.upper() == \"M\":\n",
    "        freq = \"ME\"\n",
    "\n",
    "    idx = rets.resample(freq).last().index\n",
    "    idx = idx[idx >= rets.index[0]]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def compute_weight_path(rets: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each rebalance date, estimate covariance on trailing window,\n",
    "    compute RP and MinVar weights, and blend.\n",
    "    Returns a DataFrame of weights indexed by rebalance dates.\n",
    "    \"\"\"\n",
    "    rebals = build_rebalance_schedule(rets, cfg)\n",
    "    weight_rows = []\n",
    "\n",
    "    for dt in rebals:\n",
    "        hist = rets.loc[:dt].tail(cfg.cov_lookback)\n",
    "        if len(hist) < cfg.min_hist:\n",
    "            continue\n",
    "\n",
    "        cov = shrinkage_cov(hist, cfg.shrink_alpha)\n",
    "        w_rp = risk_parity_weights(cov)\n",
    "        w_mv = minvar_weights(cov)\n",
    "        w_mix = (1.0 - cfg.alpha_minvar) * w_rp + cfg.alpha_minvar * w_mv\n",
    "        # Clean and normalize\n",
    "        w_mix = np.maximum(w_mix, 0.0)\n",
    "        s = float(w_mix.sum())\n",
    "        if s > 0:\n",
    "            w_mix /= s\n",
    "        w_mix.name = dt\n",
    "        weight_rows.append(w_mix)\n",
    "\n",
    "    if not weight_rows:\n",
    "        raise RuntimeError(\"No weights computed. Check start date and cov_lookback/min_hist.\")\n",
    "    W = pd.DataFrame(weight_rows)\n",
    "    return W\n",
    "\n",
    "\n",
    "def expand_weights_to_daily(W: pd.DataFrame, rets: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Forward-fill rebalance weights to daily frequency.\n",
    "    Aligns returns to the same index.\n",
    "    \"\"\"\n",
    "    W_daily = W.reindex(rets.index, method=\"ffill\")\n",
    "    # Drop any leading rows before first weight\n",
    "    first_valid = W_daily.dropna(how=\"all\").index[0]\n",
    "    W_daily = W_daily.loc[first_valid:]\n",
    "    rets_aligned = rets.loc[W_daily.index]\n",
    "    return W_daily, rets_aligned\n",
    "\n",
    "\n",
    "# ------------------------- Portfolio & Overlay ------------------------- #\n",
    "\n",
    "def portfolio_returns(weights: pd.DataFrame, rets: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Daily portfolio returns from weights and asset returns.\"\"\"\n",
    "    cols = [c for c in weights.columns if c in rets.columns]\n",
    "    W = weights[cols]\n",
    "    R = rets[cols]\n",
    "    port_ret = (W * R).sum(axis=1)\n",
    "    port_ret.name = \"ret_port_base\"\n",
    "    return port_ret\n",
    "\n",
    "\n",
    "def equity_curve(rets: pd.Series, start_equity: float = 1.0) -> pd.Series:\n",
    "    \"\"\"Equity curve from returns.\"\"\"\n",
    "    eq = (rets + 1.0).cumprod() * float(start_equity)\n",
    "    eq.name = \"equity\"\n",
    "    return eq\n",
    "\n",
    "\n",
    "def drawdown_series(eq: pd.Series) -> Tuple[pd.Series, float]:\n",
    "    \"\"\"Drawdown time series and max drawdown.\"\"\"\n",
    "    roll_max = eq.cummax()\n",
    "    dd = eq / roll_max - 1.0\n",
    "    dd.name = \"drawdown\"\n",
    "    max_dd = float(dd.min())\n",
    "    return dd, max_dd\n",
    "\n",
    "\n",
    "def realized_vol_annual(rets: pd.Series, lookback: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling realized annualized volatility using a simple window std.\n",
    "    \"\"\"\n",
    "    vol_daily = rets.rolling(lookback).std(ddof=0)\n",
    "    vol_ann = vol_daily * math.sqrt(252.0)\n",
    "    vol_ann.name = \"vol_ann\"\n",
    "    return vol_ann\n",
    "\n",
    "\n",
    "def dd_scale_factor(dd: float,\n",
    "                    dd1: float,\n",
    "                    dd2: float,\n",
    "                    min_scale: float) -> float:\n",
    "    \"\"\"\n",
    "    Piecewise-linear drawdown scaling:\n",
    "      - dd <= dd1         -> scale = 1\n",
    "      - dd >= dd2         -> scale = min_scale\n",
    "      - dd1 < dd < dd2    -> linear between 1 and min_scale\n",
    "    dd is positive, e.g. 0.12 for 12% drawdown.\n",
    "    \"\"\"\n",
    "    if dd <= dd1:\n",
    "        return 1.0\n",
    "    if dd >= dd2:\n",
    "        return min_scale\n",
    "    frac = (dd2 - dd) / max(dd2 - dd1, 1e-8)\n",
    "    return min_scale + (1.0 - min_scale) * frac\n",
    "\n",
    "\n",
    "def apply_dynamic_leverage(port_ret: pd.Series, cfg: Config) -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Apply leverage L_t = L_vol_t * f(drawdown_t) sequentially.\n",
    "    - L_vol_t from vol targeting.\n",
    "    - f(drawdown_t) from dd_scale_factor.\n",
    "    Returns leveraged returns, equity, leverage series, drawdown, and max drawdown.\n",
    "    \"\"\"\n",
    "    # Vol-target component, based on unlevered returns\n",
    "    vol_ann = realized_vol_annual(port_ret, cfg.vol_lookback)\n",
    "    lev_vol = cfg.target_vol / vol_ann\n",
    "    # Bound and handle early NaNs\n",
    "    lev_vol = lev_vol.clip(lower=cfg.lev_min, upper=cfg.lev_max)\n",
    "    lev_vol = lev_vol.replace([np.inf, -np.inf], np.nan).fillna(1.0)\n",
    "\n",
    "    lev_series = []\n",
    "    ret_lev = []\n",
    "    eq_series = []\n",
    "\n",
    "    eq = 1.0\n",
    "    peak = 1.0\n",
    "\n",
    "    for dt, r in port_ret.items():\n",
    "        # current drawdown from equity path so far\n",
    "        dd = (peak - eq) / peak if peak > 0 else 0.0\n",
    "        dd_factor = dd_scale_factor(dd, cfg.dd_threshold1, cfg.dd_threshold2, cfg.dd_min_scale)\n",
    "\n",
    "        L_vol = float(lev_vol.loc[dt]) if dt in lev_vol.index else 1.0\n",
    "        L = L_vol * dd_factor\n",
    "        L = max(cfg.lev_min, min(cfg.lev_max, L))\n",
    "\n",
    "        r_lev = L * float(r)\n",
    "        eq *= (1.0 + r_lev)\n",
    "        peak = max(peak, eq)\n",
    "\n",
    "        lev_series.append(L)\n",
    "        ret_lev.append(r_lev)\n",
    "        eq_series.append(eq)\n",
    "\n",
    "    idx = port_ret.index\n",
    "    lev_series = pd.Series(lev_series, index=idx, name=\"leverage\")\n",
    "    ret_lev = pd.Series(ret_lev, index=idx, name=\"ret_port_dyn\")\n",
    "    eq_series = pd.Series(eq_series, index=idx, name=\"equity_dyn\")\n",
    "\n",
    "    dd_dyn, max_dd_dyn = drawdown_series(eq_series)\n",
    "\n",
    "    return {\n",
    "        \"lev\": lev_series,\n",
    "        \"ret_dyn\": ret_lev,\n",
    "        \"eq_dyn\": eq_series,\n",
    "        \"dd_dyn\": dd_dyn,\n",
    "        \"max_dd_dyn\": max_dd_dyn,\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------- Metrics & I/O ------------------------- #\n",
    "\n",
    "def summary_stats(rets: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"Simple annualized performance stats (no RF).\"\"\"\n",
    "    if len(rets) == 0:\n",
    "        return {\"ann_ret\": 0.0, \"ann_vol\": 0.0, \"sharpe\": 0.0}\n",
    "\n",
    "    mu_daily = float(rets.mean())\n",
    "    vol_daily = float(rets.std(ddof=0))\n",
    "    ann_ret = (1.0 + mu_daily) ** 252 - 1.0\n",
    "    ann_vol = vol_daily * math.sqrt(252.0)\n",
    "    sharpe = 0.0\n",
    "    if ann_vol > 0:\n",
    "        sharpe = ann_ret / ann_vol\n",
    "    return {\n",
    "        \"ann_ret\": ann_ret,\n",
    "        \"ann_vol\": ann_vol,\n",
    "        \"sharpe\": sharpe,\n",
    "    }\n",
    "\n",
    "\n",
    "def save_outputs(df: pd.DataFrame,\n",
    "                 base_stats: Dict[str, float],\n",
    "                 base_dd: float,\n",
    "                 dyn_stats: Dict[str, float],\n",
    "                 dyn_dd: float,\n",
    "                 cfg: Config) -> None:\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    df.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"base\": {\n",
    "            \"ann_ret\": base_stats[\"ann_ret\"],\n",
    "            \"ann_vol\": base_stats[\"ann_vol\"],\n",
    "            \"sharpe\": base_stats[\"sharpe\"],\n",
    "            \"max_drawdown\": base_dd,\n",
    "        },\n",
    "        \"dynamic\": {\n",
    "            \"ann_ret\": dyn_stats[\"ann_ret\"],\n",
    "            \"ann_vol\": dyn_stats[\"ann_vol\"],\n",
    "            \"sharpe\": dyn_stats[\"sharpe\"],\n",
    "            \"max_drawdown\": dyn_dd,\n",
    "        },\n",
    "    }\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    print(\n",
    "        \"Base   : AnnRet={:.2%}, AnnVol={:.2%}, Sharpe={:.2f}, MaxDD={:.2%}\".format(\n",
    "            summary[\"base\"][\"ann_ret\"],\n",
    "            summary[\"base\"][\"ann_vol\"],\n",
    "            summary[\"base\"][\"sharpe\"],\n",
    "            summary[\"base\"][\"max_drawdown\"],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Dynamic: AnnRet={:.2%}, AnnVol={:.2%}, Sharpe={:.2f}, MaxDD={:.2%}\".format(\n",
    "            summary[\"dynamic\"][\"ann_ret\"],\n",
    "            summary[\"dynamic\"][\"ann_vol\"],\n",
    "            summary[\"dynamic\"][\"sharpe\"],\n",
    "            summary[\"dynamic\"][\"max_drawdown\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------- Pipeline ------------------------- #\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows.\")\n",
    "\n",
    "    # 1) Compute rebalance weights (shrinkage + risk parity + min-var blend)\n",
    "    W_reb = compute_weight_path(rets, cfg)\n",
    "\n",
    "    # 2) Expand to daily weights and align returns\n",
    "    W_daily, rets_aligned = expand_weights_to_daily(W_reb, rets)\n",
    "\n",
    "    # 3) Baseline (unlevered) portfolio\n",
    "    port_ret_base = portfolio_returns(W_daily, rets_aligned)\n",
    "    eq_base = equity_curve(port_ret_base, start_equity=1.0)\n",
    "    dd_base, max_dd_base = drawdown_series(eq_base)\n",
    "    stats_base = summary_stats(port_ret_base)\n",
    "\n",
    "    # 4) Dynamic leverage overlay\n",
    "    dyn = apply_dynamic_leverage(port_ret_base, cfg)\n",
    "    port_ret_dyn = dyn[\"ret_dyn\"]\n",
    "    eq_dyn = dyn[\"eq_dyn\"]\n",
    "    dd_dyn = dyn[\"dd_dyn\"]\n",
    "    max_dd_dyn = dyn[\"max_dd_dyn\"]\n",
    "    stats_dyn = summary_stats(port_ret_dyn)\n",
    "\n",
    "    # 5) Assemble output DataFrame\n",
    "    out = pd.DataFrame(index=rets_aligned.index)\n",
    "    # Prices and returns\n",
    "    out[prices.columns] = prices.reindex(out.index)\n",
    "    out[[f\"ret_{c}\" for c in rets_aligned.columns]] = rets_aligned.add_prefix(\"ret_\")\n",
    "    # Weights\n",
    "    out[[f\"w_{c}\" for c in W_daily.columns]] = W_daily.add_prefix(\"w_\")\n",
    "    # Base portfolio\n",
    "    out[\"ret_port_base\"] = port_ret_base\n",
    "    out[\"equity_base\"] = eq_base\n",
    "    out[\"dd_base\"] = dd_base\n",
    "    # Dynamic overlay\n",
    "    out[\"leverage\"] = dyn[\"lev\"]\n",
    "    out[\"ret_port_dyn\"] = port_ret_dyn\n",
    "    out[\"equity_dyn\"] = eq_dyn\n",
    "    out[\"dd_dyn\"] = dd_dyn\n",
    "\n",
    "    save_outputs(out, stats_base, max_dd_base, stats_dyn, max_dd_dyn, cfg)\n",
    "\n",
    "\n",
    "# ------------------------- CLI ------------------------- #\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-63: Drawdown-aware leverage on shrinkage risk-parity portfolio\")\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\", help=\"Start date for history (YYYY-MM-DD)\")\n",
    "    p.add_argument(\"--rebalance-freq\", type=str, default=\"ME\", help=\"Pandas offset alias, e.g. ME for month-end\")\n",
    "    p.add_argument(\"--cov-lookback\", type=int, default=252)\n",
    "    p.add_argument(\"--min-hist\", type=int, default=252)\n",
    "    p.add_argument(\"--shrink-alpha\", type=float, default=0.30)\n",
    "    p.add_argument(\"--alpha-minvar\", type=float, default=0.30)\n",
    "\n",
    "    p.add_argument(\"--vol-lookback\", type=int, default=60)\n",
    "    p.add_argument(\"--target-vol\", type=float, default=0.12)\n",
    "    p.add_argument(\"--lev-min\", type=float, default=0.3)\n",
    "    p.add_argument(\"--lev-max\", type=float, default=2.0)\n",
    "\n",
    "    p.add_argument(\"--dd-threshold1\", type=float, default=0.10)\n",
    "    p.add_argument(\"--dd-threshold2\", type=float, default=0.25)\n",
    "    p.add_argument(\"--dd-min-scale\", type=float, default=0.3)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level63_dd_leverage_series.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level63_dd_leverage_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    a = p.parse_args()\n",
    "\n",
    "    return Config(\n",
    "        start=a.start,\n",
    "        rebalance_freq=a.rebalance_freq,\n",
    "        cov_lookback=a.cov_lookback,\n",
    "        min_hist=a.min_hist,\n",
    "        shrink_alpha=a.shrink_alpha,\n",
    "        alpha_minvar=a.alpha_minvar,\n",
    "        vol_lookback=a.vol_lookback,\n",
    "        target_vol=a.target_vol,\n",
    "        lev_min=a.lev_min,\n",
    "        lev_max=a.lev_max,\n",
    "        dd_threshold1=a.dd_threshold1,\n",
    "        dd_threshold2=a.dd_threshold2,\n",
    "        dd_min_scale=a.dd_min_scale,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / IPython shim to ignore \"-f\" kernel args\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4006 price rows, 4005 return rows.\n",
      "[OK] Saved daily series → level63_dd_leverage_series.csv\n",
      "[OK] Saved summary → level63_dd_leverage_summary.json\n",
      "Base   : AnnRet=7.41%, AnnVol=11.21%, Sharpe=0.66, MaxDD=-30.35%\n",
      "Dynamic: AnnRet=9.49%, AnnVol=11.21%, Sharpe=0.85, MaxDD=-23.07%\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
