{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T00:40:27.437276Z",
     "start_time": "2025-12-16T00:40:13.661778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# level78_copula_scenarios.py\n",
    "# Multi-Asset Gaussian Copula Scenario Engine\n",
    "# -------------------------------------------\n",
    "# - Downloads daily prices via yfinance\n",
    "# - Builds empirical daily return distribution for each asset\n",
    "# - Calibrates a Gaussian copula on the joint returns\n",
    "# - Simulates joint scenarios:\n",
    "#       * Draw correlated normals ~ N(0, Corr)\n",
    "#       * Map to uniforms via Φ (normal CDF)\n",
    "#       * Map uniforms to empirical quantiles for each asset (non-parametric marginals)\n",
    "# - Builds portfolio equity paths from simulated returns\n",
    "# - Outputs:\n",
    "#       * CSV: portfolio equity paths\n",
    "#       * CSV: per-path risk stats\n",
    "#       * JSON: overall summary\n",
    "#\n",
    "# Example\n",
    "#   python level78_copula_scenarios.py \\\n",
    "#       --symbols SPY,QQQ,IWM,EFA,EEM,TLT,LQD,GLD \\\n",
    "#       --start 2010-01-01 \\\n",
    "#       --horizon-days 252 \\\n",
    "#       --n-paths 1000\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "    horizon_days: int = 252\n",
    "    n_paths: int = 1000\n",
    "    out_paths_csv: str = \"level78_copula_paths.csv\"\n",
    "    out_stats_csv: str = \"level78_copula_stats.csv\"\n",
    "    out_summary_json: str = \"level78_copula_summary.json\"\n",
    "    seed: int = 42\n",
    "    corr_shrink: float = 0.05  # small diagonal shrink for robustness\n",
    "\n",
    "\n",
    "# ----------------------------- Helpers -----------------------------\n",
    "\n",
    "def parse_symbol_string(s: str) -> Tuple[str, ...]:\n",
    "    parts = [p.strip().upper() for p in s.split(\",\") if p.strip()]\n",
    "    if not parts:\n",
    "        raise ValueError(\"No symbols parsed from --symbols.\")\n",
    "    return tuple(parts)\n",
    "\n",
    "\n",
    "def load_prices(symbols: Sequence[str], start: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download adjusted close prices for given symbols from yfinance.\n",
    "    Returns a DataFrame with Date index and one column per symbol.\n",
    "    \"\"\"\n",
    "    data = yf.download(list(symbols), start=start, auto_adjust=True, progress=False)\n",
    "    if data.empty:\n",
    "        raise RuntimeError(\"No price data returned from yfinance.\")\n",
    "\n",
    "    # Handle possible MultiIndex columns (e.g. ('Adj Close','SPY'), ...)\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        cols0 = data.columns.get_level_values(0)\n",
    "        if \"Adj Close\" in cols0:\n",
    "            px = data[\"Adj Close\"]\n",
    "        elif \"Close\" in cols0:\n",
    "            px = data[\"Close\"]\n",
    "        else:\n",
    "            raise RuntimeError(\"Could not find 'Adj Close' or 'Close' in yfinance data.\")\n",
    "    else:\n",
    "        if \"Adj Close\" in data.columns:\n",
    "            px = data[\"Adj Close\"]\n",
    "        elif \"Close\" in data.columns:\n",
    "            px = data[\"Close\"]\n",
    "        else:\n",
    "            raise RuntimeError(\"Could not find 'Adj Close' or 'Close' in yfinance data.\")\n",
    "\n",
    "    # Ensure all requested symbols present\n",
    "    missing = [s for s in symbols if s not in px.columns]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing symbols in downloaded prices: {missing}\")\n",
    "\n",
    "    px = px[list(symbols)].dropna(how=\"all\")\n",
    "    px = px.ffill().dropna()\n",
    "    return px\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Log returns of adjusted close prices.\n",
    "    \"\"\"\n",
    "    rets = np.log(prices / prices.shift(1))\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna(how=\"all\")\n",
    "    rets = rets.dropna()\n",
    "    return rets\n",
    "\n",
    "\n",
    "def normal_cdf(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized approximation of Φ(x), the standard normal CDF.\n",
    "    Abramowitz-Stegun style rational approximation, good enough for Monte Carlo.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    sign = np.sign(x)\n",
    "    x_abs = np.abs(x) / math.sqrt(2.0)\n",
    "\n",
    "    # erf approximation\n",
    "    t = 1.0 / (1.0 + 0.3275911 * x_abs)\n",
    "    # Coefficients\n",
    "    a1 = 0.254829592\n",
    "    a2 = -0.284496736\n",
    "    a3 = 1.421413741\n",
    "    a4 = -1.453152027\n",
    "    a5 = 1.061405429\n",
    "    erf_approx = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * np.exp(-x_abs * x_abs)\n",
    "\n",
    "    erf_val = sign * erf_approx\n",
    "    cdf = 0.5 * (1.0 + erf_val)\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def ensure_pos_def(corr: np.ndarray, shrink: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensure correlation matrix is positive definite via diagonal shrinkage if needed.\n",
    "    \"\"\"\n",
    "    corr = np.asarray(corr, dtype=float)\n",
    "    n = corr.shape[0]\n",
    "    # Symmetrize\n",
    "    corr = 0.5 * (corr + corr.T)\n",
    "\n",
    "    # Apply small shrink toward identity\n",
    "    if shrink > 0.0:\n",
    "        corr = (1.0 - shrink) * corr + shrink * np.eye(n)\n",
    "\n",
    "    # Try Cholesky; if fails, keep increasing shrink.\n",
    "    eps = 1e-8\n",
    "    for _ in range(8):\n",
    "        try:\n",
    "            np.linalg.cholesky(corr)\n",
    "            return corr\n",
    "        except np.linalg.LinAlgError:\n",
    "            corr = corr + eps * np.eye(n)\n",
    "            eps *= 10.0\n",
    "\n",
    "    raise RuntimeError(\"Failed to obtain positive-definite correlation matrix.\")\n",
    "\n",
    "\n",
    "def empirical_inv_cdf(sample: np.ndarray, u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Empirical inverse CDF: map uniform(0,1) draws u to sample quantiles.\n",
    "    sample: 1D array of historical returns for one asset.\n",
    "    u: array of uniforms in [0,1], any shape.\n",
    "    \"\"\"\n",
    "    sample = np.asarray(sample, dtype=float)\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    # clip to avoid edge issues\n",
    "    u_clipped = np.clip(u, 1e-6, 1.0 - 1e-6)\n",
    "    flat_u = u_clipped.ravel()\n",
    "    q = np.quantile(sample, flat_u)\n",
    "    return q.reshape(u.shape)\n",
    "\n",
    "\n",
    "def max_drawdown(equity: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Max drawdown (negative number) given equity curve.\n",
    "    \"\"\"\n",
    "    equity = np.asarray(equity, dtype=float)\n",
    "    if equity.size == 0:\n",
    "        return float(\"nan\")\n",
    "    roll_max = np.maximum.accumulate(equity)\n",
    "    dd = equity / roll_max - 1.0\n",
    "    return float(dd.min())\n",
    "\n",
    "\n",
    "# ------------------- Copula Scenario Engine -----------------------\n",
    "\n",
    "def simulate_copula_paths(\n",
    "    hist_rets: pd.DataFrame,\n",
    "    horizon_days: int,\n",
    "    n_paths: int,\n",
    "    corr_shrink: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate multi-asset return paths using a Gaussian copula with empirical marginals.\n",
    "\n",
    "    hist_rets : T x N DataFrame of daily returns\n",
    "    horizon_days : number of days to simulate per path\n",
    "    n_paths : number of Monte Carlo paths\n",
    "    corr_shrink : diagonal shrinkage to stabilize correlation matrix\n",
    "\n",
    "    Returns:\n",
    "        asset_ret_paths: array (horizon_days, n_paths, N) of simulated daily returns\n",
    "        port_ret_paths:  array (horizon_days, n_paths) for an equal-weight portfolio\n",
    "    \"\"\"\n",
    "    r = hist_rets.values   # T x N\n",
    "    T_hist, N = r.shape\n",
    "\n",
    "    # Correlation matrix of historical returns\n",
    "    corr = np.corrcoef(r, rowvar=False)\n",
    "    corr_pd = ensure_pos_def(corr, shrink=corr_shrink)\n",
    "    chol = np.linalg.cholesky(corr_pd)  # N x N\n",
    "\n",
    "    # Draw independent normals and apply correlation\n",
    "    H = horizon_days\n",
    "    P = n_paths\n",
    "    Z_iid = np.random.normal(size=(H * P, N))\n",
    "    Z_corr_flat = Z_iid @ chol.T  # (H*P) x N\n",
    "    Z_corr = Z_corr_flat.reshape(H, P, N)\n",
    "\n",
    "    # Convert to uniforms via Φ\n",
    "    U = normal_cdf(Z_corr)\n",
    "\n",
    "    # Map uniforms to empirical marginals asset by asset\n",
    "    asset_ret_paths = np.empty_like(U)\n",
    "    for j in range(N):\n",
    "        asset_ret_paths[:, :, j] = empirical_inv_cdf(r[:, j], U[:, :, j])\n",
    "\n",
    "    # Equal-weight portfolio returns\n",
    "    w = np.full(N, 1.0 / N)\n",
    "    port_ret_paths = np.tensordot(asset_ret_paths, w, axes=([2], [0]))  # (H, P)\n",
    "\n",
    "    return asset_ret_paths, port_ret_paths\n",
    "\n",
    "\n",
    "def build_portfolio_equity(port_ret_paths: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert portfolio daily returns into equity curves.\n",
    "    port_ret_paths: (H, P)\n",
    "    Returns:\n",
    "        equity_paths: (H, P)\n",
    "    \"\"\"\n",
    "    H, P = port_ret_paths.shape\n",
    "    equity = np.empty((H, P), dtype=float)\n",
    "    # Start with 1.0 and compound\n",
    "    equity[0, :] = 1.0 * (1.0 + port_ret_paths[0, :])\n",
    "    for t in range(1, H):\n",
    "        equity[t, :] = equity[t - 1, :] * (1.0 + port_ret_paths[t, :])\n",
    "    return equity\n",
    "\n",
    "\n",
    "def compute_path_stats(\n",
    "    equity_paths: np.ndarray,\n",
    "    port_ret_paths: np.ndarray,\n",
    "    horizon_days: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Per-path stats: final wealth, ann_ret, ann_vol, Sharpe, max_drawdown.\n",
    "    \"\"\"\n",
    "    H, P = equity_paths.shape\n",
    "    stats = {\n",
    "        \"final_wealth\": np.empty(P, dtype=float),\n",
    "        \"ann_ret\": np.empty(P, dtype=float),\n",
    "        \"ann_vol\": np.empty(P, dtype=float),\n",
    "        \"sharpe\": np.empty(P, dtype=float),\n",
    "        \"max_drawdown\": np.empty(P, dtype=float),\n",
    "    }\n",
    "\n",
    "    for i in range(P):\n",
    "        eq = equity_paths[:, i]\n",
    "        rets = port_ret_paths[:, i]\n",
    "        final_w = float(eq[-1])\n",
    "\n",
    "        # Annualized metrics (assuming 252 trading days/year)\n",
    "        if H > 0:\n",
    "            ann_ret = final_w ** (252.0 / H) - 1.0\n",
    "        else:\n",
    "            ann_ret = float(\"nan\")\n",
    "\n",
    "        if H > 1:\n",
    "            vol = float(np.std(rets, ddof=1)) * math.sqrt(252.0)\n",
    "        else:\n",
    "            vol = float(\"nan\")\n",
    "\n",
    "        if vol > 0 and math.isfinite(ann_ret):\n",
    "            sharpe = ann_ret / vol\n",
    "        else:\n",
    "            sharpe = float(\"nan\")\n",
    "\n",
    "        mdd = max_drawdown(eq)\n",
    "\n",
    "        stats[\"final_wealth\"][i] = final_w\n",
    "        stats[\"ann_ret\"][i] = float(ann_ret)\n",
    "        stats[\"ann_vol\"][i] = float(vol)\n",
    "        stats[\"sharpe\"][i] = float(sharpe)\n",
    "        stats[\"max_drawdown\"][i] = float(mdd)\n",
    "\n",
    "    idx = [f\"path_{i}\" for i in range(P)]\n",
    "    stats_df = pd.DataFrame(stats, index=idx)\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "# ------------------------- I/O + Orchestration --------------------\n",
    "\n",
    "def save_outputs(\n",
    "    equity_paths: np.ndarray,\n",
    "    stats_df: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(cfg.out_paths_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_stats_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_summary_json) or \".\", exist_ok=True)\n",
    "\n",
    "    H, P = equity_paths.shape\n",
    "\n",
    "    # Equity paths\n",
    "    paths_index = pd.RangeIndex(start=1, stop=H + 1, step=1, name=\"t\")\n",
    "    paths_cols = [f\"path_{i}\" for i in range(P)]\n",
    "    paths_df = pd.DataFrame(equity_paths, index=paths_index, columns=paths_cols)\n",
    "    paths_df.to_csv(cfg.out_paths_csv)\n",
    "\n",
    "    # Stats\n",
    "    stats_df.to_csv(cfg.out_stats_csv)\n",
    "\n",
    "    # Summary JSON\n",
    "    fw = stats_df[\"final_wealth\"].values\n",
    "    mdd = stats_df[\"max_drawdown\"].values\n",
    "    shr = stats_df[\"sharpe\"].values\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"n_paths\": P,\n",
    "        \"horizon_days\": cfg.horizon_days,\n",
    "        \"final_wealth\": {\n",
    "            \"mean\": float(np.mean(fw)),\n",
    "            \"median\": float(np.median(fw)),\n",
    "            \"p05\": float(np.percentile(fw, 5)),\n",
    "            \"p25\": float(np.percentile(fw, 25)),\n",
    "            \"p75\": float(np.percentile(fw, 75)),\n",
    "            \"p95\": float(np.percentile(fw, 95)),\n",
    "        },\n",
    "        \"max_drawdown\": {\n",
    "            \"mean\": float(np.mean(mdd)),\n",
    "            \"median\": float(np.median(mdd)),\n",
    "            \"p05\": float(np.percentile(mdd, 5)),\n",
    "            \"p25\": float(np.percentile(mdd, 25)),\n",
    "            \"p75\": float(np.percentile(mdd, 75)),\n",
    "            \"p95\": float(np.percentile(mdd, 95)),\n",
    "        },\n",
    "        \"sharpe\": {\n",
    "            \"mean\": float(np.nanmean(shr)),\n",
    "            \"median\": float(np.nanmedian(shr)),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(cfg.out_summary_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved equity paths -> {cfg.out_paths_csv}\")\n",
    "    print(f\"[OK] Saved path stats -> {cfg.out_stats_csv}\")\n",
    "    print(f\"[OK] Saved summary -> {cfg.out_summary_json}\")\n",
    "    print(\n",
    "        \"Final wealth median={:.3f}, p05={:.3f}, p95={:.3f}\".format(\n",
    "            summary[\"final_wealth\"][\"median\"],\n",
    "            summary[\"final_wealth\"][\"p05\"],\n",
    "            summary[\"final_wealth\"][\"p95\"],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"MaxDD median={:.1f}%, mean={:.1f}%\".format(\n",
    "            100.0 * summary[\"max_drawdown\"][\"median\"],\n",
    "            100.0 * summary[\"max_drawdown\"][\"mean\"],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sharpe mean={:.2f}, median={:.2f}\".format(\n",
    "            summary[\"sharpe\"][\"mean\"],\n",
    "            summary[\"sharpe\"][\"median\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-78: Gaussian Copula Scenario Engine\")\n",
    "    p.add_argument(\n",
    "        \"--symbols\",\n",
    "        type=str,\n",
    "        default=\"SPY,QQQ,IWM,EFA,EEM,TLT,LQD,GLD\",\n",
    "        help=\"Comma-separated list of tickers.\",\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--horizon-days\", type=int, default=252)\n",
    "    p.add_argument(\"--n-paths\", type=int, default=1000)\n",
    "    p.add_argument(\"--paths-csv\", type=str, default=\"level78_copula_paths.csv\")\n",
    "    p.add_argument(\"--stats-csv\", type=str, default=\"level78_copula_stats.csv\")\n",
    "    p.add_argument(\"--summary-json\", type=str, default=\"level78_copula_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--corr-shrink\", type=float, default=0.05)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    symbols = parse_symbol_string(a.symbols)\n",
    "    return Config(\n",
    "        symbols=symbols,\n",
    "        start=a.start,\n",
    "        horizon_days=a.horizon_days,\n",
    "        n_paths=a.n_paths,\n",
    "        out_paths_csv=a.paths_csv,\n",
    "        out_stats_csv=a.stats_csv,\n",
    "        out_summary_json=a.summary_json,\n",
    "        seed=a.seed,\n",
    "        corr_shrink=a.corr_shrink,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "    print(\n",
    "        f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, \"\n",
    "        f\"{rets.shape[1]} assets.\"\n",
    "    )\n",
    "\n",
    "    asset_ret_paths, port_ret_paths = simulate_copula_paths(\n",
    "        hist_rets=rets,\n",
    "        horizon_days=cfg.horizon_days,\n",
    "        n_paths=cfg.n_paths,\n",
    "        corr_shrink=cfg.corr_shrink,\n",
    "    )\n",
    "\n",
    "    equity_paths = build_portfolio_equity(port_ret_paths)\n",
    "    stats_df = compute_path_stats(\n",
    "        equity_paths=equity_paths,\n",
    "        port_ret_paths=port_ret_paths,\n",
    "        horizon_days=cfg.horizon_days,\n",
    "    )\n",
    "\n",
    "    save_outputs(equity_paths, stats_df, cfg)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim: strip kernel-related args\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "id": "ffb481188ebd6070",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4013 price rows, 4012 return rows, 8 assets.\n",
      "[OK] Saved equity paths -> level78_copula_paths.csv\n",
      "[OK] Saved path stats -> level78_copula_stats.csv\n",
      "[OK] Saved summary -> level78_copula_summary.json\n",
      "Final wealth median=1.067, p05=0.903, p95=1.295\n",
      "MaxDD median=-9.6%, mean=-10.3%\n",
      "Sharpe mean=0.70, median=0.61\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
