{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T15:58:24.207103Z",
     "start_time": "2025-12-27T15:58:17.503031Z"
    }
   },
   "source": [
    "# level84_var_es_backtest.py\n",
    "# Level-84: VaR + Expected Shortfall (ES / CVaR) + Backtesting (Kupiec + Christoffersen)\n",
    "#\n",
    "# Free-data, end-to-end script:\n",
    "# - Pull daily prices from yfinance\n",
    "# - Build portfolio returns (equal-weight default or user-specified weights)\n",
    "# - Compute rolling 1-day VaR and ES using:\n",
    "#     (A) Historical Simulation (HS)\n",
    "#     (B) Filtered Historical Simulation (FHS) with EWMA volatility scaling\n",
    "# - Backtest:\n",
    "#     - Kupiec POF (unconditional coverage) test\n",
    "#     - Christoffersen independence test\n",
    "#     - Christoffersen conditional coverage test (POF + IND)\n",
    "#\n",
    "# Outputs:\n",
    "#   - level84_var_es_panel.csv\n",
    "#   - level84_var_es_summary.json\n",
    "#\n",
    "# Examples:\n",
    "#   python level84_var_es_backtest.py\n",
    "#   python level84_var_es_backtest.py --symbols SPY QQQ IWM TLT GLD --alpha 0.01 --window 750 --method fhs\n",
    "#   python level84_var_es_backtest.py --symbols SPY QQQ --weights 0.6 0.4 --alpha 0.05 --method hs\n",
    "#\n",
    "# Notes:\n",
    "# - Loss is defined as L = -return (positive = loss).\n",
    "# - VaR/ES are reported as POSITIVE loss numbers (e.g., 0.02 = 2% loss).\n",
    "# - Breach happens when loss > VaR.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Optional (for p-values). Script still runs without SciPy.\n",
    "try:\n",
    "    from scipy.stats import chi2  # type: ignore\n",
    "    _HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    _HAVE_SCIPY = False\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    weights: Optional[Tuple[float, ...]] = None  # if None => equal-weight\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    alpha: float = 0.01            # tail probability (1% default)\n",
    "    window: int = 750              # rolling lookback (~3 years)\n",
    "    method: str = \"fhs\"            # \"hs\" or \"fhs\"\n",
    "\n",
    "    # EWMA for FHS\n",
    "    ewma_lambda: float = 0.94      # RiskMetrics-style daily lambda\n",
    "    vol_floor: float = 1e-8\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level84_var_es_panel.csv\"\n",
    "    out_json: str = \"level84_var_es_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Data loader -----------------------------\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    px = yf.download(list(symbols), start=start, auto_adjust=True, progress=False)\n",
    "\n",
    "    if px is None or len(px) == 0:\n",
    "        raise RuntimeError(\"No data returned from yfinance (check symbols/start).\")\n",
    "\n",
    "    # yfinance often returns MultiIndex columns for multiple tickers\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        if (\"Close\" in px.columns.get_level_values(0)) is False:\n",
    "            raise RuntimeError(f\"Expected 'Close' in MultiIndex columns. Got levels: {px.columns.levels}\")\n",
    "        close = px[\"Close\"].copy()\n",
    "    else:\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"Expected 'Close' column. Got: {list(px.columns)}\")\n",
    "        close = px[[\"Close\"]].copy()\n",
    "        close.columns = [symbols[0]]\n",
    "\n",
    "    close = close.dropna(how=\"any\")\n",
    "    close = close.sort_index()\n",
    "    close.columns = [str(c) for c in close.columns]\n",
    "    return close\n",
    "\n",
    "\n",
    "def compute_log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    rets = np.log(prices).diff().dropna()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "def normalize_weights(symbols: Tuple[str, ...], weights: Optional[Tuple[float, ...]]) -> np.ndarray:\n",
    "    n = len(symbols)\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / n\n",
    "        return w\n",
    "    if len(weights) != n:\n",
    "        raise ValueError(f\"--weights length ({len(weights)}) must match --symbols length ({n}).\")\n",
    "    w = np.array(weights, dtype=float)\n",
    "    if not np.isfinite(w).all():\n",
    "        raise ValueError(\"Weights must be finite numbers.\")\n",
    "    s = float(w.sum())\n",
    "    if abs(s) < 1e-12:\n",
    "        raise ValueError(\"Weights sum to ~0; cannot normalize.\")\n",
    "    w = w / s\n",
    "    return w\n",
    "\n",
    "\n",
    "# ----------------------------- Risk metrics: HS + FHS -----------------------------\n",
    "def hs_var_es(losses_window: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Historical simulation VaR/ES on a window of losses.\n",
    "    Returns positive numbers (loss units).\n",
    "    \"\"\"\n",
    "    q = float(np.quantile(losses_window, 1.0 - alpha))  # VaR at (1-alpha) quantile of losses\n",
    "    tail = losses_window[losses_window >= q]\n",
    "    es = float(tail.mean()) if tail.size else float(q)\n",
    "    return {\"VaR\": q, \"ES\": es}\n",
    "\n",
    "\n",
    "def ewma_vol(returns: np.ndarray, lam: float, vol_floor: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    EWMA volatility estimate (sigma_t) for each t, using past information.\n",
    "    sigma_t^2 = lam * sigma_{t-1}^2 + (1-lam) * r_{t-1}^2\n",
    "    \"\"\"\n",
    "    n = returns.size\n",
    "    sig2 = np.zeros(n, dtype=float)\n",
    "\n",
    "    # initialize with sample var of first ~50 points (or fewer)\n",
    "    m = min(50, n)\n",
    "    init = float(np.var(returns[:m], ddof=1)) if m >= 2 else float(returns[0] ** 2)\n",
    "    sig2[0] = max(init, vol_floor)\n",
    "\n",
    "    for t in range(1, n):\n",
    "        r_prev = float(returns[t - 1])\n",
    "        sig2[t] = lam * sig2[t - 1] + (1.0 - lam) * (r_prev * r_prev)\n",
    "        if sig2[t] < vol_floor:\n",
    "            sig2[t] = vol_floor\n",
    "\n",
    "    return np.sqrt(sig2)\n",
    "\n",
    "\n",
    "def fhs_var_es(returns_window: np.ndarray, alpha: float, lam: float, vol_floor: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Filtered Historical Simulation:\n",
    "    - Estimate EWMA vol series within the window\n",
    "    - Standardize returns -> residuals\n",
    "    - Compute residual VaR/ES\n",
    "    - Scale back using *last* sigma in window for next-day forecast\n",
    "    \"\"\"\n",
    "    sig = ewma_vol(returns_window, lam=lam, vol_floor=vol_floor)\n",
    "    # Avoid divide-by-zero\n",
    "    z = returns_window / np.maximum(sig, vol_floor)\n",
    "\n",
    "    # Convert to losses: L = -(sigma_next * z)\n",
    "    # For next-day (t+1) forecast, we use sigma_last as sigma_next\n",
    "    sigma_next = float(sig[-1])\n",
    "\n",
    "    z_losses = -(z)  # because loss = -return, and return ~ sigma_next * z\n",
    "    # VaR/ES on standardized losses, then scale by sigma_next\n",
    "    z_q = float(np.quantile(z_losses, 1.0 - alpha))\n",
    "    z_tail = z_losses[z_losses >= z_q]\n",
    "    z_es = float(z_tail.mean()) if z_tail.size else float(z_q)\n",
    "\n",
    "    return {\"VaR\": sigma_next * z_q, \"ES\": sigma_next * z_es, \"sigma_next\": sigma_next}\n",
    "\n",
    "\n",
    "# ----------------------------- Backtests -----------------------------\n",
    "def kupiec_pof_test(breaches: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Kupiec POF test for unconditional coverage.\n",
    "    breaches: 0/1 array where 1 indicates VaR breach.\n",
    "    \"\"\"\n",
    "    n = int(breaches.size)\n",
    "    x = int(breaches.sum())\n",
    "    p = float(alpha)\n",
    "\n",
    "    # handle edge cases safely\n",
    "    if n == 0:\n",
    "        return {\"LR_pof\": float(\"nan\"), \"p_value\": float(\"nan\"), \"n\": 0, \"x\": 0}\n",
    "\n",
    "    pi_hat = x / n\n",
    "    # log-likelihoods with safe clamps\n",
    "    def _log(a: float) -> float:\n",
    "        return math.log(max(a, 1e-15))\n",
    "\n",
    "    ll0 = (n - x) * _log(1.0 - p) + x * _log(p)\n",
    "    ll1 = (n - x) * _log(1.0 - pi_hat) + x * _log(pi_hat)\n",
    "\n",
    "    lr = -2.0 * (ll0 - ll1)\n",
    "    pv = float(chi2.sf(lr, df=1)) if _HAVE_SCIPY else float(\"nan\")\n",
    "\n",
    "    return {\"LR_pof\": float(lr), \"p_value\": pv, \"n\": n, \"x\": x, \"pi_hat\": float(pi_hat)}\n",
    "\n",
    "\n",
    "def christoffersen_ind_test(breaches: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Christoffersen independence test using 2x2 transition counts.\n",
    "    \"\"\"\n",
    "    b = breaches.astype(int)\n",
    "    if b.size < 2:\n",
    "        return {\"LR_ind\": float(\"nan\"), \"p_value\": float(\"nan\"), \"n00\": 0, \"n01\": 0, \"n10\": 0, \"n11\": 0}\n",
    "\n",
    "    b0 = b[:-1]\n",
    "    b1 = b[1:]\n",
    "\n",
    "    n00 = int(((b0 == 0) & (b1 == 0)).sum())\n",
    "    n01 = int(((b0 == 0) & (b1 == 1)).sum())\n",
    "    n10 = int(((b0 == 1) & (b1 == 0)).sum())\n",
    "    n11 = int(((b0 == 1) & (b1 == 1)).sum())\n",
    "\n",
    "    # transition probabilities\n",
    "    pi01 = n01 / max(n00 + n01, 1)\n",
    "    pi11 = n11 / max(n10 + n11, 1)\n",
    "    pi = (n01 + n11) / max(n00 + n01 + n10 + n11, 1)\n",
    "\n",
    "    def _log(a: float) -> float:\n",
    "        return math.log(max(a, 1e-15))\n",
    "\n",
    "    # likelihood under independence\n",
    "    ll_ind = (n00 + n10) * _log(1.0 - pi) + (n01 + n11) * _log(pi)\n",
    "    # likelihood under Markov\n",
    "    ll_mkv = (n00) * _log(1.0 - pi01) + (n01) * _log(pi01) + (n10) * _log(1.0 - pi11) + (n11) * _log(pi11)\n",
    "\n",
    "    lr = -2.0 * (ll_ind - ll_mkv)\n",
    "    pv = float(chi2.sf(lr, df=1)) if _HAVE_SCIPY else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"LR_ind\": float(lr),\n",
    "        \"p_value\": pv,\n",
    "        \"n00\": n00, \"n01\": n01, \"n10\": n10, \"n11\": n11,\n",
    "        \"pi01\": float(pi01), \"pi11\": float(pi11), \"pi\": float(pi)\n",
    "    }\n",
    "\n",
    "\n",
    "def christoffersen_cc_test(pof: Dict[str, float], ind: Dict[str, float]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Conditional coverage: LR_cc = LR_pof + LR_ind (df=2)\n",
    "    \"\"\"\n",
    "    lr_pof = float(pof.get(\"LR_pof\", float(\"nan\")))\n",
    "    lr_ind = float(ind.get(\"LR_ind\", float(\"nan\")))\n",
    "    lr_cc = lr_pof + lr_ind\n",
    "    pv = float(chi2.sf(lr_cc, df=2)) if _HAVE_SCIPY else float(\"nan\")\n",
    "    return {\"LR_cc\": float(lr_cc), \"p_value\": pv}\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, object]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_log_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, assets={rets.shape[1]}\")\n",
    "\n",
    "    w = normalize_weights(cfg.symbols, cfg.weights)\n",
    "    port_ret = rets.values @ w\n",
    "    port_ret = pd.Series(port_ret, index=rets.index, name=\"port_ret\")\n",
    "\n",
    "    # Loss series\n",
    "    loss = -port_ret\n",
    "\n",
    "    # Rolling VaR/ES\n",
    "    out = pd.DataFrame(index=rets.index)\n",
    "    out[\"port_ret\"] = port_ret\n",
    "    out[\"loss\"] = loss\n",
    "\n",
    "    VaR = np.full(len(out), np.nan, dtype=float)\n",
    "    ES = np.full(len(out), np.nan, dtype=float)\n",
    "    sigma_next = np.full(len(out), np.nan, dtype=float)\n",
    "\n",
    "    method = cfg.method.lower().strip()\n",
    "    if method not in (\"hs\", \"fhs\"):\n",
    "        raise ValueError(\"--method must be 'hs' or 'fhs'\")\n",
    "\n",
    "    for t in range(cfg.window, len(out)):\n",
    "        # Use trailing window ending at t-1 for a forecast at t\n",
    "        win = out[\"port_ret\"].iloc[t - cfg.window:t].values.astype(float)\n",
    "        loss_win = -win\n",
    "\n",
    "        if method == \"hs\":\n",
    "            m = hs_var_es(loss_win, cfg.alpha)\n",
    "            VaR[t] = m[\"VaR\"]\n",
    "            ES[t] = m[\"ES\"]\n",
    "        else:\n",
    "            m = fhs_var_es(win, cfg.alpha, lam=cfg.ewma_lambda, vol_floor=cfg.vol_floor)\n",
    "            VaR[t] = m[\"VaR\"]\n",
    "            ES[t] = m[\"ES\"]\n",
    "            sigma_next[t] = float(m[\"sigma_next\"])\n",
    "\n",
    "    out[\"VaR\"] = VaR\n",
    "    out[\"ES\"] = ES\n",
    "    if method == \"fhs\":\n",
    "        out[\"sigma_next\"] = sigma_next\n",
    "\n",
    "    # Breaches: realized loss > forecast VaR\n",
    "    out[\"breach\"] = ((out[\"loss\"] > out[\"VaR\"]) & out[\"VaR\"].notna()).astype(int)\n",
    "\n",
    "    # Backtest window (only where VaR exists)\n",
    "    bt = out.dropna(subset=[\"VaR\"]).copy()\n",
    "    breaches = bt[\"breach\"].values.astype(int)\n",
    "\n",
    "    pof = kupiec_pof_test(breaches, alpha=cfg.alpha)\n",
    "    ind = christoffersen_ind_test(breaches)\n",
    "    cc = christoffersen_cc_test(pof, ind)\n",
    "\n",
    "    # Basic performance stats (returns, not risk forecast accuracy)\n",
    "    ann_ret = float(bt[\"port_ret\"].mean() * 252.0)\n",
    "    ann_vol = float(bt[\"port_ret\"].std(ddof=1) * math.sqrt(252.0))\n",
    "    sharpe = float(ann_ret / ann_vol) if ann_vol > 0 else float(\"nan\")\n",
    "\n",
    "    # Save summary\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"n_backtest\": int(len(bt)),\n",
    "        },\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": list(cfg.symbols),\n",
    "            \"weights\": [float(x) for x in w.tolist()],\n",
    "        },\n",
    "        \"performance\": {\n",
    "            \"ann_ret\": ann_ret,\n",
    "            \"ann_vol\": ann_vol,\n",
    "            \"sharpe\": sharpe,\n",
    "        },\n",
    "        \"risk\": {\n",
    "            \"alpha\": float(cfg.alpha),\n",
    "            \"method\": method,\n",
    "            \"avg_VaR\": float(bt[\"VaR\"].mean()),\n",
    "            \"avg_ES\": float(bt[\"ES\"].mean()),\n",
    "        },\n",
    "        \"backtests\": {\n",
    "            \"kupiec_pof\": pof,\n",
    "            \"christoffersen_ind\": ind,\n",
    "            \"christoffersen_cc\": cc,\n",
    "            \"scipy_available_for_pvalues\": bool(_HAVE_SCIPY),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return {\"out\": out, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, object], cfg: Config) -> None:\n",
    "    out: pd.DataFrame = result[\"out\"]  # type: ignore\n",
    "    summary: Dict = result[\"summary\"]  # type: ignore\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    out.to_csv(cfg.out_csv)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    # Console summary\n",
    "    bt = out.dropna(subset=[\"VaR\"])\n",
    "    n = int(len(bt))\n",
    "    x = int(bt[\"breach\"].sum())\n",
    "    rate = x / n if n > 0 else float(\"nan\")\n",
    "\n",
    "    print(f\"[OK] Saved panel → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(f\"[INFO] Backtest points: {n}, Breaches: {x}, Breach rate: {rate:.4f}, Expected: {cfg.alpha:.4f}\")\n",
    "    print(f\"[INFO] Avg VaR={bt['VaR'].mean():.5f}  Avg ES={bt['ES'].mean():.5f}  (loss units)\")\n",
    "    pof = summary[\"backtests\"][\"kupiec_pof\"]\n",
    "    ind = summary[\"backtests\"][\"christoffersen_ind\"]\n",
    "    cc = summary[\"backtests\"][\"christoffersen_cc\"]\n",
    "    print(f\"[TEST] Kupiec LR={pof['LR_pof']:.3f}  p={pof['p_value']}\")\n",
    "    print(f\"[TEST] Ind   LR={ind['LR_ind']:.3f}  p={ind['p_value']}\")\n",
    "    print(f\"[TEST] CC    LR={cc['LR_cc']:.3f}  p={cc['p_value']}\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-84: VaR+ES with Kupiec/Christoffersen backtests\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--weights\", nargs=\"*\", type=float, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.01)\n",
    "    p.add_argument(\"--window\", type=int, default=750)\n",
    "    p.add_argument(\"--method\", type=str, default=\"fhs\", choices=[\"hs\", \"fhs\"])\n",
    "\n",
    "    p.add_argument(\"--ewma-lambda\", type=float, default=0.94)\n",
    "    p.add_argument(\"--vol-floor\", type=float, default=1e-8)\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level84_var_es_panel.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level84_var_es_summary.json\")\n",
    "\n",
    "    a = p.parse_args()\n",
    "\n",
    "    weights_tuple = tuple(a.weights) if a.weights is not None and len(a.weights) > 0 else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        weights=weights_tuple,\n",
    "        start=a.start,\n",
    "        alpha=float(a.alpha),\n",
    "        window=int(a.window),\n",
    "        method=str(a.method),\n",
    "        ewma_lambda=float(a.ewma_lambda),\n",
    "        vol_floor=float(a.vol_floor),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm cell shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4021 price rows, 4020 return rows, assets=8\n",
      "[OK] Saved panel → level84_var_es_panel.csv\n",
      "[OK] Saved summary → level84_var_es_summary.json\n",
      "[INFO] Backtest points: 3270, Breaches: 38, Breach rate: 0.0116, Expected: 0.0100\n",
      "[INFO] Avg VaR=0.01935  Avg ES=0.02518  (loss units)\n",
      "[TEST] Kupiec LR=0.825  p=0.3638026067475352\n",
      "[TEST] Ind   LR=11.211  p=0.0008131871473722776\n",
      "[TEST] CC    LR=12.036  p=0.0024350039072983027\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
