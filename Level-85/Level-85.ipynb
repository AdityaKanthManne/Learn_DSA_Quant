{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T16:02:44.448827Z",
     "start_time": "2025-12-27T16:01:16.307042Z"
    }
   },
   "source": [
    "# level85_evt_pot_var_es.py\n",
    "# Level-85: EVT (Extreme Value Theory) Peaks-Over-Threshold (POT) VaR + ES + Backtesting\n",
    "#\n",
    "# What you get (end-to-end):\n",
    "# 1) Pull daily prices from yfinance\n",
    "# 2) Build portfolio returns (equal-weight default or user weights)\n",
    "# 3) Compute rolling 1-day VaR and ES using EVT POT with GPD tail fit on LOSSES:\n",
    "#       - Choose threshold by quantile u_q (e.g., 95% => top 5% losses as exceedances)\n",
    "#       - Fit GPD to exceedances (loss - u) using MLE (scipy if available, else robust fallback)\n",
    "#       - Forecast VaR_alpha and ES_alpha for next day\n",
    "# 4) Backtest VaR breaches:\n",
    "#       - Kupiec POF (unconditional coverage)\n",
    "#       - Christoffersen independence + conditional coverage\n",
    "#\n",
    "# Outputs:\n",
    "#   - level85_evt_panel.csv\n",
    "#   - level85_evt_summary.json\n",
    "#\n",
    "# Examples:\n",
    "#   python level85_evt_pot_var_es.py\n",
    "#   python level85_evt_pot_var_es.py --symbols SPY QQQ IWM TLT GLD --weights 0.35 0.25 0.15 0.15 0.10\n",
    "#   python level85_evt_pot_var_es.py --alpha 0.01 --window 1000 --u-quantile 0.95\n",
    "#\n",
    "# Notes:\n",
    "# - Loss is defined as L = -return (positive = loss).\n",
    "# - VaR and ES are positive loss numbers (e.g., 0.02 = 2% loss).\n",
    "# - Breach if realized loss > forecast VaR.\n",
    "# - EVT POT formula is sensitive; keep a reasonably large window and not-too-high threshold.\n",
    "#\n",
    "# Dependencies:\n",
    "# - Required: numpy, pandas, yfinance\n",
    "# - Optional: scipy (for GPD MLE + chi-square p-values). Script runs without SciPy.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Optional, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Optional SciPy\n",
    "_HAVE_SCIPY = False\n",
    "try:\n",
    "    from scipy.stats import genpareto, chi2  # type: ignore\n",
    "    _HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    _HAVE_SCIPY = False\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    weights: Optional[Tuple[float, ...]] = None\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    alpha: float = 0.01          # VaR tail probability (1% default)\n",
    "    window: int = 1000           # rolling lookback for EVT fit\n",
    "    u_quantile: float = 0.95     # threshold quantile for POT (e.g., 0.95 => exceedances are top 5% losses)\n",
    "\n",
    "    # Guardrails\n",
    "    min_exceed: int = 40         # minimum exceedances needed to trust EVT; else fallback to historical\n",
    "    xi_cap: float = 0.80         # cap shape parameter to avoid crazy moments\n",
    "    beta_floor: float = 1e-8     # floor scale param\n",
    "    seed: int = 42\n",
    "\n",
    "    out_csv: str = \"level85_evt_panel.csv\"\n",
    "    out_json: str = \"level85_evt_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Data loader -----------------------------\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    px = yf.download(list(symbols), start=start, auto_adjust=True, progress=False)\n",
    "    if px is None or len(px) == 0:\n",
    "        raise RuntimeError(\"No data returned from yfinance (check symbols/start).\")\n",
    "\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        if \"Close\" not in px.columns.get_level_values(0):\n",
    "            raise RuntimeError(\"Expected 'Close' in yfinance MultiIndex columns.\")\n",
    "        close = px[\"Close\"].copy()\n",
    "    else:\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"Expected 'Close' column. Got: {list(px.columns)}\")\n",
    "        close = px[[\"Close\"]].copy()\n",
    "        close.columns = [symbols[0]]\n",
    "\n",
    "    close = close.dropna(how=\"any\").sort_index()\n",
    "    close.columns = [str(c) for c in close.columns]\n",
    "    return close\n",
    "\n",
    "\n",
    "def compute_log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    rets = np.log(prices).diff().dropna()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "def normalize_weights(symbols: Tuple[str, ...], weights: Optional[Tuple[float, ...]]) -> np.ndarray:\n",
    "    n = len(symbols)\n",
    "    if weights is None:\n",
    "        return np.ones(n) / n\n",
    "    if len(weights) != n:\n",
    "        raise ValueError(f\"--weights length ({len(weights)}) must match --symbols length ({n}).\")\n",
    "    w = np.array(weights, dtype=float)\n",
    "    if not np.isfinite(w).all():\n",
    "        raise ValueError(\"Weights must be finite numbers.\")\n",
    "    s = float(w.sum())\n",
    "    if abs(s) < 1e-12:\n",
    "        raise ValueError(\"Weights sum to ~0; cannot normalize.\")\n",
    "    return w / s\n",
    "\n",
    "\n",
    "# ----------------------------- Backtests -----------------------------\n",
    "def kupiec_pof_test(breaches: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    n = int(breaches.size)\n",
    "    x = int(breaches.sum())\n",
    "    p = float(alpha)\n",
    "    if n == 0:\n",
    "        return {\"LR_pof\": float(\"nan\"), \"p_value\": float(\"nan\"), \"n\": 0, \"x\": 0}\n",
    "\n",
    "    pi_hat = x / n\n",
    "\n",
    "    def _log(a: float) -> float:\n",
    "        return math.log(max(a, 1e-15))\n",
    "\n",
    "    ll0 = (n - x) * _log(1.0 - p) + x * _log(p)\n",
    "    ll1 = (n - x) * _log(1.0 - pi_hat) + x * _log(pi_hat)\n",
    "    lr = -2.0 * (ll0 - ll1)\n",
    "\n",
    "    pv = float(chi2.sf(lr, df=1)) if (_HAVE_SCIPY) else float(\"nan\")\n",
    "    return {\"LR_pof\": float(lr), \"p_value\": pv, \"n\": n, \"x\": x, \"pi_hat\": float(pi_hat)}\n",
    "\n",
    "\n",
    "def christoffersen_ind_test(breaches: np.ndarray) -> Dict[str, float]:\n",
    "    b = breaches.astype(int)\n",
    "    if b.size < 2:\n",
    "        return {\"LR_ind\": float(\"nan\"), \"p_value\": float(\"nan\"), \"n00\": 0, \"n01\": 0, \"n10\": 0, \"n11\": 0}\n",
    "\n",
    "    b0 = b[:-1]\n",
    "    b1 = b[1:]\n",
    "\n",
    "    n00 = int(((b0 == 0) & (b1 == 0)).sum())\n",
    "    n01 = int(((b0 == 0) & (b1 == 1)).sum())\n",
    "    n10 = int(((b0 == 1) & (b1 == 0)).sum())\n",
    "    n11 = int(((b0 == 1) & (b1 == 1)).sum())\n",
    "\n",
    "    pi01 = n01 / max(n00 + n01, 1)\n",
    "    pi11 = n11 / max(n10 + n11, 1)\n",
    "    pi = (n01 + n11) / max(n00 + n01 + n10 + n11, 1)\n",
    "\n",
    "    def _log(a: float) -> float:\n",
    "        return math.log(max(a, 1e-15))\n",
    "\n",
    "    ll_ind = (n00 + n10) * _log(1.0 - pi) + (n01 + n11) * _log(pi)\n",
    "    ll_mkv = (n00) * _log(1.0 - pi01) + (n01) * _log(pi01) + (n10) * _log(1.0 - pi11) + (n11) * _log(pi11)\n",
    "\n",
    "    lr = -2.0 * (ll_ind - ll_mkv)\n",
    "    pv = float(chi2.sf(lr, df=1)) if (_HAVE_SCIPY) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"LR_ind\": float(lr),\n",
    "        \"p_value\": pv,\n",
    "        \"n00\": n00, \"n01\": n01, \"n10\": n10, \"n11\": n11,\n",
    "        \"pi01\": float(pi01), \"pi11\": float(pi11), \"pi\": float(pi)\n",
    "    }\n",
    "\n",
    "\n",
    "def christoffersen_cc_test(pof: Dict[str, float], ind: Dict[str, float]) -> Dict[str, float]:\n",
    "    lr_cc = float(pof.get(\"LR_pof\", float(\"nan\"))) + float(ind.get(\"LR_ind\", float(\"nan\")))\n",
    "    pv = float(chi2.sf(lr_cc, df=2)) if (_HAVE_SCIPY) else float(\"nan\")\n",
    "    return {\"LR_cc\": float(lr_cc), \"p_value\": pv}\n",
    "\n",
    "\n",
    "# ----------------------------- EVT POT VaR/ES -----------------------------\n",
    "def _gpd_fit_exceedances(y: np.ndarray, beta_floor: float, xi_cap: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Fit GPD to exceedances y = loss - u, y>=0.\n",
    "\n",
    "    Returns dict with xi (shape), beta (scale).\n",
    "    Uses SciPy genpareto.fit if available, otherwise a robust fallback.\n",
    "    \"\"\"\n",
    "    y = y.astype(float)\n",
    "    y = y[np.isfinite(y)]\n",
    "    y = y[y >= 0.0]\n",
    "    if y.size < 5:\n",
    "        return {\"xi\": 0.0, \"beta\": float(max(beta_floor, y.mean() if y.size else beta_floor)), \"fit_method\": \"fallback_too_few\"}\n",
    "\n",
    "    if _HAVE_SCIPY:\n",
    "        # SciPy parameterization: c=xi, loc, scale=beta\n",
    "        # Force loc=0 for exceedances\n",
    "        c, loc, scale = genpareto.fit(y, floc=0.0)\n",
    "        xi = float(np.clip(c, -0.49, xi_cap))\n",
    "        beta = float(max(scale, beta_floor))\n",
    "        return {\"xi\": xi, \"beta\": beta, \"fit_method\": \"scipy_mle\"}\n",
    "\n",
    "    # Fallback (no SciPy):\n",
    "    # Use a simple moment-based estimate with clipping:\n",
    "    # For GPD with xi < 0.5, mean = beta/(1-xi) => beta = mean*(1-xi)\n",
    "    # We pick xi from a crude tail-index proxy using CV:\n",
    "    #   For GPD, var exists if xi<0.5 and CV^2 = 1/(1-2xi)  => xi ≈ (CV^2-1)/(2*CV^2)\n",
    "    m = float(np.mean(y))\n",
    "    v = float(np.var(y, ddof=1)) if y.size >= 2 else 0.0\n",
    "    cv2 = v / max(m * m, 1e-15)\n",
    "    xi_raw = (cv2 - 1.0) / (2.0 * max(cv2, 1e-12))\n",
    "    xi = float(np.clip(xi_raw, -0.49, min(0.49, xi_cap)))  # keep in var-exists zone\n",
    "    beta = float(max(m * (1.0 - xi), beta_floor))\n",
    "    return {\"xi\": xi, \"beta\": beta, \"fit_method\": \"fallback_moments\"}\n",
    "\n",
    "\n",
    "def evt_pot_var_es(\n",
    "    losses_window: np.ndarray,\n",
    "    alpha: float,\n",
    "    u_quantile: float,\n",
    "    min_exceed: int,\n",
    "    beta_floor: float,\n",
    "    xi_cap: float\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    EVT POT forecast for VaR_alpha and ES_alpha (both positive losses).\n",
    "\n",
    "    losses_window: array of losses in the lookback window\n",
    "    u = quantile(losses, u_quantile)\n",
    "    exceedances y = loss - u, loss>u\n",
    "\n",
    "    Let p_u = P(L > u) estimated by exceedance frequency = Nu / N\n",
    "\n",
    "    For target tail alpha (e.g., 0.01), VaR satisfies:\n",
    "      P(L > VaR) = alpha\n",
    "      => VaR = u + (beta/xi) * [ (alpha/p_u)^(-xi) - 1 ]   if xi != 0\n",
    "      => VaR = u + beta * log(p_u/alpha)                 if xi == 0\n",
    "\n",
    "    ES for GPD tail (requires xi < 1):\n",
    "      ES = (VaR + (beta - xi*u)) / (1 - xi)   in common derivations when fitting exceedances above u:\n",
    "      More directly (with exceedance formulation):\n",
    "        ES = (VaR + (beta - xi*u)) / (1 - xi)\n",
    "      We use a stable form:\n",
    "        ES = (VaR + (beta - xi*u)) / (1 - xi)    (xi < 1)\n",
    "      If xi close to 1, we clamp.\n",
    "    \"\"\"\n",
    "    L = losses_window.astype(float)\n",
    "    L = L[np.isfinite(L)]\n",
    "    if L.size < 50:\n",
    "        # too short: fallback to historical\n",
    "        q = float(np.quantile(L, 1.0 - alpha))\n",
    "        tail = L[L >= q]\n",
    "        es = float(tail.mean()) if tail.size else float(q)\n",
    "        return {\"VaR\": q, \"ES\": es, \"u\": float(\"nan\"), \"p_u\": float(\"nan\"), \"xi\": 0.0, \"beta\": float(\"nan\"), \"fit_method\": \"hist_short\"}\n",
    "\n",
    "    u = float(np.quantile(L, u_quantile))\n",
    "    exc = L[L > u] - u\n",
    "    n = int(L.size)\n",
    "    nu = int(exc.size)\n",
    "    p_u = nu / n if n > 0 else float(\"nan\")\n",
    "\n",
    "    if nu < min_exceed or not np.isfinite(p_u) or p_u <= 0:\n",
    "        # fallback to historical (HS)\n",
    "        q = float(np.quantile(L, 1.0 - alpha))\n",
    "        tail = L[L >= q]\n",
    "        es = float(tail.mean()) if tail.size else float(q)\n",
    "        return {\"VaR\": q, \"ES\": es, \"u\": u, \"p_u\": float(p_u), \"xi\": 0.0, \"beta\": float(\"nan\"), \"fit_method\": \"hist_fallback\"}\n",
    "\n",
    "    fit = _gpd_fit_exceedances(exc, beta_floor=beta_floor, xi_cap=xi_cap)\n",
    "    xi = float(fit[\"xi\"])\n",
    "    beta = float(fit[\"beta\"])\n",
    "\n",
    "    # alpha must be smaller than p_u typically (i.e., deeper tail than threshold)\n",
    "    # If not, you're asking for a quantile that isn't beyond u; fallback to HS.\n",
    "    if not (alpha < p_u):\n",
    "        q = float(np.quantile(L, 1.0 - alpha))\n",
    "        tail = L[L >= q]\n",
    "        es = float(tail.mean()) if tail.size else float(q)\n",
    "        return {\"VaR\": q, \"ES\": es, \"u\": u, \"p_u\": float(p_u), \"xi\": xi, \"beta\": beta, \"fit_method\": \"hist_alpha_ge_pu\"}\n",
    "\n",
    "    # VaR\n",
    "    if abs(xi) < 1e-8:\n",
    "        var = u + beta * math.log(p_u / alpha)\n",
    "    else:\n",
    "        # var = u + beta/xi * ((alpha/p_u)^(-xi) - 1)\n",
    "        term = (alpha / p_u) ** (-xi)\n",
    "        var = u + (beta / xi) * (term - 1.0)\n",
    "\n",
    "    var = float(max(var, 0.0))\n",
    "\n",
    "    # ES (requires xi < 1)\n",
    "    xi_es = float(min(xi, 0.99))\n",
    "    denom = (1.0 - xi_es)\n",
    "    es = (var + (beta - xi_es * u)) / max(denom, 1e-6)\n",
    "    es = float(max(es, var))  # ES should be >= VaR\n",
    "\n",
    "    return {\n",
    "        \"VaR\": float(var),\n",
    "        \"ES\": float(es),\n",
    "        \"u\": float(u),\n",
    "        \"p_u\": float(p_u),\n",
    "        \"xi\": float(xi),\n",
    "        \"beta\": float(beta),\n",
    "        \"fit_method\": str(fit.get(\"fit_method\", \"unknown\")),\n",
    "        \"n\": float(n),\n",
    "        \"nu\": float(nu),\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Dict[str, Any]:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_log_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, assets={rets.shape[1]}\")\n",
    "\n",
    "    w = normalize_weights(cfg.symbols, cfg.weights)\n",
    "    port_ret = rets.values @ w\n",
    "    port_ret = pd.Series(port_ret, index=rets.index, name=\"port_ret\")\n",
    "\n",
    "    loss = -port_ret\n",
    "\n",
    "    out = pd.DataFrame(index=rets.index)\n",
    "    out[\"port_ret\"] = port_ret\n",
    "    out[\"loss\"] = loss\n",
    "\n",
    "    VaR = np.full(len(out), np.nan, dtype=float)\n",
    "    ES = np.full(len(out), np.nan, dtype=float)\n",
    "    u_arr = np.full(len(out), np.nan, dtype=float)\n",
    "    pu_arr = np.full(len(out), np.nan, dtype=float)\n",
    "    xi_arr = np.full(len(out), np.nan, dtype=float)\n",
    "    beta_arr = np.full(len(out), np.nan, dtype=float)\n",
    "\n",
    "    fit_method = [\"\"] * len(out)\n",
    "\n",
    "    for t in range(cfg.window, len(out)):\n",
    "        Lwin = out[\"loss\"].iloc[t - cfg.window:t].values.astype(float)\n",
    "        m = evt_pot_var_es(\n",
    "            losses_window=Lwin,\n",
    "            alpha=cfg.alpha,\n",
    "            u_quantile=cfg.u_quantile,\n",
    "            min_exceed=cfg.min_exceed,\n",
    "            beta_floor=cfg.beta_floor,\n",
    "            xi_cap=cfg.xi_cap,\n",
    "        )\n",
    "        VaR[t] = m[\"VaR\"]\n",
    "        ES[t] = m[\"ES\"]\n",
    "        u_arr[t] = float(m.get(\"u\", np.nan))\n",
    "        pu_arr[t] = float(m.get(\"p_u\", np.nan))\n",
    "        xi_arr[t] = float(m.get(\"xi\", np.nan))\n",
    "        beta_arr[t] = float(m.get(\"beta\", np.nan))\n",
    "        fit_method[t] = str(m.get(\"fit_method\", \"\"))\n",
    "\n",
    "    out[\"VaR\"] = VaR\n",
    "    out[\"ES\"] = ES\n",
    "    out[\"u\"] = u_arr\n",
    "    out[\"p_u\"] = pu_arr\n",
    "    out[\"xi\"] = xi_arr\n",
    "    out[\"beta\"] = beta_arr\n",
    "    out[\"fit_method\"] = fit_method\n",
    "\n",
    "    out[\"breach\"] = ((out[\"loss\"] > out[\"VaR\"]) & out[\"VaR\"].notna()).astype(int)\n",
    "\n",
    "    bt = out.dropna(subset=[\"VaR\"]).copy()\n",
    "    breaches = bt[\"breach\"].values.astype(int)\n",
    "\n",
    "    pof = kupiec_pof_test(breaches, alpha=cfg.alpha)\n",
    "    ind = christoffersen_ind_test(breaches)\n",
    "    cc = christoffersen_cc_test(pof, ind)\n",
    "\n",
    "    ann_ret = float(bt[\"port_ret\"].mean() * 252.0)\n",
    "    ann_vol = float(bt[\"port_ret\"].std(ddof=1) * math.sqrt(252.0))\n",
    "    sharpe = float(ann_ret / ann_vol) if ann_vol > 0 else float(\"nan\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"scipy_available\": bool(_HAVE_SCIPY),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "            \"n_backtest\": int(len(bt)),\n",
    "        },\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": list(cfg.symbols),\n",
    "            \"weights\": [float(x) for x in w.tolist()],\n",
    "        },\n",
    "        \"performance\": {\n",
    "            \"ann_ret\": ann_ret,\n",
    "            \"ann_vol\": ann_vol,\n",
    "            \"sharpe\": sharpe,\n",
    "        },\n",
    "        \"risk\": {\n",
    "            \"alpha\": float(cfg.alpha),\n",
    "            \"u_quantile\": float(cfg.u_quantile),\n",
    "            \"avg_VaR\": float(bt[\"VaR\"].mean()),\n",
    "            \"avg_ES\": float(bt[\"ES\"].mean()),\n",
    "            \"median_u\": float(bt[\"u\"].median()),\n",
    "            \"median_p_u\": float(bt[\"p_u\"].median()),\n",
    "            \"median_xi\": float(bt[\"xi\"].median()),\n",
    "            \"median_beta\": float(bt[\"beta\"].median()),\n",
    "            \"fit_method_counts\": bt[\"fit_method\"].value_counts().to_dict(),\n",
    "        },\n",
    "        \"backtests\": {\n",
    "            \"kupiec_pof\": pof,\n",
    "            \"christoffersen_ind\": ind,\n",
    "            \"christoffersen_cc\": cc,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return {\"out\": out, \"summary\": summary}\n",
    "\n",
    "\n",
    "def save_outputs(result: Dict[str, Any], cfg: Config) -> None:\n",
    "    out: pd.DataFrame = result[\"out\"]\n",
    "    summary: Dict[str, Any] = result[\"summary\"]\n",
    "\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    out.to_csv(cfg.out_csv)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    bt = out.dropna(subset=[\"VaR\"])\n",
    "    n = int(len(bt))\n",
    "    x = int(bt[\"breach\"].sum())\n",
    "    rate = x / n if n > 0 else float(\"nan\")\n",
    "\n",
    "    print(f\"[OK] Saved panel → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(f\"[INFO] Backtest points: {n}, Breaches: {x}, Breach rate: {rate:.4f}, Expected: {cfg.alpha:.4f}\")\n",
    "    print(f\"[INFO] Avg VaR={bt['VaR'].mean():.5f}  Avg ES={bt['ES'].mean():.5f}  (loss units)\")\n",
    "    pof = summary[\"backtests\"][\"kupiec_pof\"]\n",
    "    ind = summary[\"backtests\"][\"christoffersen_ind\"]\n",
    "    cc = summary[\"backtests\"][\"christoffersen_cc\"]\n",
    "    print(f\"[TEST] Kupiec LR={pof['LR_pof']:.3f}  p={pof['p_value']}\")\n",
    "    print(f\"[TEST] Ind   LR={ind['LR_ind']:.3f}  p={ind['p_value']}\")\n",
    "    print(f\"[TEST] CC    LR={cc['LR_cc']:.3f}  p={cc['p_value']}\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-85: EVT POT VaR/ES + Kupiec/Christoffersen backtests\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=Config.start)\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--weights\", nargs=\"*\", type=float, default=None)\n",
    "    p.add_argument(\"--alpha\", type=float, default=Config.alpha)\n",
    "    p.add_argument(\"--window\", type=int, default=Config.window)\n",
    "    p.add_argument(\"--u-quantile\", type=float, default=Config.u_quantile)\n",
    "\n",
    "    p.add_argument(\"--min-exceed\", type=int, default=Config.min_exceed)\n",
    "    p.add_argument(\"--xi-cap\", type=float, default=Config.xi_cap)\n",
    "    p.add_argument(\"--beta-floor\", type=float, default=Config.beta_floor)\n",
    "\n",
    "    p.add_argument(\"--seed\", type=int, default=Config.seed)\n",
    "    p.add_argument(\"--csv\", type=str, default=Config.out_csv)\n",
    "    p.add_argument(\"--json\", type=str, default=Config.out_json)\n",
    "\n",
    "    a = p.parse_args()\n",
    "\n",
    "    weights_tuple = tuple(a.weights) if (a.weights is not None and len(a.weights) > 0) else None\n",
    "\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        weights=weights_tuple,\n",
    "        start=a.start,\n",
    "        alpha=float(a.alpha),\n",
    "        window=int(a.window),\n",
    "        u_quantile=float(a.u_quantile),\n",
    "        min_exceed=int(a.min_exceed),\n",
    "        xi_cap=float(a.xi_cap),\n",
    "        beta_floor=float(a.beta_floor),\n",
    "        seed=int(a.seed),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    result = run_pipeline(cfg)\n",
    "    save_outputs(result, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm cell shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4021 price rows, 4020 return rows, assets=8\n",
      "[OK] Saved panel → level85_evt_panel.csv\n",
      "[OK] Saved summary → level85_evt_summary.json\n",
      "[INFO] Backtest points: 3020, Breaches: 31, Breach rate: 0.0103, Expected: 0.0100\n",
      "[INFO] Avg VaR=0.02005  Avg ES=0.03071  (loss units)\n",
      "[TEST] Kupiec LR=0.021  p=0.8841773046705668\n",
      "[TEST] Ind   LR=13.810  p=0.00020221090576883762\n",
      "[TEST] CC    LR=13.832  p=0.0009919636033119696\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
