{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-15T02:50:23.507784Z",
     "start_time": "2025-11-15T02:50:18.586089Z"
    }
   },
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Level-46 — Feature Stationarity Checker & Demeaning Pipeline\n",
    "\n",
    "- Loads time-series features (default: derived from SPY daily prices via yfinance)\n",
    "- Runs ADF + KPSS tests for each feature\n",
    "- Classifies features as stationary / non-stationary / borderline\n",
    "- Applies simple transformations (diff/logdiff + z-score) to improve stationarity\n",
    "- Saves:\n",
    "    * level46_features_raw.csv\n",
    "    * level46_features_transformed.csv\n",
    "    * level46_stationarity_report.csv\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "\n",
    "# ---------------------- Config ---------------------- #\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbol: str = \"SPY\"\n",
    "    start: str = \"2010-01-01\"\n",
    "    adf_alpha: float = 0.05\n",
    "    kpss_alpha: float = 0.05\n",
    "    out_raw_csv: str = \"level46_features_raw.csv\"\n",
    "    out_transformed_csv: str = \"level46_features_transformed.csv\"\n",
    "    out_report_csv: str = \"level46_stationarity_report.csv\"\n",
    "    out_report_json: str = \"level46_stationarity_report.json\"\n",
    "    max_diff_order: int = 1  # we keep it simple: at most 1 difference\n",
    "    dropna_after_transform: bool = True\n",
    "\n",
    "\n",
    "# ---------------------- Helpers ---------------------- #\n",
    "\n",
    "def load_price_data(cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load daily OHLCV data for cfg.symbol from yfinance and build a basic feature matrix.\n",
    "\n",
    "    You can replace this with your own feature CSV, e.g.:\n",
    "\n",
    "        df = pd.read_csv(\"features.csv\", parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n",
    "\n",
    "    expected: DateTimeIndex, numeric feature columns\n",
    "    \"\"\"\n",
    "    df = yf.download(cfg.symbol, start=cfg.start, auto_adjust=True, progress=False)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(f\"Failed to load data for symbol={cfg.symbol}\")\n",
    "    df = df[[\"Close\", \"Volume\"]].rename(columns={\"Close\": \"close\", \"Volume\": \"volume\"})\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Build simple features:\n",
    "    #   - log returns\n",
    "    #   - rolling volatility\n",
    "    #   - moving averages / spreads\n",
    "    df[\"ret_1\"] = np.log(df[\"close\"]).diff()\n",
    "    df[\"ret_5\"] = np.log(df[\"close\"]).diff(5)\n",
    "    df[\"sma_20\"] = df[\"close\"].rolling(20).mean()\n",
    "    df[\"sma_50\"] = df[\"close\"].rolling(50).mean()\n",
    "    df[\"sma_spread\"] = df[\"sma_20\"] - df[\"sma_50\"]\n",
    "    df[\"rv_20\"] = df[\"ret_1\"].rolling(20).std()\n",
    "    df[\"log_vol\"] = np.log(df[\"volume\"])\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def safe_adf(series: pd.Series) -> Tuple[float, float]:\n",
    "    \"\"\"Run ADF and return (statistic, p-value), handling short series gracefully.\"\"\"\n",
    "    s = series.dropna()\n",
    "    if len(s) < 20:\n",
    "        return np.nan, np.nan\n",
    "    stat, pval, *_ = adfuller(s, autolag=\"AIC\")\n",
    "    return float(stat), float(pval)\n",
    "\n",
    "\n",
    "def safe_kpss(series: pd.Series, regression: str = \"c\") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Run KPSS and return (statistic, p-value). Handle failures (e.g., constant series)\n",
    "    by returning NaNs.\n",
    "    \"\"\"\n",
    "    s = series.dropna()\n",
    "    if len(s) < 20:\n",
    "        return np.nan, np.nan\n",
    "    try:\n",
    "        stat, pval, *_ = kpss(s, regression=regression, nlags=\"auto\")\n",
    "        return float(stat), float(pval)\n",
    "    except Exception:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "\n",
    "def classify_stationarity(\n",
    "    adf_p: float,\n",
    "    kpss_p: float,\n",
    "    adf_alpha: float,\n",
    "    kpss_alpha: float,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Modeled on “ADF + KPSS combo” logic:\n",
    "\n",
    "    - ADF rejects (p < alpha) & KPSS does NOT reject (p >= alpha) → Stationary\n",
    "    - ADF does NOT reject & KPSS rejects → Clearly non-stationary\n",
    "    - Else → Borderline / Inconclusive\n",
    "    \"\"\"\n",
    "    adf_reject = (not np.isnan(adf_p)) and (adf_p < adf_alpha)\n",
    "    kpss_reject = (not np.isnan(kpss_p)) and (kpss_p < kpss_alpha)\n",
    "\n",
    "    if adf_reject and not kpss_reject:\n",
    "        return \"stationary\"\n",
    "    elif (not adf_reject) and kpss_reject:\n",
    "        return \"non_stationary\"\n",
    "    elif adf_reject and kpss_reject:\n",
    "        return \"mixed\"\n",
    "    else:\n",
    "        return \"borderline\"\n",
    "\n",
    "\n",
    "def recommend_transform(col_name: str, label: str) -> str:\n",
    "    \"\"\"\n",
    "    Very simple rule-based mapping:\n",
    "    - If looks like a price/level and non-stationary → log-diff\n",
    "    - If non-stationary and NOT clearly a price → 1st diff\n",
    "    - If stationary or borderline → zscore (demean/std)\n",
    "    \"\"\"\n",
    "    name = col_name.lower()\n",
    "\n",
    "    # Basic heuristics for \"price-like\" series\n",
    "    price_like = any(\n",
    "        kw in name for kw in [\"close\", \"price\", \"level\", \"index\"]\n",
    "    )\n",
    "\n",
    "    if label == \"non_stationary\":\n",
    "        if price_like:\n",
    "            return \"logdiff\"\n",
    "        else:\n",
    "            return \"diff\"\n",
    "    elif label == \"mixed\":\n",
    "        # play it safe\n",
    "        return \"diff\"\n",
    "    else:\n",
    "        # stationary or borderline: standardize\n",
    "        return \"zscore\"\n",
    "\n",
    "\n",
    "def apply_transform(series: pd.Series, rule: str) -> pd.Series:\n",
    "    \"\"\"Apply transformation rule to a single series.\"\"\"\n",
    "    s = series.astype(float)\n",
    "\n",
    "    if rule == \"logdiff\":\n",
    "        s = np.log(s.replace(0, np.nan)).diff()\n",
    "    elif rule == \"diff\":\n",
    "        s = s.diff()\n",
    "    elif rule == \"zscore\":\n",
    "        # global (in-sample) z-score; for live use, prefer rolling or expanding\n",
    "        mu = s.mean()\n",
    "        sigma = s.std()\n",
    "        if sigma == 0 or np.isnan(sigma):\n",
    "            return s * 0.0\n",
    "        s = (s - mu) / sigma\n",
    "    elif rule == \"none\":\n",
    "        return s\n",
    "    else:\n",
    "        # unknown rule, fall back to identity\n",
    "        return s\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def run_stationarity_pipeline(cfg: Config, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Main logic:\n",
    "    - takes a DataFrame df with DateTimeIndex and numeric columns\n",
    "    - runs ADF & KPSS per column\n",
    "    - recommends & applies a transform\n",
    "    - returns (raw_df, transformed_df, report_df)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.select_dtypes(include=[np.number])  # keep numeric columns only\n",
    "    df = df.sort_index()\n",
    "\n",
    "    report_rows: List[Dict] = {}\n",
    "    transformed = pd.DataFrame(index=df.index)\n",
    "\n",
    "    rows = []\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "\n",
    "        adf_stat, adf_p = safe_adf(s)\n",
    "        kpss_stat, kpss_p = safe_kpss(s, regression=\"c\")\n",
    "\n",
    "        label = classify_stationarity(adf_p, kpss_p, cfg.adf_alpha, cfg.kpss_alpha)\n",
    "        rule = recommend_transform(col, label)\n",
    "\n",
    "        t_series = apply_transform(s, rule)\n",
    "\n",
    "        rows.append({\n",
    "            \"feature\": col,\n",
    "            \"adf_stat\": adf_stat,\n",
    "            \"adf_p\": adf_p,\n",
    "            \"kpss_stat\": kpss_stat,\n",
    "            \"kpss_p\": kpss_p,\n",
    "            \"stationarity_label\": label,\n",
    "            \"recommended_transform\": rule,\n",
    "        })\n",
    "\n",
    "        transformed[col] = t_series\n",
    "\n",
    "    report_df = pd.DataFrame(rows).set_index(\"feature\")\n",
    "\n",
    "    if cfg.dropna_after_transform:\n",
    "        transformed = transformed.dropna()\n",
    "\n",
    "    return df, transformed, report_df\n",
    "\n",
    "\n",
    "def save_outputs(\n",
    "    raw_df: pd.DataFrame,\n",
    "    transformed_df: pd.DataFrame,\n",
    "    report_df: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    raw_df.to_csv(cfg.out_raw_csv)\n",
    "    transformed_df.to_csv(cfg.out_transformed_csv)\n",
    "    report_df.to_csv(cfg.out_report_csv)\n",
    "    with open(cfg.out_report_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report_df.reset_index().to_dict(orient=\"records\"), f, indent=2)\n",
    "    print(f\"[OK] Saved raw features      → {cfg.out_raw_csv}\")\n",
    "    print(f\"[OK] Saved transformed feats → {cfg.out_transformed_csv}\")\n",
    "    print(f\"[OK] Saved stationarity rpt  → {cfg.out_report_csv}\")\n",
    "    print(f\"[OK] Saved JSON report       → {cfg.out_report_json}\")\n",
    "\n",
    "\n",
    "# ---------------------- CLI ---------------------- #\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-46 Stationarity Checker & Demeaning Pipeline\"\n",
    "    )\n",
    "    p.add_argument(\"--symbol\", type=str, default=\"SPY\", help=\"Ticker for demo (yfinance)\")\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\", help=\"Start date for data\")\n",
    "    p.add_argument(\"--adf-alpha\", type=float, default=0.05, help=\"ADF significance level\")\n",
    "    p.add_argument(\"--kpss-alpha\", type=float, default=0.05, help=\"KPSS significance level\")\n",
    "    p.add_argument(\"--raw-csv\", type=str, default=\"level46_features_raw.csv\")\n",
    "    p.add_argument(\"--transformed-csv\", type=str, default=\"level46_features_transformed.csv\")\n",
    "    p.add_argument(\"--report-csv\", type=str, default=\"level46_stationarity_report.csv\")\n",
    "    p.add_argument(\"--report-json\", type=str, default=\"level46_stationarity_report.json\")\n",
    "    p.add_argument(\"--dropna\", action=\"store_true\", help=\"Drop NaNs after transforms\")\n",
    "\n",
    "    args = p.parse_args()\n",
    "\n",
    "    cfg = Config(\n",
    "        symbol=args.symbol,\n",
    "        start=args.start,\n",
    "        adf_alpha=args.adf_alpha,\n",
    "        kpss_alpha=args.kpss_alpha,\n",
    "        out_raw_csv=args.raw_csv,\n",
    "        out_transformed_csv=args.transformed_csv,\n",
    "        out_report_csv=args.report_csv,\n",
    "        out_report_json=args.report_json,\n",
    "        max_diff_order=1,\n",
    "        dropna_after_transform=args.dropna,\n",
    "    )\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    print(f\"[INFO] Loading data for {cfg.symbol} from {cfg.start}...\")\n",
    "    df = load_price_data(cfg)\n",
    "\n",
    "    print(f\"[INFO] Running stationarity pipeline on {df.shape[1]} features...\")\n",
    "    raw_df, transformed_df, report_df = run_stationarity_pipeline(cfg, df)\n",
    "\n",
    "    save_outputs(raw_df, transformed_df, report_df, cfg)\n",
    "\n",
    "    # Simple console summary\n",
    "    print(\"\\n[SUMMARY] Stationarity report:\")\n",
    "    print(report_df[[\"stationarity_label\", \"recommended_transform\"]])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Make it Jupyter-friendly by stripping unwanted kernel args like \"-f kernel-xxxx.json\"\n",
    "    if len(sys.argv) > 1:\n",
    "        sys.argv = [sys.argv[0]] + [\n",
    "            arg for arg in sys.argv[1:]\n",
    "            if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "        ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01myfinance\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01myf\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mstatsmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtsa\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstattools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m adfuller, kpss\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m# ---------------------- Config ---------------------- #\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;129m@dataclass\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mConfig\u001B[39;00m:\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'statsmodels'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
