{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-30T03:26:12.441150Z",
     "start_time": "2025-10-30T03:26:06.661585Z"
    }
   },
   "source": [
    "# Level-31 â€” Adaptive event labeling + calibrated GradientBoosting + backtest (hardened 1-D handling)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "TICKER       = \"AAPL\"\n",
    "YEARS        = 3.0          # years of daily data\n",
    "FREQ         = \"1D\"         # daily bars\n",
    "VOL_SPAN     = 50           # EWMA vol span\n",
    "H_BARS       = 10           # vertical barrier in bars\n",
    "CUSUM_GRID   = [0.002, 0.003, 0.004, 0.006, 0.008, 0.010]  # thresholds to try\n",
    "UP_M, DN_M   = 3.0, 3.0     # triple-barrier multipliers (in vols)\n",
    "MIN_EVENTS   = 500          # ensure enough labels\n",
    "KFOLDS       = 5\n",
    "RNG_SEED     = 42\n",
    "TC_BP        = 5            # transaction cost (bp) per toggle\n",
    "MAX_DAILY_TURNOVER = 0.5    # cap for daily turnover\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# ----------------------------- Utils -----------------------------\n",
    "def utc_now_date():\n",
    "    return datetime.now(timezone.utc).date()\n",
    "\n",
    "def load_prices(ticker, years, freq=\"1D\"):\n",
    "    # Pulls more days than needed to be safe\n",
    "    end = utc_now_date()\n",
    "    start = (datetime.now(timezone.utc) - timedelta(days=int(365*years + 20))).date()\n",
    "    df = yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False)\n",
    "    if df.empty:\n",
    "        raise SystemExit(\"No data downloaded.\")\n",
    "    if \"Adj Close\" in df.columns:\n",
    "        s = df[\"Adj Close\"].copy()\n",
    "    elif \"Close\" in df.columns:\n",
    "        s = df[\"Close\"].copy()\n",
    "    else:\n",
    "        raise RuntimeError(\"No Close/Adj Close in downloaded data.\")\n",
    "    s.name = \"Close\"\n",
    "    s = s.asfreq(\"B\").ffill()   # business days, forward-fill\n",
    "    return s\n",
    "\n",
    "def ewma_vol(r, span=50):\n",
    "    return r.ewm(span=span, adjust=False).std()\n",
    "\n",
    "def to_1d_series(r, index=None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Normalize r to a 1-D float Series with a proper index.\n",
    "    Accepts Series, DataFrame (uses first column), or any ndarray-like; squeezes to 1-D.\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.Series):\n",
    "        s = r.copy()\n",
    "        s = s.astype(\"float64\")\n",
    "        return s.fillna(0.0)\n",
    "\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        # use first column\n",
    "        s = r.iloc[:, 0].copy()\n",
    "        s = s.astype(\"float64\")\n",
    "        return s.fillna(0.0)\n",
    "\n",
    "    # ndarray-like\n",
    "    arr = np.asarray(r)\n",
    "    arr = np.ravel(arr)  # squeeze to 1-D safely\n",
    "    if index is None:\n",
    "        index = pd.RangeIndex(len(arr))\n",
    "    return pd.Series(arr, index=index, dtype=\"float64\").fillna(0.0)\n",
    "\n",
    "def cusum_filter(r, threshold, index=None) -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Symmetric CUSUM robust to Series/DataFrame/ndarray inputs.\n",
    "    Always converts to 1-D float Series (keeping provided index if given),\n",
    "    then iterates over plain floats.\n",
    "    \"\"\"\n",
    "    s = to_1d_series(r, index=index)\n",
    "    idx = s.index\n",
    "    vals = s.to_numpy(dtype=float)\n",
    "\n",
    "    s_pos, s_neg = 0.0, 0.0\n",
    "    t_events = []\n",
    "    for i, x in enumerate(vals):\n",
    "        x = float(x)\n",
    "        s_pos = max(0.0, s_pos + x)\n",
    "        s_neg = min(0.0, s_neg + x)\n",
    "        if s_pos > threshold:\n",
    "            s_pos = 0.0\n",
    "            t_events.append(idx[i])\n",
    "        elif s_neg < -threshold:\n",
    "            s_neg = 0.0\n",
    "            t_events.append(idx[i])\n",
    "    return pd.DatetimeIndex(t_events).unique().sort_values()\n",
    "\n",
    "def get_vertical_barriers(t_events: pd.DatetimeIndex, h: int, index: pd.DatetimeIndex) -> pd.Series:\n",
    "    if len(t_events) == 0:\n",
    "        return pd.Series(dtype=\"datetime64[ns]\")\n",
    "    out = {}\n",
    "    for t0 in t_events:\n",
    "        pos = index.get_indexer([t0])[0]\n",
    "        t1_pos = min(pos + h, len(index) - 1)\n",
    "        out[t0] = index[t1_pos]\n",
    "    return pd.Series(out)\n",
    "\n",
    "def _first_true_index(bool_series: pd.Series):\n",
    "    \"\"\"Return the index label of the first True in a boolean Series, or None if none.\"\"\"\n",
    "    if bool_series is None or len(bool_series) == 0:\n",
    "        return None\n",
    "    # Ensure we only call argmax when there's at least one True\n",
    "    if not bool(bool_series.any()):\n",
    "        return None\n",
    "    arr = bool_series.to_numpy(dtype=bool)\n",
    "    i = int(np.argmax(arr))\n",
    "    return bool_series.index[i]\n",
    "\n",
    "def get_triple_barrier_labels(close, t_events, vbar, up_m, dn_m, daily_vol):\n",
    "    # Align and build target\n",
    "    trgt = daily_vol.reindex(t_events).bfill().ffill()\n",
    "    df = pd.DataFrame({\"t1\": vbar.reindex(t_events), \"trgt\": trgt}, index=t_events).dropna(subset=[\"t1\", \"trgt\"])\n",
    "    labels = []\n",
    "    for t0, row in df.iterrows():\n",
    "        t1 = pd.Timestamp(row[\"t1\"])\n",
    "        c0 = float(close.loc[t0])\n",
    "        up_lvl = c0 * (1 + up_m * float(row[\"trgt\"]))\n",
    "        dn_lvl = c0 * (1 - dn_m * float(row[\"trgt\"]))\n",
    "        # slice path (inclusive)\n",
    "        path = to_1d_series(close.loc[t0:t1])\n",
    "        if path.empty:\n",
    "            continue\n",
    "        path_up = (path >= up_lvl)\n",
    "        path_dn = (path <= dn_lvl)\n",
    "\n",
    "        hit_up = _first_true_index(path_up)\n",
    "        hit_dn = _first_true_index(path_dn)\n",
    "\n",
    "        if (hit_up is not None) and (hit_dn is not None):\n",
    "            lbl = 1 if hit_up <= hit_dn else 0\n",
    "            t_end = hit_up if lbl == 1 else hit_dn\n",
    "        elif hit_up is not None:\n",
    "            lbl, t_end = 1, hit_up\n",
    "        elif hit_dn is not None:\n",
    "            lbl, t_end = 0, hit_dn\n",
    "        else:\n",
    "            c1 = float(close.loc[t1])\n",
    "            lbl, t_end = (1 if c1 > c0 else 0), t1\n",
    "\n",
    "        labels.append((t0, pd.Timestamp(t_end), int(lbl), float(row[\"trgt\"])))\n",
    "\n",
    "    if not labels:\n",
    "        return pd.DataFrame(columns=[\"t1\", \"label\", \"trgt\"])\n",
    "    out = pd.DataFrame(labels, columns=[\"t0\", \"t1\", \"label\", \"trgt\"]).set_index(\"t0\")\n",
    "    return out\n",
    "\n",
    "def make_features(close: pd.Series) -> pd.DataFrame:\n",
    "    r = close.pct_change().replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "    f = pd.DataFrame(index=close.index)\n",
    "    f[\"r1\"] = r\n",
    "    f[\"r5\"] = close.pct_change(5)\n",
    "    f[\"r10\"] = close.pct_change(10)\n",
    "    f[\"mom5\"] = (close / close.shift(5) - 1.0)\n",
    "    f[\"mom10\"] = (close / close.shift(10) - 1.0)\n",
    "    f[\"vol10\"] = r.rolling(10).std()\n",
    "    f[\"vol20\"] = r.rolling(20).std()\n",
    "    f[\"z20\"] = (close - close.rolling(20).mean()) / (1e-12 + close.rolling(20).std())\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0.0).rolling(14).mean()\n",
    "    dn = (-delta.clip(upper=0.0)).rolling(14).mean()\n",
    "    rs = up / (1e-12 + dn)\n",
    "    f[\"rsi14\"] = 100.0 - 100.0 / (1.0 + rs)\n",
    "    return f.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "\n",
    "def sample_weights_from_trgt(trgt: pd.Series) -> pd.Series:\n",
    "    w = 1.0 / (1e-8 + trgt)\n",
    "    return w.clip(upper=np.quantile(w, 0.99))\n",
    "\n",
    "def choose_proba_threshold(y_true: pd.Series, proba: pd.Series) -> float:\n",
    "    grid = np.linspace(0.4, 0.7, 16)\n",
    "    best_t, best_s = 0.5, -1e9\n",
    "    for t in grid:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        if int(pred.sum()) == 0:\n",
    "            score = -1e9\n",
    "        else:\n",
    "            tp = ((pred == 1) & (y_true == 1)).mean()\n",
    "            fp = ((pred == 1) & (y_true == 0)).mean()\n",
    "            score = float(tp - 0.5 * fp)\n",
    "        if score > best_s:\n",
    "            best_s, best_t = score, t\n",
    "    return float(best_t)\n",
    "\n",
    "def sharpe_ratio(x: pd.Series) -> float:\n",
    "    std = x.std()\n",
    "    if std == 0 or np.isnan(std):\n",
    "        return 0.0\n",
    "    return float(np.sqrt(252) * x.mean() / std)\n",
    "\n",
    "def drawdown(x: pd.Series) -> float:\n",
    "    cum = (1 + x).cumprod()\n",
    "    peak = cum.cummax()\n",
    "    dd = (cum / peak - 1.0).min()\n",
    "    return float(dd)\n",
    "\n",
    "def make_calibrator(base, method=\"isotonic\", cv=\"prefit\"):\n",
    "    sig = inspect.signature(CalibratedClassifierCV)\n",
    "    if \"estimator\" in sig.parameters:\n",
    "        return CalibratedClassifierCV(estimator=base, method=method, cv=cv)\n",
    "    else:\n",
    "        return CalibratedClassifierCV(base_estimator=base, method=method, cv=cv)\n",
    "\n",
    "def adaptive_events_and_labels(close, rets, base_H, cusum_grid, vol_span, up_m, dn_m, min_events):\n",
    "    daily_vol = ewma_vol(to_1d_series(rets, index=close.index), span=vol_span).clip(lower=1e-8).fillna(0.0)\n",
    "    used_thr = None\n",
    "    events_idx = pd.DatetimeIndex([])\n",
    "    for thr in cusum_grid:\n",
    "        ev = cusum_filter(rets, thr, index=close.index)  # pass explicit index\n",
    "        if len(ev) >= min_events:\n",
    "            used_thr = thr\n",
    "            events_idx = ev\n",
    "            break\n",
    "    if used_thr is None:\n",
    "        used_thr = min(cusum_grid)\n",
    "        events_idx = cusum_filter(rets, used_thr, index=close.index)\n",
    "\n",
    "    vbar = get_vertical_barriers(events_idx, base_H, close.index)\n",
    "    labels = get_triple_barrier_labels(close, events_idx, vbar, up_m, dn_m, daily_vol)\n",
    "    labels = labels.dropna()\n",
    "    if labels.empty:\n",
    "        raise SystemExit(\"No labeled events even after trying CUSUM thresholds. Adjust CUSUM_GRID/UP_M/DN_M/VOL_SPAN.\")\n",
    "    print(f\"[Adaptive] events={len(labels)}  H={base_H}  thrâ‰ˆ{used_thr}\")\n",
    "    return labels, daily_vol, events_idx, base_H, float(used_thr)\n",
    "\n",
    "# ----------------------------- Main -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Data\n",
    "    close = load_prices(TICKER, YEARS, FREQ)\n",
    "    rets  = close.pct_change().replace([np.inf, -np.inf], 0.0).fillna(0.0)  # Series, but we guard anyway downstream\n",
    "\n",
    "    # 2) Events & Labels (adaptive CUSUM)\n",
    "    labels, daily_vol, events_idx, H_used, thr_used = adaptive_events_and_labels(\n",
    "        close, rets, H_BARS, CUSUM_GRID, VOL_SPAN, UP_M, DN_M, MIN_EVENTS\n",
    "    )\n",
    "\n",
    "    # 3) Features aligned to event times\n",
    "    feats = make_features(close)\n",
    "    X = feats.reindex(labels.index).dropna()\n",
    "    y = labels.loc[X.index, \"label\"].astype(int)\n",
    "    w = sample_weights_from_trgt(labels.loc[X.index, \"trgt\"])\n",
    "\n",
    "    # 4) Time-series CV with calibration and threshold selection\n",
    "    tscv = TimeSeriesSplit(n_splits=KFOLDS)\n",
    "    oof_proba = pd.Series(index=X.index, dtype=float)\n",
    "    oof_pred  = pd.Series(index=X.index, dtype=int)\n",
    "    thrs = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(X), 1):\n",
    "        tr_ind = X.index[tr_idx]\n",
    "        va_ind = X.index[va_idx]\n",
    "        X_tr, y_tr, w_tr = X.loc[tr_ind], y.loc[tr_ind], w.loc[tr_ind]\n",
    "        X_va, y_va, w_va = X.loc[va_ind], y.loc[va_ind], w.loc[va_ind]\n",
    "\n",
    "        base = GradientBoostingClassifier(random_state=RNG_SEED)\n",
    "        base.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "\n",
    "        cal = make_calibrator(base, method=\"isotonic\", cv=\"prefit\")\n",
    "        # Fit calibrator on validation slice\n",
    "        cal.fit(X_va, y_va, sample_weight=w_va)\n",
    "\n",
    "        proba_va = pd.Series(cal.predict_proba(X_va)[:, 1], index=va_ind)\n",
    "        oof_proba.loc[va_ind] = proba_va\n",
    "\n",
    "        thr_f = choose_proba_threshold(y_va, proba_va)\n",
    "        thrs.append(thr_f)\n",
    "        oof_pred.loc[va_ind] = (proba_va >= thr_f).astype(int)\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_va, proba_va)\n",
    "        except Exception:\n",
    "            auc = float(\"nan\")\n",
    "        print(f\"Fold {fold}: AUC={auc:.3f}  thr={thr_f:.2f}\")\n",
    "\n",
    "    chosen_thr = float(np.median(thrs)) if thrs else 0.5\n",
    "    print(f\"\\nChosen probability threshold (median over folds): {chosen_thr:.2f}\")\n",
    "\n",
    "    # 5) Final fit on all data (refit + calibrate on last fold split)\n",
    "    tr_idx, va_idx = list(TimeSeriesSplit(n_splits=KFOLDS).split(X))[-1]\n",
    "    tr_ind = X.index[tr_idx]\n",
    "    va_ind = X.index[va_idx]\n",
    "    base = GradientBoostingClassifier(random_state=RNG_SEED)\n",
    "    base.fit(X.loc[tr_ind], y.loc[tr_ind], sample_weight=w.loc[tr_ind])\n",
    "    cal = make_calibrator(base, method=\"isotonic\", cv=\"prefit\")\n",
    "    cal.fit(X.loc[va_ind], y.loc[va_ind], sample_weight=w.loc[va_ind])\n",
    "\n",
    "    # 6) Backtest (long/flat on next-day return)\n",
    "    proba_all = pd.Series(cal.predict_proba(X)[:, 1], index=X.index)\n",
    "    signal = (proba_all >= chosen_thr).astype(int)\n",
    "\n",
    "    next_ret = close.pct_change().shift(-1)\n",
    "    ret_e = next_ret.reindex(signal.index)\n",
    "    pnl_gross = (signal * ret_e).fillna(0.0)\n",
    "\n",
    "    toggle = (signal != signal.shift(1)).fillna(False).astype(int)\n",
    "    avg_turn = float(toggle.mean())\n",
    "    if avg_turn > MAX_DAILY_TURNOVER and avg_turn > 0:\n",
    "        scale = MAX_DAILY_TURNOVER / avg_turn\n",
    "        # Keep signals numeric (0 or scaled 1). Turnover pattern is unchanged.\n",
    "        signal = (signal * scale)\n",
    "        toggle = (signal != signal.shift(1)).fillna(False).astype(int)\n",
    "        print(f\"Scaled signals to respect turnover cap. New avg daily turnover â‰ˆ {float(toggle.mean()):.3f}\")\n",
    "\n",
    "    tc = toggle * (TC_BP / 1e4)\n",
    "    pnl_net = pnl_gross - tc\n",
    "\n",
    "    # Metrics\n",
    "    def sharpe_ratio(x: pd.Series) -> float:\n",
    "        std = x.std()\n",
    "        if std == 0 or np.isnan(std):\n",
    "            return 0.0\n",
    "        return float(np.sqrt(252) * x.mean() / std)\n",
    "\n",
    "    def drawdown(x: pd.Series) -> float:\n",
    "        cum = (1 + x).cumprod()\n",
    "        peak = cum.cummax()\n",
    "        dd = (cum / peak - 1.0).min()\n",
    "        return float(dd)\n",
    "\n",
    "    sharpe = sharpe_ratio(pnl_net)\n",
    "    cagr_cum = (1 + pnl_net).cumprod()\n",
    "    if len(cagr_cum) > 1:\n",
    "        years_span = max(1e-9, (cagr_cum.index[-1] - cagr_cum.index[0]).days / 365.25)\n",
    "        cagr_val = float(cagr_cum.iloc[-1] ** (1 / years_span) - 1.0) if years_span > 0 else 0.0\n",
    "    else:\n",
    "        cagr_val = 0.0\n",
    "    maxdd = drawdown(pnl_net)\n",
    "    # Hit rate only when signal > 0 (post-threshold)\n",
    "    trade_mask = (signal > 0)\n",
    "    hit = float(((trade_mask) & (ret_e > 0)).sum() / max(1, trade_mask.sum()))\n",
    "\n",
    "    print(\"\\n=== Walk-forward Backtest (long/flat meta-signal) ===\")\n",
    "    print(f\"Sharpe: {sharpe:.3f}  CAGR: {100*cagr_val:.2f}%  MaxDD: {100*maxdd:.2f}%  Hit%: {100*hit:.2f}%\")\n",
    "    print(f\"Avg daily turnover: {float(toggle.mean()):.3f}  (Max cap {MAX_DAILY_TURNOVER})\")\n",
    "    print(f\"Avg daily TC paid (bp): {float((tc*1e4).mean()):.2f}\")\n",
    "\n",
    "    # 7) Save results\n",
    "    cv_df = pd.DataFrame({\n",
    "        \"proba\": oof_proba,\n",
    "        \"pred\":  oof_pred,\n",
    "        \"label\": y.reindex(oof_proba.index)\n",
    "    }).dropna()\n",
    "    bt_df = pd.DataFrame({\n",
    "        \"signal\": signal,\n",
    "        \"next_ret\": ret_e,\n",
    "        \"pnl_gross\": pnl_gross,\n",
    "        \"toggle\": toggle,\n",
    "        \"tc\": tc,\n",
    "        \"pnl_net\": pnl_net\n",
    "    }).dropna()\n",
    "\n",
    "    cv_name = f\"{TICKER}_level31_cv_summary.csv\"\n",
    "    bt_name = f\"{TICKER}_level31_backtest.csv\"\n",
    "    cv_df.to_csv(cv_name)\n",
    "    bt_df.to_csv(bt_name)\n",
    "    print(f\"\\nSaved: {cv_name}, {bt_name}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adaptive] events=674  H=10  thrâ‰ˆ0.002\n",
      "Fold 1: AUC=0.606  thr=0.40\n",
      "Fold 2: AUC=0.544  thr=0.40\n",
      "Fold 3: AUC=0.537  thr=0.40\n",
      "Fold 4: AUC=0.554  thr=0.40\n",
      "Fold 5: AUC=0.568  thr=0.40\n",
      "\n",
      "Chosen probability threshold (median over folds): 0.40\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_21984\\2875955321.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    332\u001B[39m         peak = cum.cummax()\n\u001B[32m    333\u001B[39m         dd = (cum / peak - \u001B[32m1.0\u001B[39m).min()\n\u001B[32m    334\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m float(dd)\n\u001B[32m    335\u001B[39m \n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m     sharpe = sharpe_ratio(pnl_net)\n\u001B[32m    337\u001B[39m     cagr_cum = (\u001B[32m1\u001B[39m + pnl_net).cumprod()\n\u001B[32m    338\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m len(cagr_cum) > \u001B[32m1\u001B[39m:\n\u001B[32m    339\u001B[39m         years_span = max(\u001B[32m1e-9\u001B[39m, (cagr_cum.index[-\u001B[32m1\u001B[39m] - cagr_cum.index[\u001B[32m0\u001B[39m]).days / \u001B[32m365.25\u001B[39m)\n",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_21984\\2875955321.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m    324\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m sharpe_ratio(x: pd.Series) -> float:\n\u001B[32m    325\u001B[39m         std = x.std()\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m std == \u001B[32m0\u001B[39m \u001B[38;5;28;01mor\u001B[39;00m np.isnan(std):\n\u001B[32m    327\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m0.0\u001B[39m\n\u001B[32m    328\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m float(np.sqrt(\u001B[32m252\u001B[39m) * x.mean() / std)\n",
      "\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1575\u001B[39m     @final\n\u001B[32m   1576\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m __nonzero__(self) -> NoReturn:\n\u001B[32m-> \u001B[39m\u001B[32m1577\u001B[39m         raise ValueError(\n\u001B[32m   1578\u001B[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001B[32m   1579\u001B[39m             \u001B[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001B[39m\n\u001B[32m   1580\u001B[39m         )\n",
      "\u001B[31mValueError\u001B[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
