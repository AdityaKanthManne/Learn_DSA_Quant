{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T02:33:06.059797Z",
     "start_time": "2025-11-10T02:33:05.129700Z"
    }
   },
   "source": [
    "# level41_roll_spread_estimator.py\n",
    "# Python-only, free data (yfinance). Roll (1984) effective spread estimator from daily closes.\n",
    "# Outputs:\n",
    "#   - CSV : level41_roll_timeseries.csv (Close, dP, gamma1, spread_$, spread_bps, valid flags)\n",
    "#   - JSON: level41_roll_metrics.json (summary stats)\n",
    "# Usage:\n",
    "#   python level41_roll_spread_estimator.py\n",
    "# Notes:\n",
    "#   - Works best on high-liquidity names. Daily closes are a proxy; tick data is superior but not free.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional, Dict\n",
    "import json\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    ticker: str = \"SPY\"\n",
    "    start: str = \"2005-01-01\"\n",
    "    end: Optional[str] = None\n",
    "    auto_adjust: bool = True           # True -> 'Close' is adjusted\n",
    "    window: int = 60                   # rolling window for autocovariance\n",
    "    min_obs: int = 40                  # minimum obs to trust estimate\n",
    "    clip_bps: float = 200.0            # clip extreme bps (sanity cap) for reporting only\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# ----------------------------- Loader -----------------------------\n",
    "def load_adjusted_close(tickers, start, end=None, auto_adjust=True) -> pd.DataFrame:\n",
    "    raw = yf.download(tickers, start=start, end=end, auto_adjust=auto_adjust, progress=False)\n",
    "    price_key = \"Close\" if auto_adjust else \"Adj Close\"\n",
    "    if isinstance(raw.columns, pd.MultiIndex):\n",
    "        out = raw[price_key].copy()\n",
    "    else:\n",
    "        name = tickers if isinstance(tickers, str) else tickers[0]\n",
    "        out = raw[[price_key]].rename(columns={price_key: name})\n",
    "    cols = tickers if isinstance(tickers, (list, tuple)) else [tickers]\n",
    "    out = out.reindex(columns=cols).dropna(how=\"all\")\n",
    "    return out\n",
    "\n",
    "# ----------------------------- Roll Core -----------------------------\n",
    "def roll_autocov_lag1(dp: pd.Series, window: int, min_obs: int) -> pd.Series:\n",
    "    \"\"\"Rolling first-order autocovariance of price changes (dp vs dp.shift(1)).\"\"\"\n",
    "    x = dp\n",
    "    xlag = dp.shift(1)\n",
    "    m0 = x.rolling(window, min_periods=min_obs).mean()\n",
    "    m1 = xlag.rolling(window, min_periods=min_obs).mean()\n",
    "    cov = ((x - m0) * (xlag - m1)).rolling(window, min_periods=min_obs).mean()\n",
    "    return cov\n",
    "\n",
    "def roll_spread_from_cov(gamma1: pd.Series) -> pd.Series:\n",
    "    \"\"\"Roll (1984) effective spread s = 2*sqrt(-gamma1) when gamma1<0; else NaN.\"\"\"\n",
    "    neg = (-gamma1).clip(lower=0.0)\n",
    "    return 2.0 * np.sqrt(neg)\n",
    "\n",
    "# ----------------------------- KPIs -----------------------------\n",
    "def summarize(close: pd.Series, spread_abs: pd.Series) -> Dict[str, float]:\n",
    "    # Convert to bps for stats too\n",
    "    bps = 1e4 * (spread_abs / close)\n",
    "    valid = spread_abs.notna()\n",
    "    out = {\n",
    "        \"avg_spread_bps\": float(bps[valid].mean()) if valid.any() else np.nan,\n",
    "        \"median_spread_bps\": float(bps[valid].median()) if valid.any() else np.nan,\n",
    "        \"p90_spread_bps\": float(bps[valid].quantile(0.90)) if valid.any() else np.nan,\n",
    "        \"pct_valid_days\": float(100 * valid.mean()),\n",
    "        \"n_days\": int(len(close)),\n",
    "        \"window\": int(CFG.window),\n",
    "        \"min_obs\": int(CFG.min_obs),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def build_roll_series(cfg: Config):\n",
    "    px = load_adjusted_close(cfg.ticker, start=cfg.start, end=cfg.end, auto_adjust=cfg.auto_adjust)\n",
    "    if isinstance(px, pd.DataFrame):\n",
    "        close = px[cfg.ticker].dropna()\n",
    "    else:\n",
    "        close = px.dropna()\n",
    "        close.name = cfg.ticker\n",
    "\n",
    "    dp = close.diff()\n",
    "    gamma1 = roll_autocov_lag1(dp, cfg.window, cfg.min_obs)\n",
    "\n",
    "    # Roll spread (absolute $)\n",
    "    spread_abs = roll_spread_from_cov(gamma1)\n",
    "\n",
    "    # Validity flag: only when gamma1 < 0 and enough obs\n",
    "    valid = (gamma1 < 0) & gamma1.notna()\n",
    "\n",
    "    # Spread in bps\n",
    "    spread_bps = 1e4 * (spread_abs / close)\n",
    "    # For reporting (optional), cap crazy tails (won't affect CSV raw values)\n",
    "    spread_bps_report = spread_bps.clip(upper=cfg.clip_bps)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Close\": close,\n",
    "        \"dP\": dp,\n",
    "        \"gamma1\": gamma1,\n",
    "        \"spread_$\": spread_abs,\n",
    "        \"spread_bps\": spread_bps,\n",
    "        \"valid\": valid.astype(float)  # 1.0/0.0 for easy averaging\n",
    "    }).dropna(subset=[\"Close\"])\n",
    "\n",
    "    metrics = summarize(close, spread_abs)\n",
    "\n",
    "    return out, metrics, {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"ticker\": cfg.ticker,\n",
    "        \"avg_spread_bps_report_capped\": float(spread_bps_report.dropna().mean()) if spread_bps_report.notna().any() else np.nan\n",
    "    }\n",
    "\n",
    "# ----------------------------- Main -----------------------------\n",
    "def main():\n",
    "    out, metrics, diag = build_roll_series(CFG)\n",
    "    ts_path = \"level41_roll_timeseries.csv\"\n",
    "    m_path  = \"level41_roll_metrics.json\"\n",
    "    d_path  = \"level41_roll_diagnostics.json\"\n",
    "\n",
    "    out.to_csv(ts_path, index=True)\n",
    "    with open(m_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    with open(d_path, \"w\") as f:\n",
    "        json.dump(diag, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved timeseries  → {ts_path}\")\n",
    "    print(f\"[OK] Saved metrics    → {m_path}\")\n",
    "    print(f\"[OK] Saved diagnostics→ {d_path}\")\n",
    "    print(\"Metrics summary:\", {k: round(v, 4) if v==v else None for k, v in metrics.items()})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved timeseries  → level41_roll_timeseries.csv\n",
      "[OK] Saved metrics    → level41_roll_metrics.json\n",
      "[OK] Saved diagnostics→ level41_roll_diagnostics.json\n",
      "Metrics summary: {'avg_spread_bps': 46.1314, 'median_spread_bps': 32.4737, 'p90_spread_bps': 98.5705, 'pct_valid_days': 98.4753, 'n_days': 5247, 'window': 60, 'min_obs': 40}\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
