{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T03:10:15.116469Z",
     "start_time": "2025-11-27T03:09:57.226672Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Level-54 — Random Forest Regime Classifier with Volatility-Sensitive Position Sizing\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "DSA concept (what you are practicing here)\n",
    "------------------------------------------\n",
    "This level is built to exercise three core DSA concepts:\n",
    "\n",
    "1) Sliding / rolling windows on time-series\n",
    "   We use rolling sums of returns to define a *forward* turbulence / volatility\n",
    "   proxy over a fixed horizon (e.g., 10 trading days). This is a classic\n",
    "   sliding window pattern over an array: at each index t, you aggregate\n",
    "   elements from t ... t+h-1. In pandas, rolling(...) is just a higher-level\n",
    "   implementation of a two-pointer / prefix-sum style algorithm.\n",
    "\n",
    "2) Trees and ensembles (Random Forests)\n",
    "   A Random Forest is a collection (ensemble) of decision trees. Each tree is a\n",
    "   recursively defined data structure:\n",
    "       - each node stores: split feature, threshold, left/right children,\n",
    "       - leaves store: class probabilities.\n",
    "   The forest itself is an array/list of these tree objects. Conceptually you\n",
    "   are working with hierarchical (tree) structures and a bag of them (an array\n",
    "   of trees), which is a classic DSA combination.\n",
    "\n",
    "3) Dictionaries + grid search with sorting\n",
    "   Hyperparameter tuning is implemented by:\n",
    "       - iterating over a small grid of (n_estimators, max_depth, min_samples_leaf),\n",
    "       - storing validation metrics and feature importances in dictionaries\n",
    "         keyed by a string describing that configuration,\n",
    "       - turning those into a DataFrame and sorting by a metric (like AUC).\n",
    "   This is a simple but extremely useful pattern in practice:\n",
    "       brute-force search over a grid → aggregate stats in dict → sort/argmax.\n",
    "\n",
    "Quant idea (what this model does financially)\n",
    "---------------------------------------------\n",
    "We build a **regime classifier** for a single asset (default SPY) using daily\n",
    "data. The label is not \"up vs down\", but whether the *magnitude* of forward\n",
    "10-day return moves is high or low:\n",
    "\n",
    "    fut_ret_h = sum_{i=0..h-1} r_{t+i}\n",
    "    turb_h    = |fut_ret_h|\n",
    "    y = 1 if turb_h > median(turb_h) else 0\n",
    "\n",
    "So y=1 roughly corresponds to \"high-turbulence / high-move regimes\" and y=0 to\n",
    "\"calmer regimes.\" Using past features (returns, volatility, momentum, etc.), a\n",
    "RandomForestClassifier is trained to predict this binary regime.\n",
    "\n",
    "Once we have probabilistic regime estimates on the test set, we define a very\n",
    "simple volatility-sensitive strategy:\n",
    "\n",
    "    - Position = 1.0 in calm regimes (predicted low turbulence).\n",
    "    - Position = 0.5 in predicted high-turbulence regimes (we cut risk in half).\n",
    "\n",
    "We then compute Sharpe ratio and a “regime hit-rate” (how often the predicted\n",
    "regime matches realized turbulence class) to see if the classifier improves\n",
    "risk-adjusted returns vs always being fully invested.\n",
    "\n",
    "External resources (to study similar ideas in practice)\n",
    "-------------------------------------------------------\n",
    "You can read about Random Forests with feature importance in the scikit-learn\n",
    "documentation and examples:\n",
    "    - scikit-learn: RandomForestClassifier user guide and examples.\n",
    "\n",
    "For finance / regime-context examples, search for:\n",
    "    - \"Random forest market regime classification\"\n",
    "    - \"Tree-based volatility state models\"\n",
    "    - \"Machine learning for volatility regimes scikit-learn\"\n",
    "You’ll find notebooks and blog posts where forests are used to classify bull /\n",
    "bear or high/low volatility states on equity indices and traded futures.\n",
    "\n",
    "Script summary\n",
    "--------------\n",
    "1) Downloads daily prices via yfinance and falls back to a synthetic geometric\n",
    "   random walk if download fails.\n",
    "2) Builds features: recent returns, volatility, momentum, Bollinger-band\n",
    "   position, and an RSI-like oscillator.\n",
    "3) Builds a turbulence label based on the absolute forward h-day return,\n",
    "   binarized at the median.\n",
    "4) Splits data chronologically into train / validation / test.\n",
    "5) Runs a small grid search over RandomForest hyperparameters using validation\n",
    "   AUC to select the best configuration.\n",
    "6) Re-fits the best forest on train+validation, evaluates on test, and computes\n",
    "   regime hit-rate and Sharpe of the volatility-sensitive strategy.\n",
    "7) Saves:\n",
    "     - Per-date test predictions to CSV.\n",
    "     - A feature-importance table across hyperparameters to CSV.\n",
    "     - A JSON with best model info and grid metrics.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "# ---------------------------- Config ---------------------------- #\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbol: str = \"SPY\"\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # labeling horizon (forward window) in trading days\n",
    "    label_horizon: int = 10\n",
    "\n",
    "    # train/val/test fractions (chronological)\n",
    "    train_frac: float = 0.6\n",
    "    val_frac: float = 0.2  # test_frac = 1 - train_frac - val_frac\n",
    "\n",
    "    # Random Forest hyperparameter grid\n",
    "    n_estimators_grid: List[int] = None\n",
    "    max_depth_grid: List[int] = None  # use None for \"no limit\"\n",
    "    min_samples_leaf_grid: List[int] = None\n",
    "\n",
    "    random_state: int = 54\n",
    "\n",
    "    # trading rule\n",
    "    position_high_turb: float = 0.5   # exposure in high-turbulence regimes\n",
    "    position_low_turb: float = 1.0    # exposure in low-turbulence regimes\n",
    "\n",
    "    # output paths\n",
    "    out_preds_csv: str = \"level54_rf_regime_predictions.csv\"\n",
    "    out_importance_csv: str = \"level54_rf_feature_importance_grid.csv\"\n",
    "    out_metrics_json: str = \"level54_rf_regime_metrics.json\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.n_estimators_grid is None:\n",
    "            self.n_estimators_grid = [100, 200]\n",
    "        if self.max_depth_grid is None:\n",
    "            self.max_depth_grid = [3, 5, None]\n",
    "        if self.min_samples_leaf_grid is None:\n",
    "            self.min_samples_leaf_grid = [1, 5]\n",
    "\n",
    "\n",
    "# ------------------------- Utility funcs ------------------------ #\n",
    "\n",
    "\n",
    "def synthetic_price_series(\n",
    "    n: int = 2500,\n",
    "    start_price: float = 100.0,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Fallback geometric random walk if yfinance fails.\"\"\"\n",
    "    rng = np.random.default_rng(54)\n",
    "    mu_daily = 0.06 / 252.0\n",
    "    sigma_daily = 0.2 / math.sqrt(252.0)\n",
    "    rets = rng.normal(mu_daily, sigma_daily, size=n)\n",
    "    prices = start_price * np.exp(np.cumsum(rets))\n",
    "    idx = pd.date_range(\"2010-01-01\", periods=n, freq=\"B\")\n",
    "    return pd.Series(prices, index=idx, name=\"close\")\n",
    "\n",
    "\n",
    "def load_price_series(cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust loader around yfinance.\n",
    "\n",
    "    Handles:\n",
    "        - Series\n",
    "        - DataFrame with OHLCV\n",
    "        - MultiIndex columns\n",
    "    and falls back to synthetic data on error/empty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        px = yf.download(\n",
    "            cfg.symbol,\n",
    "            start=cfg.start,\n",
    "            auto_adjust=True,\n",
    "            progress=False,\n",
    "        )\n",
    "    except Exception:\n",
    "        px = pd.DataFrame()\n",
    "\n",
    "    if px is None or len(px) == 0:\n",
    "        print(\"[WARN] yfinance download failed. Using synthetic price path.\")\n",
    "        close = synthetic_price_series()\n",
    "    else:\n",
    "        if isinstance(px, pd.Series):\n",
    "            close_obj = px\n",
    "        elif isinstance(px, pd.DataFrame):\n",
    "            if \"Close\" in px.columns:\n",
    "                close_obj = px[\"Close\"]\n",
    "            else:\n",
    "                if isinstance(px.columns, pd.MultiIndex):\n",
    "                    # Try to pick a (\"Close\", ticker) or similar\n",
    "                    candidates = [\n",
    "                        c\n",
    "                        for c in px.columns\n",
    "                        if str(c[0]).lower() == \"close\"\n",
    "                        or str(c[-1]).lower() == \"close\"\n",
    "                    ]\n",
    "                    if len(candidates) > 0:\n",
    "                        close_obj = px[candidates[0]]\n",
    "                    else:\n",
    "                        close_obj = px.iloc[:, 0]\n",
    "                else:\n",
    "                    # No \"Close\" column; pick first numeric column\n",
    "                    num_cols = px.select_dtypes(include=[np.number])\n",
    "                    if num_cols.shape[1] > 0:\n",
    "                        close_obj = num_cols.iloc[:, 0]\n",
    "                    else:\n",
    "                        close_obj = px.iloc[:, 0]\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected type from yfinance download.\")\n",
    "\n",
    "        # Make sure we have a 1D array\n",
    "        close_arr = np.asarray(close_obj, dtype=float).reshape(-1)\n",
    "        close = pd.Series(close_arr, index=close_obj.index, name=\"close\")\n",
    "\n",
    "    df = pd.DataFrame({\"close\": close.astype(float)})\n",
    "    df[\"ret\"] = np.log(df[\"close\"]).diff()\n",
    "    df = df.dropna().copy()\n",
    "    return df\n",
    "\n",
    "\n",
    "def sharpe_ratio(ret: pd.Series, ann_factor: float = 252.0) -> float:\n",
    "    \"\"\"Simple Sharpe estimate with ddof=1 for std.\"\"\"\n",
    "    if ret is None or len(ret) < 2:\n",
    "        return 0.0\n",
    "    mu = float(ret.mean())\n",
    "    sigma = float(ret.std(ddof=1))\n",
    "    if sigma <= 0:\n",
    "        return 0.0\n",
    "    return float(mu / sigma * math.sqrt(ann_factor))\n",
    "\n",
    "\n",
    "def hit_rate_binary(pred: pd.Series, true: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Hit-rate between two binary label series (0/1).\n",
    "    \"\"\"\n",
    "    aligned = pd.concat([pred, true], axis=1).dropna()\n",
    "    if aligned.shape[0] == 0:\n",
    "        return 0.0\n",
    "    return float((aligned.iloc[:, 0] == aligned.iloc[:, 1]).mean())\n",
    "\n",
    "\n",
    "# ----------------------- Feature engineering -------------------- #\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Feature set:\n",
    "\n",
    "    r1, r5, r20:\n",
    "        1, 5, 20 day log returns.\n",
    "    vol_10, vol_20:\n",
    "        rolling volatility of returns.\n",
    "    mom_20:\n",
    "        20-day log momentum.\n",
    "    bb_pos_20:\n",
    "        normalized position inside 20-day Bollinger band.\n",
    "    rsi_14:\n",
    "        RSI-like oscillator built from EWMA of up/down moves.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"r1\"] = out[\"ret\"].shift(1)\n",
    "    out[\"r5\"] = out[\"ret\"].rolling(5).sum().shift(1)\n",
    "    out[\"r20\"] = out[\"ret\"].rolling(20).sum().shift(1)\n",
    "\n",
    "    out[\"vol_10\"] = out[\"ret\"].rolling(10).std().shift(1)\n",
    "    out[\"vol_20\"] = out[\"ret\"].rolling(20).std().shift(1)\n",
    "\n",
    "    out[\"mom_20\"] = np.log(out[\"close\"] / out[\"close\"].shift(20))\n",
    "\n",
    "    rolling_mean = out[\"close\"].rolling(20).mean()\n",
    "    rolling_std = out[\"close\"].rolling(20).std()\n",
    "    out[\"bb_pos_20\"] = (out[\"close\"] - rolling_mean) / (rolling_std + 1e-12)\n",
    "\n",
    "    def rsi_like(ret: pd.Series, span: int = 14) -> pd.Series:\n",
    "        up = ret.clip(lower=0.0)\n",
    "        dn = -ret.clip(upper=0.0)\n",
    "        avg_up = up.ewm(alpha=1 / span, adjust=False).mean()\n",
    "        avg_dn = dn.ewm(alpha=1 / span, adjust=False).mean()\n",
    "        rs = avg_up / (avg_dn + 1e-12)\n",
    "        rsi = 100.0 - 100.0 / (1.0 + rs)\n",
    "        return rsi\n",
    "\n",
    "    out[\"rsi_14\"] = rsi_like(out[\"ret\"])\n",
    "\n",
    "    out = out.dropna().copy()\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_turbulence_labels(feat_df: pd.DataFrame, horizon: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Turbulence / regime label:\n",
    "\n",
    "        fut_ret_h(t) = sum_{i=0..h-1} ret_{t+i}\n",
    "        turb_h(t)    = |fut_ret_h(t)|\n",
    "\n",
    "    y = 1  (high-turbulence regime)  if turb_h > median(turb_h)\n",
    "        0  (low-turbulence regime)   otherwise\n",
    "    \"\"\"\n",
    "    rets = feat_df[\"ret\"]\n",
    "    # Forward horizon sum; use shift so window covers [t .. t+h-1]\n",
    "    fut_ret = rets.rolling(horizon).sum().shift(-horizon + 1)\n",
    "    turb = fut_ret.abs()\n",
    "\n",
    "    # Global median threshold (ignores NaNs)\n",
    "    thresh = float(turb.median(skipna=True))\n",
    "    y = (turb > thresh).astype(int)\n",
    "\n",
    "    labels = pd.DataFrame(\n",
    "        {\n",
    "            \"fut_ret_h\": fut_ret,\n",
    "            \"turb\": turb,\n",
    "            \"y\": y,\n",
    "        }\n",
    "    )\n",
    "    return labels\n",
    "\n",
    "\n",
    "# ---------------------- Time splits & model --------------------- #\n",
    "\n",
    "\n",
    "def chrono_splits(\n",
    "    data: pd.DataFrame,\n",
    "    train_frac: float,\n",
    "    val_frac: float,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Chronological splits: train, val, test.\n",
    "\n",
    "    Lengths:\n",
    "        n_train = floor(train_frac * n)\n",
    "        n_val   = floor(val_frac * n)\n",
    "        n_test  = n - n_train - n_val\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    n_train = int(train_frac * n)\n",
    "    n_val = int(val_frac * n)\n",
    "    n_test = n - n_train - n_val\n",
    "    if n_test <= 0:\n",
    "        raise ValueError(\"Not enough data for test split; adjust fractions.\")\n",
    "\n",
    "    train = data.iloc[:n_train].copy()\n",
    "    val = data.iloc[n_train : n_train + n_val].copy()\n",
    "    test = data.iloc[n_train + n_val :].copy()\n",
    "\n",
    "    return {\"train\": train, \"val\": val, \"test\": test}\n",
    "\n",
    "\n",
    "def rf_key(n_estimators: int, max_depth, min_leaf: int) -> str:\n",
    "    \"\"\"Helper to create a compact key for a RF config.\"\"\"\n",
    "    d = \"None\" if max_depth is None else str(max_depth)\n",
    "    return f\"n{n_estimators}_d{d}_leaf{min_leaf}\"\n",
    "\n",
    "\n",
    "def fit_rf_for_config(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series,\n",
    "    n_estimators: int,\n",
    "    max_depth,\n",
    "    min_leaf: int,\n",
    "    cfg: Config,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Fit a RandomForestClassifier for a given hyperparameter tuple,\n",
    "    and evaluate metrics on the validation set.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_leaf,\n",
    "        random_state=cfg.random_state,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    rf.fit(X_train.values, y_train.values)\n",
    "\n",
    "    proba_val = rf.predict_proba(X_val.values)[:, 1]\n",
    "    y_pred_val = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "    try:\n",
    "        auc_val = roc_auc_score(y_val.values, proba_val)\n",
    "    except ValueError:\n",
    "        auc_val = float(\"nan\")\n",
    "\n",
    "    acc_val = accuracy_score(y_val.values, y_pred_val)\n",
    "\n",
    "    importances = rf.feature_importances_.ravel()\n",
    "\n",
    "    return {\n",
    "        \"auc_val\": float(auc_val) if np.isfinite(auc_val) else float(\"nan\"),\n",
    "        \"acc_val\": float(acc_val),\n",
    "        \"importances\": importances,\n",
    "        \"rf\": rf,\n",
    "    }\n",
    "\n",
    "\n",
    "def refit_best_rf(\n",
    "    data_split: Dict[str, pd.DataFrame],\n",
    "    X_cols: List[str],\n",
    "    best_cfg: Dict[str, object],\n",
    "    cfg: Config,\n",
    ") -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Refit RF on train+val with the best hyperparameters,\n",
    "    return the fitted forest.\n",
    "\n",
    "    Fix: coerce max_depth into int or None, because grid_df turns None→NaN\n",
    "    and ints→floats like 3.0, which sklearn rejects.\n",
    "    \"\"\"\n",
    "    train = data_split[\"train\"]\n",
    "    val = data_split[\"val\"]\n",
    "    df_tv = pd.concat([train, val], axis=0)\n",
    "\n",
    "    X_tv = df_tv[X_cols]\n",
    "    y_tv = df_tv[\"y\"].astype(int)\n",
    "\n",
    "    raw_md = best_cfg[\"max_depth\"]\n",
    "    if raw_md is None:\n",
    "        max_depth = None\n",
    "    elif isinstance(raw_md, float):\n",
    "        if np.isnan(raw_md):\n",
    "            max_depth = None\n",
    "        else:\n",
    "            max_depth = int(raw_md)\n",
    "    else:\n",
    "        max_depth = int(raw_md)\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=int(best_cfg[\"n_estimators\"]),\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=int(best_cfg[\"min_samples_leaf\"]),\n",
    "        random_state=cfg.random_state,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    rf.fit(X_tv.values, y_tv.values)\n",
    "    return rf\n",
    "\n",
    "\n",
    "# ----------------------------- IO ------------------------------- #\n",
    "\n",
    "\n",
    "def save_predictions(\n",
    "    test_df: pd.DataFrame,\n",
    "    p_high: pd.Series,\n",
    "    regime_pred: pd.Series,\n",
    "    strat_ret: pd.Series,\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"close\": test_df[\"close\"],\n",
    "            \"ret\": test_df[\"ret\"],\n",
    "            \"fut_ret_h\": test_df[\"fut_ret_h\"],\n",
    "            \"turb\": test_df[\"turb\"],\n",
    "            \"label_y\": test_df[\"y\"],\n",
    "            \"p_high_turb\": p_high,\n",
    "            \"regime_pred\": regime_pred,\n",
    "            \"strat_ret\": strat_ret,\n",
    "        }\n",
    "    )\n",
    "    out.to_csv(cfg.out_preds_csv, index=True)\n",
    "    print(f\"[OK] Saved test predictions → {cfg.out_preds_csv}\")\n",
    "\n",
    "\n",
    "def save_importance_grid(\n",
    "    feature_names: List[str],\n",
    "    importance_map: Dict[str, np.ndarray],\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save feature importances for each hyperparameter configuration.\n",
    "\n",
    "    Rows = feature names\n",
    "    Columns = config keys (e.g. \"n100_d3_leaf1\")\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for feat_idx, feat in enumerate(feature_names):\n",
    "        row = {\"feature\": feat}\n",
    "        for key, imp_vec in importance_map.items():\n",
    "            if feat_idx < len(imp_vec):\n",
    "                row[key] = float(imp_vec[feat_idx])\n",
    "            else:\n",
    "                row[key] = float(\"nan\")\n",
    "        rows.append(row)\n",
    "\n",
    "    df_imp = pd.DataFrame(rows)\n",
    "    df_imp.to_csv(cfg.out_importance_csv, index=False)\n",
    "    print(f\"[OK] Saved feature importance grid → {cfg.out_importance_csv}\")\n",
    "\n",
    "\n",
    "def save_metrics(\n",
    "    best_row: Dict[str, object],\n",
    "    grid_df: pd.DataFrame,\n",
    "    test_metrics: Dict[str, float],\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    payload = {\n",
    "        \"best_config\": {\n",
    "            \"n_estimators\": int(best_row[\"n_estimators\"]),\n",
    "            \"max_depth\": (\n",
    "                None\n",
    "                if (\n",
    "                    isinstance(best_row[\"max_depth\"], float)\n",
    "                    and np.isnan(best_row[\"max_depth\"])\n",
    "                )\n",
    "                else best_row[\"max_depth\"]\n",
    "            ),\n",
    "            \"min_samples_leaf\": int(best_row[\"min_samples_leaf\"]),\n",
    "            \"val_auc\": float(best_row[\"auc_val\"]),\n",
    "            \"val_acc\": float(best_row[\"acc_val\"]),\n",
    "        },\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"grid_metrics\": grid_df.to_dict(orient=\"records\"),\n",
    "    }\n",
    "    with open(cfg.out_metrics_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2)\n",
    "    print(f\"[OK] Saved metrics → {cfg.out_metrics_json}\")\n",
    "\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_names: List[str],\n",
    "    importances: np.ndarray,\n",
    "    top_k: int = 10,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Simple bar plot of top_k features by importance for the best RF.\n",
    "    \"\"\"\n",
    "    if importances is None or len(importances) == 0:\n",
    "        return\n",
    "\n",
    "    idx_sorted = np.argsort(-importances)\n",
    "    top_idx = idx_sorted[:top_k]\n",
    "    top_feats = [feature_names[i] for i in top_idx]\n",
    "    top_vals = importances[top_idx]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(range(len(top_feats)), top_vals)\n",
    "    plt.yticks(range(len(top_feats)), top_feats)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(\"Random Forest Feature Importances (Top Features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --------------------------- Pipeline --------------------------- #\n",
    "\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    # 1) Load prices\n",
    "    df = load_price_series(cfg)\n",
    "    print(\n",
    "        f\"[INFO] Loaded {len(df)} rows from {df.index.min().date()} \"\n",
    "        f\"to {df.index.max().date()}\"\n",
    "    )\n",
    "\n",
    "    # 2) Features + labels\n",
    "    feat = build_features(df)\n",
    "    lab = build_turbulence_labels(feat, cfg.label_horizon)\n",
    "\n",
    "    data = pd.concat([feat, lab], axis=1).dropna().copy()\n",
    "\n",
    "    # 3) Chronological splits\n",
    "    splits = chrono_splits(data, cfg.train_frac, cfg.val_frac)\n",
    "    train = splits[\"train\"]\n",
    "    val = splits[\"val\"]\n",
    "    test = splits[\"test\"]\n",
    "\n",
    "    # X columns are everything except label and label-related columns\n",
    "    X_cols = [c for c in data.columns if c not in (\"y\", \"fut_ret_h\", \"turb\")]\n",
    "\n",
    "    X_train = train[X_cols]\n",
    "    y_train = train[\"y\"].astype(int)\n",
    "    X_val = val[X_cols]\n",
    "    y_val = val[\"y\"].astype(int)\n",
    "    X_test = test[X_cols]\n",
    "    y_test = test[\"y\"].astype(int)\n",
    "\n",
    "    print(\n",
    "        f\"[INFO] Split sizes — \"\n",
    "        f\"train: {len(train)}, val: {len(val)}, test: {len(test)}\"\n",
    "    )\n",
    "\n",
    "    # 4) Grid search over RF hyperparameters\n",
    "    results = []\n",
    "    importance_map: Dict[str, np.ndarray] = {}\n",
    "    rf_map: Dict[str, RandomForestClassifier] = {}\n",
    "\n",
    "    for n_est in cfg.n_estimators_grid:\n",
    "        for max_d in cfg.max_depth_grid:\n",
    "            for leaf in cfg.min_samples_leaf_grid:\n",
    "                key = rf_key(n_est, max_d, leaf)\n",
    "                print(f\"[INFO] Fitting RF config {key} ...\")\n",
    "                res = fit_rf_for_config(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_val,\n",
    "                    y_val,\n",
    "                    n_estimators=n_est,\n",
    "                    max_depth=max_d,\n",
    "                    min_leaf=leaf,\n",
    "                    cfg=cfg,\n",
    "                )\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"key\": key,\n",
    "                        \"n_estimators\": n_est,\n",
    "                        \"max_depth\": max_d,\n",
    "                        \"min_samples_leaf\": leaf,\n",
    "                        \"auc_val\": res[\"auc_val\"],\n",
    "                        \"acc_val\": res[\"acc_val\"],\n",
    "                    }\n",
    "                )\n",
    "                importance_map[key] = res[\"importances\"]\n",
    "                rf_map[key] = res[\"rf\"]\n",
    "\n",
    "    grid_df = pd.DataFrame(results).sort_values(\"auc_val\", ascending=False)\n",
    "    print(\"[INFO] Validation results (sorted by AUC):\")\n",
    "    print(grid_df)\n",
    "\n",
    "    # 5) Choose best config by validation AUC\n",
    "    best_row = grid_df.iloc[0].to_dict()\n",
    "    best_key = best_row[\"key\"]\n",
    "    print(\n",
    "        f\"[INFO] Best RF config = {best_key} with val AUC=\"\n",
    "        f\"{best_row['auc_val']:.4f}, acc={best_row['acc_val']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 6) Refit on train+val with best config\n",
    "    best_cfg = {\n",
    "        \"n_estimators\": best_row[\"n_estimators\"],\n",
    "        \"max_depth\": best_row[\"max_depth\"],\n",
    "        \"min_samples_leaf\": best_row[\"min_samples_leaf\"],\n",
    "    }\n",
    "    best_rf = refit_best_rf(splits, X_cols, best_cfg, cfg)\n",
    "\n",
    "    # 7) Evaluate on test\n",
    "    p_high_test = pd.Series(\n",
    "        best_rf.predict_proba(X_test.values)[:, 1],\n",
    "        index=X_test.index,\n",
    "        name=\"p_high_turb\",\n",
    "    )\n",
    "    regime_pred = (p_high_test >= 0.5).astype(int)\n",
    "\n",
    "    try:\n",
    "        auc_test = roc_auc_score(y_test.values, p_high_test.values)\n",
    "    except ValueError:\n",
    "        auc_test = float(\"nan\")\n",
    "\n",
    "    acc_test = accuracy_score(y_test.values, regime_pred.values)\n",
    "    regime_hit = hit_rate_binary(regime_pred, y_test)\n",
    "\n",
    "    # Strategy: lower exposure in predicted high-turbulence regimes\n",
    "    positions = pd.Series(\n",
    "        cfg.position_low_turb,\n",
    "        index=X_test.index,\n",
    "        name=\"position\",\n",
    "    )\n",
    "    positions[regime_pred == 1] = cfg.position_high_turb\n",
    "\n",
    "    strat_ret = positions * df[\"ret\"].loc[positions.index]\n",
    "    strat_ret.name = \"strat_ret\"\n",
    "\n",
    "    sharpe_strat = sharpe_ratio(strat_ret)\n",
    "    sharpe_buyhold = sharpe_ratio(df[\"ret\"].loc[strat_ret.index])\n",
    "\n",
    "    test_metrics = {\n",
    "        \"auc_test\": float(auc_test) if np.isfinite(auc_test) else float(\"nan\"),\n",
    "        \"acc_test\": float(acc_test),\n",
    "        \"regime_hit_rate\": float(regime_hit),\n",
    "        \"sharpe_strat\": float(sharpe_strat),\n",
    "        \"sharpe_buyhold\": float(sharpe_buyhold),\n",
    "        \"n_test\": int(len(test)),\n",
    "        \"position_high_turb\": float(cfg.position_high_turb),\n",
    "        \"position_low_turb\": float(cfg.position_low_turb),\n",
    "    }\n",
    "\n",
    "    print(\"[INFO] Test metrics:\")\n",
    "    for k, v in test_metrics.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    # 8) Save outputs\n",
    "    save_predictions(test, p_high_test, regime_pred, strat_ret, cfg)\n",
    "    save_importance_grid(X_cols, importance_map, cfg)\n",
    "    save_metrics(best_row, grid_df, test_metrics, cfg)\n",
    "\n",
    "    # 9) Plot feature importances for the best RF fit on train+val\n",
    "    try:\n",
    "        best_imp = best_rf.feature_importances_.ravel()\n",
    "        plot_feature_importance(X_cols, best_imp, top_k=10)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# ----------------------------- Main ----------------------------- #\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Make it Jupyter-safe by stripping unwanted CLI args\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]]\n",
    "    cfg = Config()\n",
    "    run_pipeline(cfg)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 4000 rows from 2010-01-05 to 2025-11-26\n",
      "[INFO] Split sizes — train: 2382, val: 794, test: 795\n",
      "[INFO] Fitting RF config n100_d3_leaf1 ...\n",
      "[INFO] Fitting RF config n100_d3_leaf5 ...\n",
      "[INFO] Fitting RF config n100_d5_leaf1 ...\n",
      "[INFO] Fitting RF config n100_d5_leaf5 ...\n",
      "[INFO] Fitting RF config n100_dNone_leaf1 ...\n",
      "[INFO] Fitting RF config n100_dNone_leaf5 ...\n",
      "[INFO] Fitting RF config n200_d3_leaf1 ...\n",
      "[INFO] Fitting RF config n200_d3_leaf5 ...\n",
      "[INFO] Fitting RF config n200_d5_leaf1 ...\n",
      "[INFO] Fitting RF config n200_d5_leaf5 ...\n",
      "[INFO] Fitting RF config n200_dNone_leaf1 ...\n",
      "[INFO] Fitting RF config n200_dNone_leaf5 ...\n",
      "[INFO] Validation results (sorted by AUC):\n",
      "                 key  n_estimators  max_depth  min_samples_leaf   auc_val  \\\n",
      "6      n200_d3_leaf1           200        3.0                 1  0.690790   \n",
      "7      n200_d3_leaf5           200        3.0                 5  0.690783   \n",
      "0      n100_d3_leaf1           100        3.0                 1  0.690564   \n",
      "1      n100_d3_leaf5           100        3.0                 5  0.690479   \n",
      "9      n200_d5_leaf5           200        5.0                 5  0.667046   \n",
      "3      n100_d5_leaf5           100        5.0                 5  0.662209   \n",
      "8      n200_d5_leaf1           200        5.0                 1  0.659842   \n",
      "2      n100_d5_leaf1           100        5.0                 1  0.658127   \n",
      "5   n100_dNone_leaf5           100        NaN                 5  0.635409   \n",
      "11  n200_dNone_leaf5           200        NaN                 5  0.632794   \n",
      "4   n100_dNone_leaf1           100        NaN                 1  0.622100   \n",
      "10  n200_dNone_leaf1           200        NaN                 1  0.620156   \n",
      "\n",
      "     acc_val  \n",
      "6   0.644836  \n",
      "7   0.646096  \n",
      "0   0.642317  \n",
      "1   0.646096  \n",
      "9   0.644836  \n",
      "3   0.643577  \n",
      "8   0.644836  \n",
      "2   0.646096  \n",
      "5   0.630982  \n",
      "11  0.632242  \n",
      "4   0.622166  \n",
      "10  0.613350  \n",
      "[INFO] Best RF config = n200_d3_leaf1 with val AUC=0.6908, acc=0.6448\n",
      "[INFO] Test metrics:\n",
      "  auc_test: 0.6590235737738559\n",
      "  acc_test: 0.6113207547169811\n",
      "  regime_hit_rate: 0.6113207547169811\n",
      "  sharpe_strat: 1.1849167522177286\n",
      "  sharpe_buyhold: 1.11037106756508\n",
      "  n_test: 795\n",
      "  position_high_turb: 0.5\n",
      "  position_low_turb: 1.0\n",
      "[OK] Saved test predictions → level54_rf_regime_predictions.csv\n",
      "[OK] Saved feature importance grid → level54_rf_feature_importance_grid.csv\n",
      "[OK] Saved metrics → level54_rf_regime_metrics.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHqCAYAAACZcdjsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAASMlJREFUeJzt3QmcTfX/+PH3jGEYjH3N2PcloQhliQwhqi+lEhJZS6TM9yuyhKSvpEU7RUqiUva+VF9N2pQlKTKZskYZS41w/4/35/c993/vuLP5zMy5c+f1fDyOcZZ77ueczzn3ft7ns9wwj8fjEQAAAACwEG7zYgAAAABQBBYAAAAArBFYAAAAALBGYAEAAADAGoEFAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAALq37+/VK1a1e1kAMhlEhMTpWDBgrJp0ya3k4IM+vvvvyUmJkaeeeYZt5OCXI7AAnDZ/PnzJSwszDtFRETIJZdcYgr2v/76q9vJC9rz5DuNGzdOgtG0adPknXfeydC2CQkJqR7flVdemS3p279/vzz88MPyzTffSLBxzsesWbMkt1q5cqU5v3nN5MmTpUWLFtK6dWvZuHFjqtd1yikUP0M+/fRTcw388ccfEszy588vo0ePlkceeUT++usvt5ODXCzC7QQA+P9fxtWqVTMf6p999pn5Evzvf/8r27dvN0//4H+efDVs2FCCNbD4xz/+IT179szwa/r06SPXXXed37IyZcpkW2AxadIkUzN12WWXZct75GUaWDz99NN5Krg4cuSILFiwwEyqXr168tprr/ltExcXJ0WKFJF//etfIf8ZooGF3mP6oKh48eISzAYMGGACrNdff13uvPNOt5ODXIrAAggSXbp0kcsvv9z8/6677pLSpUvLo48+Ku+995707t3b7eQF5XnKSqdOnZLChQuL25o2bSq333675GYaHBcoUEDCw/NmpXiwXEtuWLhwoal17d69u5kvV67cBdfzjBkzzOebW9d5dn2G5PZrTAOfTp06mYdaBBa4WHnzUx/IBa6++mrzd8+ePd5lZ86ckQkTJkizZs2kWLFi5otFt9uwYUOqzUief/55qVGjhkRGRsoVV1whX3zxxQXvpc119Imd1ozo3+XLl6f6ZTZmzBjTFlf3V6dOHfMeHo/Hbzt97xEjRshbb70l9evXl0KFCknLli1l27ZtZv1zzz0nNWvWNO/Xrl07k96s8p///MecEz03+kXZo0cP2blzp982+gRZ0/jdd9/JrbfeKiVKlJCrrrrKr3Ck51jTXbJkSbnllltMu3FfP/74o9x0001Svnx5cxyVKlUy2x0/ftx7DvR86ZNbp7mFPrW09f3335taEE2Xvq8WkDT49HXs2DG5//77pVGjRubJcHR0tClMffvtt95ttImKXg/Ok0onjVqoUFqLESi9ml86+e5HX/fGG2/I+PHjTTO+qKgoSUpKMus3b94snTt3NterLm/btu1Ft713mrJoTd4999xjanI0j++++25zb2hzkzvuuMPkp04PPPCA37Xpe1/Mnj1bqlSpYvJY06Q1g1l5Lem509oKFai5j6ahVatWUqpUKZMGvd6WLl16QRqce8m5R/W+a9CggaxevfqCbbXp5MCBA6VixYpmO30qP3ToUHNuHHqORo0a5b2H9T7UBxjnz5/325fmp6apaNGi5vrRa2nOnDnp5pGmU5tB6XWXGT/99JP06tXLXNd6nWjzvw8++MBvG+dae/PNN+Wf//ynufc0b66//voL7k8bq1at8ua7Hn/Xrl1lx44dftts3brV5HH16tXNfahp0cL40aNH/a6NsWPHmv9rXjjXgF6HzrXo3G++dLlvLVdOfF45rr32WnN/6WcIcDGosQCClFPY1i8RhxbWXnzxRdNcZtCgQXLixAl56aWXJDY2Vj7//PMLmrNolbZuowUv/WKaOXOm3HjjjeZLXNvUqrVr15ovHA0Apk+fbr4YtaCpXzy+tICmX+AaxGjhRd9rzZo15otTCzRaUPP1ySefmALv8OHDzbzuu1u3bqawpx0Ehw0bJr///rtJk34hayEuI/SL8LfffvNbpk8/1fr1600BWr/s9cv4zz//lLlz55q23l9//fUFndG1IFOrVi3TZMkpgGob44ceesjUEmnNkTbt0H20adNGtmzZYgqYWlDTc56cnCwjR440X9Z6Dt5//31TcNNCtDb/0Nc3b95cBg8ebPatAV56Tp8+fcHx6f40v7Rwo8eihXdtsqAFnyVLlpimVm+//bbccMMNZnvNXy3g6fFpgebQoUMmmNMCtBZOtOCpTVS0SYgGqpo+J5DVwu7FmDJliqml0IBGz4v+X/NU80MLPRMnTjQ1GK+88opcc8015vrQc3MxnHOuTUy02aAGz5ov2uykcuXKJj+1GdJjjz1mCuMabPh69dVXzX2h16bWrmiBWdOkga8+Yc+Ka6lJkyamqdm6desuaAqk9D31frrtttvM9aQFed2HXkNakPWlBb1ly5aZe0YLuk8++aS5Z/ft22cCE6XvpedTrz/Nz7p165prUoMVvaY0P/SvXgO6XD8T9FzpOdOmSQcOHJAnnnjC7EvTrJ8xHTp0MEGH0oBKA8J77703zQ7A+uBCg5nM0OtTrztNnwaMekwakOv50fQ717VD71H9PHvwwQfl8OHDJt0dO3Y0fYW0cG3zGaJ51a9fP3N/67Frmp599llTkNf738l3PUd6n+lnpV6Lem/qdah/9ZrU9Oln7Q8//CCLFy82n4/Oe2hArJ8rmZWdn1cOvVd133pd6Oc1kGkeAK565ZVX9BvCs379es+RI0c8iYmJnqVLl3rKlCnjiYyMNPOOs2fPepKTk/1e//vvv3vKlSvnufPOO73L9u7da/ZZqlQpz7Fjx7zL3333XbN8xYoV3mWXXXaZp0KFCp4//vjDu2zt2rVmuypVqniXvfPOO2bZ1KlT/d7/H//4hycsLMyze/du7zLdTtOu6XA899xzZnn58uU9SUlJ3uVxcXFmue+2aZ2nQJPvsZQtW9Zz9OhR77Jvv/3WEx4e7rnjjju8yyZOnGhe16dPH7/3SEhI8OTLl8/zyCOP+C3ftm2bJyIiwrt8y5Yt5vVvvfVWmmkuXLiwp1+/fp6McPIs0LRhwwazTYcOHTyNGjXy/PXXX97XnT9/3tOqVStPrVq1vMt0/blz5y7Yv+bJ5MmTvcu++OILs389tylp3gdKe9u2bc3k0LTpPqpXr+45ffq0X7o0TbGxseb/Dt2mWrVqnmuvvTZD5+Oxxx674BpIuc+WLVuaa3DIkCF+90qlSpX80urss1ChQp5ffvnFu3zz5s1m+X333Zdl15IaPny43/Xpy/dcqTNnzngaNmzoueaaa/yW6+sLFCjgd39pOnT53Llzvcs0TZo2zdOUnHM1ZcoUc03+8MMPfuvHjRtnrvt9+/aZ+XvvvdcTHR1tzmFmaBpTpiuQBg0a+OXLqFGjzOs++eQT77ITJ06Y66Rq1area9m51i655BK/z5AlS5aY5XPmzLH6DNH3LF68uGfQoEF+rzt48KCnWLFifstT5p9avHix2dfHH3/sXabXb6DPN+daDHTv6XK9rnL680rt37/fbPvoo4+muy0QCE2hgCChT9z0SZY2UdCmLvo0Wp/4+9Yc5MuXzzx5VNp0Qaurz549a5rD6FPUlG6++Wa/Gg/nqbQ+aVP6lFKf8ukTOt+nVlodrjUYvvQJsL6/PlH0pU2j9LtQmw/40qedvk91tXmE0iet+tQ15XInTenR5iX6tNB38j0WbZ6gzQEcl156qTkeTX9KQ4YM8ZvXp8J6XvXpnz7RdCZ9wqdPCp0mZ8650hobfaKZlfRpc8rja9y4sclrrQHQtOnTdidtWsOkTyO1qYMzipg2cXH6N5w7d85so01TtOlaoOskK+g15Pu0WPNC06RNN/T9nfRq8zC9Nj7++OMLmt9klNaY+TYr0mtIr0Fd7tBrVe+LQNeV1vBorY9Dn/TrPpxrJCuupfT4niutudOn6Hp/Bsof/Wzwre3SdGjzJOfY9DxqDZX2awjUd8A5V9o0Ud9DPxN8r2/dv14nmidKn3JrPjn3VkY5zYB8P3MyQs+n5oFv8x69XvVe0JpbrWXzpTVQvp8h+nlZoUKFgPmSmc8Q/atP8LW2xvf86LWk14dvk1Pf/NNaL93OGb0tu+6xnPi8cvIuZY0OkFE0hQKChH7Z1a5d2xQwXn75ZfMlrwXElLSJwOOPP27a2mvTA0fKUU6UNnUI9KWhBRn1888/m7/6JZRSykKobqtNaHy/0JU2qfHdV2rv7Xy5aeAUaLmTpvRoASRQ4cl5f013SppG/VJN2eEx5TnTgrAWUAOdD+U0H9PX6dCM//73v2XRokWmsKbNNrQzqm+AdjH0vbWgl5I2ddO0abMHnQLRZiFaYNbChja10SZne/fuNYVGh9N0JqsFOpdOwJEavdYzWwjN7LUV6LoKlL9672mzsqy6ltKjzVCmTp1qAhhtouIINOxqyuNVet6cY9PmL9pMMr2RjTRPtG9AaqOM6fWjtMmVngttCqbXk3bo1cKr9pXJiJR9rtKj59t5wJDaZ4vvsaXMPz1n2lcko321UvsMca5ZbRYXiAZzDg30tSmeNmFzzpsjZb+FrJITn1dO3uXE8L8ITQQWQJDw/bLTJ6r69E6f9u7atcvbEVI76elTVF2vfRvKli1rnqZp/wXfTt4OXZcVX/wXI7X3djNNKaVsj60Fcv1C1dqXQOn07ZCqwZ3mxbvvvmv6qWhNjuaDtq9O2T8lKzhP97UPg9ZQBKKFK6VtsDX40L4r2vdBn7prDYZ22s1oLUFqBQsNUgKdm0DnUmk/h9SGss1sB9+LubZy6rrKSNt+h/Yv0YKdtoPX4E+ftmshUPufaL+o7LpnNE+0xkX7OQWiwZXSzxUNeDSA0ntBJ02b1hQ4w8gG4gStGX1IEGyca1b7WehT/5R0tCuHBlraD0E/h/X61mtZX6/BV0busbTuLzc/r5y8c/qDAJlFYAEEISdYaN++vTz11FPeH2/SjozamVSrwH2/mLRj7MXQUXF8n9T50oAm5bbaoVWb4fjWWmjNie++3OK8f8p0O2nUL8r0hmfU5iZaWNMnfE4hKy06Uo5OOhqSFjK0Y++8efPMk+isfuqn+a60ABqoRsOXXid67WjHfl/azMO3wJBW+vSJeKAf9dKnx05a0uI03dGnvOmlN6cFut61k63TdC8rrqW0zq92tNeRebTg7lsrqYX3i6E1EHqeA41slTJPTp48maH80CaX2rRKJy3Aai2GDgCgAasTwAaqWdHCr9aSZYae79TOtbM+rfzTe3b37t2miZgN55rVwCqtc6SF7w8//NDUWOjgB6mlK61rwKmpS3mPpaz5zcnPK+XknVNbBGQWfSyAIKVDemotho544vwSqvNUyvdJpQ7nGR8ff1HvoU9K9WmbPoX0rb7XtsYp2zXrj7bp0zQNdHzpaCf65anNJtzkeyy+X9Za2NIndCl/dC4QHcVFz7EWGFI+DdZ5pw25NjvRvi2+9AtbawV8m7Vo4TOrfnFXCzt6TWjhTvsApOQ7yoweQ8r0a/v6lL/k7hSOA6VRCy36NNN3qFJtvpPRYT11dBndhw6rqoXZtNKb07Q/gu+50GZmeh8513BWXEtpnV/NH71nfJ9OazOejP5Ke0p63Wkt5ooVK+TLL7+8YL1zLehTdv2s0IAmJU2jc037Dpnq7N8ptPte3ylp0Ku1roHSkBY9n5oHvp9j2tRMR1nSYC9lfy9nVC/fQFrvCdvPIK0J1ABNa/x8m5mmvGYDfQ4rZ1StjFwD+j4aoDr9Whxag5VRWf15pb766itzberw4MDFoMYCCGJaza5DDOpY59pxT4f/09oKHX5Rh6TUp0v6xEm/eAMV3jJCa0Z0X9r0SpvOaNthHa5Qx8r33ac+udSn4PpruVoI0g7FWsjSqnVtYpORoVSzmza70cKFfilqR15niFBtR5yRXz/WY9Cndzr8ph6jFta0dkbPs/62h3Ym1aZI2olaf1tA80afFOqXtjaf0C957ZzuW7jWWh5t26z9U/TJYqC25Jnph6P5pIUCHW5Yaw50qE4tkP3yyy/e36nQ60SHktWhMHUYTx1GVdtWp6xp0OPVjrp6DelxaiFI06fp1KErtcCmTTu0QKpN7bQpXkbzWQstOjSy5odeS5oWba+vBXrtVKoFKy0Iu0GfuOt51GFRtWClBUJtxuPbRMj2WnLyX2mzEy206vWhvx2g95teE3putbmjttHXvNV0aR+Ii6GFYb0fdThZvU71ibMWtjWg1OFqNZ/180QHhNDrQ5vFaPq0AK/Xh+a1XvNa2NW8188B7WugzWT0KboeuwZb6T3J1t/60M8ILcz69klIi9bI6pCser71XGnTPQ3q9L7T2p2UP7So6zX/9JrS61/zT8+d3hM2NL06tGzfvn3ND1VqXmltkA7rq7+poU/49cGKbqfN2HSobA1A9LrWcx+opsa5BvSc6P40+NLPUr3X9DzrjwXqXw3INMjQmrOMyurPK+ehkh5ndvXFQh4QcKwoADnGGQIx0DCROsxijRo1zKRDP+qwkdOmTTNDgerQoU2aNPG8//77ZlhQ36FhAw3VmdpQhurtt9/21KtXz+yzfv36nmXLll2wT2c4Rh2Ss2LFip78+fOb4UT1PXyH/nTeQ4fa9JVampwhJNMbCjGt8+RLh+1t3bq1GVJUh8zs3r2757vvvvPbxhm+UYf3DUTPx1VXXWWG5tSpbt265nh27dpl1v/0009meF/Nl4IFC3pKlizpad++vXlvX99//72nTZs2Ji36fmkNPZtWnvnas2ePGVpUh+3VPNChN7t162aGKPYdbnbMmDFmGGF9bz0f8fHxFwwV6wxBrHmuw1OmHP7y8ccfN/vX60L38eWXX6Y63Gxq+adDXd54441m6GPdj15TvXv39nz44YcXPdxsymsgtfzU8635F2ifemwxMTEmTVdffbUZwjWrryW9Z0eOHGmGjtbhcH2/cl966SVz/+j76/Wlx+bsK717KbXhgH/++WdzbThDVesQwPpa3yGq9R7WIZ5r1qxphrEtXbq0Ga541qxZZshbpddSp06dzHC7uk3lypU9d999t+fAgQOe9Bw6dMhcS6+99lqGh5t1rmsdulqHe9V7qnnz5uazzZdzremwrnoMmj7Nm65du5pjT09GP0P0fXRIYx1iVtOi93n//v3N9e/Q4YpvuOEGk17drlevXt6hWlN+vuowv3of6XDAvkPP6pC1AwcONK8vWrSouS8OHz6c6nCz2f15pUOOa36/+OKL6Z5LIDVh+o/bwQ0AANlNn+pqbYzWRuiTXGQPreHRJ+/aST0r6S9va62p1sLoELPIWlrzo7UwWjuZmcEIAF/0sQAAAFlGB5PQX+DWX+pG7qBNurR5nnbsJqiADfpYAACALKOjQzkDTiB30L4f2pcEsEWNBQAAAABr9LEAAAAAYI0aCwAAAADWCCwAAAAAWKPzdg47f/687N+/3/yIjf66JQAAABCstNeE/tq9/tBryh+sTInAIodpUBETE+N2MgAAAIAMS0xMlEqVKqW5DYFFDtOaCidzoqOj3U4OAAAAkKqkpCTzUNwpw6aFwCKHOc2fNKggsAAAAEBukJEm/HTeBgAAAGCNwAIAAACANQILAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANQILAAAAANYILAAAAABYi7DfBS5Gw4lrJDwyyu1kAAAAIIglzOgquQU1FgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAAAABrIR9YhIWFyTvvvON2MgAAAICQFvKBRUYlJCTIwIEDpVq1alKoUCGpUaOGTJw4Uc6cOeO33datW+Xqq6+WggULSkxMjMycOdO1NAMAAADBIsLtBASL77//Xs6fPy/PPfec1KxZU7Zv3y6DBg2SU6dOyaxZs8w2SUlJ0qlTJ+nYsaPMmzdPtm3bJnfeeacUL15cBg8e7PYhAAAAAK4J6hqL559/XipWrGgK/L569OhhCvTq2WefNbULBQoUkDp16shrr712Ue/VuXNneeWVV0zgUL16dbn++uvl/vvvl2XLlnm3WbRokanBePnll6VBgwZyyy23yD333CP//ve/LY8UAAAAyN2COrDo1auXHD16VDZs2OBdduzYMVm9erXcdtttsnz5crn33ntlzJgxpobh7rvvlgEDBvhtb+P48eNSsmRJ73x8fLy0adPGBDGO2NhY2bVrl/z+++9Z8p4AAABAbhTUgUWJEiWkS5cu8vrrr3uXLV26VEqXLi3t27c3TZT69+8vw4YNk9q1a8vo0aPlxhtv9DZdsrF7926ZO3euCVYcBw8elHLlyvlt58zrukCSk5NNEyrfCQAAAAg1QR1YKK2ZePvtt00B3WmOpE2QwsPDZefOndK6dWu/7XVel9v49ddfTdMorTHRfhY2pk+fLsWKFfNO2uEbAAAACDVBH1h0795dPB6PfPDBB5KYmCiffPKJCTayy/79+01tSKtWrUwfD1/ly5eXQ4cO+S1z5nVdIHFxcaZJlTPpMQAAAAChJugDCx3WVZs3aU3F4sWLTQftpk2bmnX16tWTTZs2+W2v8/Xr17/omop27dpJs2bNTEdurRXx1bJlS/n444/l77//9i5bt26dSZM22wokMjJSoqOj/SYAAAAg1OSK4Wa1hqJbt26yY8cOuf32273Lx44dK71795YmTZqYIWBXrFhhRnFav379RQcVVapUMX00jhw54l3n1EbceuutMmnSJPN7Fw8++KDpMD5nzhyZPXt2Fh0pAAAAkDvlisDimmuuMaMz6ehLWrh39OzZ0xTsNRDQ0aH0x+20pkEDhMzSmgftsK1TpUqV/NZpUyylfSTWrl0rw4cPN7Ua2ol8woQJ/IYFAAAA8rwwj1NqRo7QUaFMJ+5RSyQ8Msrt5AAAACCIJczoGhRlV+0rnF6T/qDvYwEAAAAg+OWZwGLatGlSpEiRgJP+VgYAAACAEO9jkRWGDBliOnoHUqhQoRxPDwAAABBK8kxgoZ2/dQIAAACQ9fJMUygAAAAA2YfAAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgLc+MChVstk+KTffXCwEAAIDcghoLAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFhjuFmXNJy4RsIjo9xOBgAAwAUSZnR1OwnIhaixAAAAAGCNwAIAAACANQILAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgLeQDi7CwMHnnnXfcTgYAAAAQ0kI+sMiMRx55RFq1aiVRUVFSvHjxgNvs27dPunbtarYpW7asjB07Vs6ePZvjaQUAAACCSYTbCQgmZ86ckV69eknLli3lpZdeumD9uXPnTFBRvnx5+fTTT+XAgQNyxx13SP78+WXatGmupBkAAAAIBkFdY/H8889LxYoV5fz5837Le/ToIXfeeaf5/7PPPis1atSQAgUKSJ06deS111676PebNGmS3HfffdKoUaOA69euXSvfffedLFy4UC677DLp0qWLTJkyRZ5++mkTlAAAAAB5VVAHFlp7cPToUdmwYYN32bFjx2T16tVy2223yfLly+Xee++VMWPGyPbt2+Xuu++WAQMG+G2fleLj403QUa5cOe+y2NhYSUpKkh07dgR8TXJyslnvOwEAAAChJqgDixIlSphagddff927bOnSpVK6dGlp3769zJo1S/r37y/Dhg2T2rVry+jRo+XGG280y7PDwYMH/YIK5czrukCmT58uxYoV804xMTHZkjYAAADATUEdWCitmXj77bfNk3+1aNEiueWWWyQ8PFx27twprVu39tte53V5sIiLi5Pjx497p8TERLeTBAAAAOS9wKJ79+7i8Xjkgw8+MIXyTz75xAQbbtBO24cOHfJb5szrukAiIyMlOjrabwIAAABCTdAHFgULFjTNm7SmYvHixaaDdtOmTc26evXqyaZNm/y21/n69etnS1p0tKht27bJ4cOHvcvWrVtngoXsek8AAAAgN8gVw81qDUW3bt1MB+nbb7/du1x/Q6J3797SpEkT6dixo6xYsUKWLVsm69evv6j30d+o0M7h+leHlv3mm2/M8po1a0qRIkWkU6dOJoDo27evzJw50/SrGD9+vAwfPtzUTAAAAAB5Va4ILK655hopWbKk7Nq1S2699Vbv8p49e8qcOXNMZ20dHapatWryyiuvSLt27S7qfSZMmCALFizwzmvAonSUKd1nvnz55P3335ehQ4ea2ovChQtLv379ZPLkyVlwlAAAAEDuFebRDgzIMTrcrBkdatQSCY+Mcjs5AAAAF0iY0dXtJCDIyq46CFF6fYWDvo8FAAAAgOCXZwKLadOmmX4SgSb9rQwAAAAAId7HIisMGTLEdPQOpFChQjmeHgAAACCU5JnAQjt/6wQAAAAg6+WZplAAAAAAsg+BBQAAAABrBBYAAAAArBFYAAAAALCWZzpvB5vtk2LT/ZERAAAAILegxgIAAACANQILAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFjjdyxc0nDiGgmPjHI7GQAQFBJmdHU7CQAAS9RYAAAAALBGYAEAAADAGoEFAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKyFfGBRtWpVeeKJJ9xOBgAAABDSQj6w+OKLL2Tw4MEZ2vb555+Xdu3aSXR0tISFhckff/yR6rbJycly2WWXme2++eabLEwxAAAAkPvk+sDizJkzaa4vU6aMREVFZWhfp0+fls6dO8s///nPdLd94IEHpGLFihlOJwAAABDKcl1goTUKI0aMkFGjRknp0qUlNjZWHn74YalcubJERkaawv4999xzUU2hdJ/jxo2TK6+8Ms3tVq1aJWvXrpVZs2ZZHw8AAAAQCnJdYKEWLFggBQoUkE2bNpkahtmzZ8tzzz0nP/74o7zzzjvSqFGjbHvvQ4cOyaBBg+S1117LcE0IAAAAEOoiJBeqVauWzJw50/w/f/78Ur58eenYsaP5v9ZcNG/ePFve1+PxSP/+/WXIkCFy+eWXS0JCQrqv0b4YOjmSkpKyJW0AAACAm3JljUWzZs28/+/Vq5f8+eefUr16dVOTsHz5cjl79my2vO/cuXPlxIkTEhcXl+HXTJ8+XYoVK+adYmJisiVtAAAAgJtyZWBRuHBh7/+1oL5r1y555plnpFChQjJs2DBp06aN/P3331n+vv/5z38kPj7e9OWIiIiQmjVrmuVae9GvX7+Ar9Eg5Pjx494pMTExy9MFAAAAuC1XNoVKSQOK7t27m2n48OFSt25d2bZtmzRt2jRL3+fJJ5+UqVOneuf3799vOo+/+eab0qJFi4Cv0SBEJwAAACCU5frAYv78+XLu3DlTsNfO1AsXLjSBRpUqVTK9r4MHD5pp9+7dZl6Dk6JFi5p+GyVLljR/fRUpUsT8rVGjhlSqVCmLjggAAADIfXJlUyhfxYsXlxdeeEFat24tl156qaxfv15WrFghpUqVyvS+5s2bJ02aNDF9NZQ2qdL59957LxtSDgAAAISOMI8OdYQco6NCmU7co5ZIeCTD1QKASpjR1e0kAADSKLtqX+Ho6GgJ6RoLAAAAAO7LM4HFokWLTJ+IQFODBg3cTh4AAACQq+X6ztsZdf3116c6cpP+sB4AAACAi5dnAgsd3UknAAAAAFkvzzSFAgAAAJB9CCwAAAAAWCOwAAAAAGCNwAIAAACANQILAAAAANbyzKhQwWb7pNh0f70QAAAAyC2osQAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANYabdUnDiWskPDLK7WQAISlhRle3kwAAQJ5DjQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAGoEFAAAAAGsEFgAAAACsEVhkQrt27SQsLMxvGjJkiNvJAgAAAFwX4XYCcoszZ86Yv4MGDZLJkyd7l0dFRbmYKgAAACA4EFikUTvRsGFDiYiIkIULF0qjRo28gUT58uXdTh4AAAAQVGgKlYYFCxZIgQIFZNOmTTJv3jyzbNGiRVK6dGkTdMTFxcnp06fT3EdycrIkJSX5TQAAAECoocYiDbVq1ZKZM2d652+99VapUqWKVKxYUbZu3SoPPvig7Nq1S5YtW5bqPqZPny6TJk3KoRQDAAAA7iCwSEOzZs385gcPHuz9vzaNqlChgnTo0EH27NkjNWrUCLgPrdUYPXq0d15rLGJiYrIx1QAAAEDOI7BIQ+HChdNc36JFC/N39+7dqQYWkZGRZgIAAABCGX0sLHzzzTfmr9ZcAAAAAHkZNRYZpM2dXn/9dbnuuuukVKlSpo/FfffdJ23atJFLL73U7eQBAAAAriKwyCAdHWr9+vXyxBNPyKlTp0w/iZtuuknGjx/vdtIAAAAA1xFYpGLjxo1+8xpIfPTRR66lBwAAAAhm9LEAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWOMH8lyyfVKsREdHu50MAAAAIEtQYwEAAADAGoEFAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKzxOxYuaThxjYRHRrmdDOCiJMzo6nYSAABAkKHGAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANQKL/zl27JiMHDlS6tSpI4UKFZLKlSvLPffcI8ePH/fbbt++fdK1a1eJioqSsmXLytixY+Xs2bOupRsAAAAIBhFuJyBY/PLLL7J//36ZNWuW1K9fX37++WcZMmSIWbZ06VKzzblz50xQUb58efn000/lwIEDcscdd0j+/Pll2rRpbh8CAAAA4Jowj8fjkTyoXbt20rBhQ4mIiJCFCxdKo0aNZMOGDX7bvPXWW3L77bfLqVOnzHarVq2Sbt26mWCjXLlyZpt58+bJgw8+KEeOHJECBQqk+75JSUlSrFgxiRm1RMIjo7Lt+IDslDCjq9tJAAAAOcApu2ornujo6DS3zdNNoRYsWGCCgU2bNpkAISXnBGpQoeLj400A4gQVKjY21pzwHTt25GjaAQAAgGCSp5tC1apVS2bOnBlw3W+//SZTpkyRwYMHe5cdPHjQL6hQzryuCyQ5OdlMDg1CAAAAgFCTp2ssmjVrFnC5Fv61L4X2tXj44Yet3mP69Omm+siZYmJirPYHAAAABKM8HVgULlz4gmUnTpyQzp07S9GiRWX58uWmY7ZDO20fOnTIb3tnXtcFEhcXZ5pUOVNiYmKWHwcAAADgtjwdWASqqejUqZPpd/Hee+9JwYIF/da3bNlStm3bJocPH/YuW7dunemHobUbgURGRpr1vhMAAAAQaggsUgQVOgLUSy+9ZOa134ROOsys0vUaQPTt21e+/fZbWbNmjYwfP16GDx9uAggAAAAgr8rTnbd9ff3117J582bz/5o1a/qt27t3r1StWlXy5csn77//vgwdOtTUXmhTqn79+snkyZNdSjUAAAAQHPJsYLFx48YLftciIz/pUaVKFVm5cmU2pgwAAADIfWgKBQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAWp795W23bZ8UK9HR0W4nAwAAAMgS1FgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBrDzbqk4cQ1Eh4Z5XYykIslzOjqdhIAAAC8qLEAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANQILC+3atZNRo0a5nQwAAADAdQQWqThz5ozbSQAAAAByDQILn9qHESNGmBqI0qVLS2xsrGzfvl26dOkiRYoUkXLlyknfvn3lt99+M9v3799fPvroI5kzZ46EhYWZKSEhwe3DAAAAAFxBYOFjwYIFUqBAAdm0aZPMmDFDrrnmGmnSpIl8+eWXsnr1ajl06JD07t3bbKsBRcuWLWXQoEFy4MABM8XExFywz+TkZElKSvKbAAAAgFAT4XYCgkmtWrVk5syZ5v9Tp041QcW0adO8619++WUTPPzwww9Su3ZtE4RERUVJ+fLlU93n9OnTZdKkSTmSfgAAAMAt1Fj4aNasmff/3377rWzYsME0g3KmunXrmnV79uzJ8D7j4uLk+PHj3ikxMTFb0g4AAAC4iRoLH4ULF/b+/+TJk9K9e3d59NFHL9iuQoUKGd5nZGSkmQAAAIBQRmCRiqZNm8rbb78tVatWlYiIwKdJm0KdO3cux9MGAAAABBuaQqVi+PDhcuzYMenTp4988cUXpvnTmjVrZMCAAd5gQoOOzZs3m9GgdLSo8+fPu51sAAAAwBUEFqmoWLGiGR1Kg4hOnTpJo0aNzFC0xYsXl/Dw/ztt999/v+TLl0/q168vZcqUkX379rmdbAAAAMAVYR6Px+POW+dNOtxssWLFJGbUEgmPjHI7OcjFEmZ0dTsJAAAgj5Rdjx8/LtHR0WluS40FAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwFqE/S5wMbZPik33R0YAAACA3IIaCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANQILAAAAANYILAAAAABYI7AAAAAAYI3fsXBJw4lrJDwyyu1k5GkJM7q6nQQAAICQQY0FAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwFrIBxYJCQkSFhYm33zzjdtJAQAAAEJWyAcWAAAAALIfgQUAAAAAayETWJw/f15mzpwpNWvWlMjISKlcubI88sgjAbf96KOPpHnz5ma7ChUqyLhx4+Ts2bPe9UuXLpVGjRpJoUKFpFSpUtKxY0c5deqUd/2LL74o9erVk4IFC0rdunXlmWeeyZFjBAAAAIJVhISIuLg4eeGFF2T27Nly1VVXyYEDB+T777+/YLtff/1VrrvuOunfv7+8+uqrZptBgwaZIOHhhx82r+vTp48JUm644QY5ceKEfPLJJ+LxeMzrFy1aJBMmTJCnnnpKmjRpIlu2bDGvL1y4sPTr18+FIwcAAADcFxKBhRb+58yZYwr7TuG+Ro0aJsDQztu+tHYhJibGbKudurXGYf/+/fLggw+agEEDC629uPHGG6VKlSrmNVp74Zg4caI8/vjjZr2qVq2afPfdd/Lcc88FDCySk5PN5EhKSsq28wAAAAC4JSSaQu3cudMU3jt06JChbVu2bGmCCkfr1q3l5MmT8ssvv0jjxo3NfjSY6NWrl6kF+f3338122hxqz549MnDgQClSpIh3mjp1qlkeyPTp06VYsWLeSYMaAAAAINSERGChfSGySr58+WTdunWyatUqqV+/vsydO1fq1Kkje/fuNcGH0mBDh691pu3bt8tnn32WahOt48ePe6fExMQsSysAAAAQLEIisKhVq5YJLj788MN0t9VO1/Hx8d4+E2rTpk1StGhRqVSpkpnX2gytxZg0aZLpQ1GgQAFZvny5lCtXTipWrCg//fST6STuO2mTqEC0g3h0dLTfBAAAAISakOhjoR2vtY/EAw88YIIADQqOHDkiO3bsuKB51LBhw+SJJ56QkSNHyogRI2TXrl2m38To0aMlPDxcNm/ebAKUTp06SdmyZc287ksDEqXBxj333GOaNXXu3Nk0wfryyy9NcyndBwAAAJAXhURgoR566CGJiIgwHbC1M7YOIztkyJALtrvkkktk5cqVMnbsWNOfomTJkqbPxPjx4816rVH4+OOPTfChHa21A7d21u7SpYtZf9ddd0lUVJQ89thjZh86GpT2xxg1alSOHzMAAAAQLMI8vm2CkO00WDGduEctkfDIKLeTk6clzOjqdhIAAAByRdlV+wqn16Q/JPpYAAAAAHAXgQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAWoT9LnAxtk+KTffXCwEAAIDcghoLAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFhjuFmXNJy4RsIjo9xORq6RMKOr20kAAABAGqixAAAAAGCNwAIAAACANQILAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgjcACAAAAgDUCi//59ttvpU+fPhITEyOFChWSevXqyZw5cy7YbuPGjdK0aVOJjIyUmjVryvz5811JLwAAABBMItxOQLD46quvpGzZsrJw4UITXHz66acyePBgyZcvn4wYMcJss3fvXunatasMGTJEFi1aJB9++KHcddddUqFCBYmNjXX7EAAAAIDQrrFo166djBw5UkaNGiUlSpSQcuXKyQsvvCCnTp2SAQMGSNGiRc3T/1WrVnlf89FHH0nz5s1NzYAW3MeNGydnz5612mda7rzzTlND0bZtW6levbrcfvvtZj/Lli3zbjNv3jypVq2aPP7446ZGQwOOf/zjHzJ79uwsPmMAAABA7pJjTaEWLFggpUuXls8//9wEBEOHDpVevXpJq1at5Ouvv5ZOnTpJ37595fTp0/Lrr7/KddddJ1dccYVpovTss8/KSy+9JFOnTr3ofV6M48ePS8mSJb3z8fHx0rFjR79ttKZCl6cmOTlZkpKS/CYAAAAg1ORYYNG4cWMZP3681KpVS+Li4qRgwYImKBg0aJBZNmHCBDl69Khs3bpVnnnmGdMc6amnnpK6detKz549ZdKkSaam4Pz58xe1z8zSplBvvvmmaQ7lOHjwoKkZ8aXzGiz8+eefAfczffp0KVasmHfS4wIAAABCTY4FFpdeeqn3/9pvoVSpUtKoUSPvMqfAfvjwYdm5c6e0bNlSwsLCvOtbt24tJ0+elF9++eWi9pkZ27dvlx49esjEiRNNrYcNDXi05sOZEhMTrfYHAAAA5OnO2/nz5/eb16DBd5kTRPjWSLixz++++046dOhgaiq0NsRX+fLl5dChQ37LdD46OtqMJBWI9hHRCQAAAAhlQTncrHaM1n4LHo/Hu2zTpk2mQ3alSpWy7X137Ngh7du3l379+skjjzxywXqtRdGRoHytW7fOLAcAAADysqAMLIYNG2aaDGmH7O+//17effdd0yxp9OjREh6ePUnW5k8aVGjTJ30f7U+h05EjR7zb6DCzP/30kzzwwAMmXdoXZMmSJXLfffdlS5oAAACA3CIoA4tLLrlEVq5caUZ70g7aWqAfOHDgBU2TstLSpUtNEKG/Y6HD2zqTjkzl0KFmP/jgA1NLoenSzuQvvvgiv2EBAACAPC/M49veCNlOR5Ayo0ONWiLhkVFuJyfXSJjR1e0kAAAA5Nmy6/Hjx02/4lxXYwEAAAAgd8kzgYU2pypSpEjASdcBAAAAyAXDzbpt8uTJcv/99wdcl161DgAAAIC05ZnAomzZsmYCAAAAkPXyTFMoAAAAANmHwAIAAACANQILAAAAANYILAAAAABYyzOdt4PN9kmxjEYFAACAkEGNBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAGoEFAAAAAGsEFgAAAACsEVgAAAAAsMbvWLik4cQ1Eh4ZJaEkYUZXt5MAAAAAl1BjAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAGoFFJjz//PPSrl07iY6OlrCwMPnjjz/cThIAAAAQFAgsMujMmTNy+vRp6dy5s/zzn/90OzkAAABAUIlwOwHBSmsmGjZsKBEREbJw4UJp1KiRbNiwwazbuHGj28kDAAAAggqBRRoWLFggQ4cOlU2bNrmdFAAAACCoEVikoVatWjJz5kyrfSQnJ5vJkZSUlAUpAwAAAIILfSzS0KxZM+t9TJ8+XYoVK+adYmJisiRtAAAAQDAhsEhD4cKFrfcRFxcnx48f906JiYlZkjYAAAAgmNAUKptFRkaaCQAAAAhlBBaZcPDgQTPt3r3bzG/btk2KFi0qlStXlpIlS7qdPAAAAMA1NIXKhHnz5kmTJk1k0KBBZr5NmzZm/r333nM7aQAAAICrwjwej8fdJOQtOiqU6cQ9aomER0ZJKEmY0dXtJAAAACAbyq7aVzg6OjrNbamxAAAAAGCNwAIAAACANQILAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAIA1AgsAAAAA1ggsAAAAAFgjsAAAAABgLcJ+F7gY2yfFpvvrhQAAAEBuQY0FAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwx3KxLGk5cI+GRUZKbJczo6nYSAAAAECSosQAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANQILAAAAANYILAAAAABYI7AAAAAAkLOBRbt27WTUqFGprq9atao88cQT9qkCAAAAkKtQY/E/y5Ytk2uvvVbKlCkj0dHR0rJlS1mzZs0F2z399NMmgCpYsKC0aNFCPv/8c1fSCwAAAAQTAov/+fjjj01gsXLlSvnqq6+kffv20r17d9myZYt3mzfffFNGjx4tEydOlK+//loaN24ssbGxcvjwYVfTDgAAAOS6wOLs2bMyYsQIKVasmJQuXVoeeugh8Xg83vUnTpyQPn36SOHCheWSSy4xT/gzKiwsTJ599lnp0qWLFCpUSKpXry5Lly7122bbtm1yzTXXmPWlSpWSwYMHy8mTJ73rN27cKM2bNzfvX7x4cWndurX8/PPP6b63NuF64IEH5IorrpBatWrJtGnTzN8VK1Z4t/n3v/8tgwYNkgEDBkj9+vVl3rx5EhUVJS+//HKGjxEAAAAIRZkOLBYsWCARERGmCdCcOXNMYfvFF1/0rn/sscfMk3x90j9u3Di59957Zd26dRnevwYqN910k3z77bdy2223yS233CI7d+40606dOmVqCEqUKCFffPGFvPXWW7J+/XoT6DhBT8+ePaVt27aydetWiY+PN4GHBiyZdf78eRMklSxZ0syfOXPG1GR07NjRu014eLiZ1/dJTXJysiQlJflNAAAAQKiJyOwLYmJiZPbs2aawXqdOHVODoPP6JF9pDYEGFKp27dqyadMms16bGWVEr1695K677jL/nzJliglK5s6dK88884y8/vrr8tdff8mrr75qaiTUU089ZZosPfroo5I/f345fvy4dOvWTWrUqGHW16tXTy7GrFmzTE1I7969zfxvv/0m586dk3Llyvltp/Pff/99qvuZPn26TJo06aLSAAAAAIRsjcWVV17pVwOgnZx//PFHU+h25n3pvFPjkBFpvV7/am2IE1Q4gYzWLuzatcvULvTv39/UamiwoTUqBw4cyOwhmgBGg4ElS5ZI2bJlxUZcXJwJdpwpMTHRan8AAABAMAq5ztuvvPKKaZrUqlUr09laa00+++yzDL/+jTfeMDUmGlT4NnvS/iT58uWTQ4cO+W2v8+XLl091f5GRkWaUKd8JAAAAkLweWGzevNlvXgvt2slZC93OfMr1mWmOlNbr9a/2vdC+Fg5taqV9HbRZlqNJkyampuDTTz+Vhg0bmhqIjFi8eLHpmK1/u3bt6reuQIEC0qxZM/nwww+9y7SmROdT1rIAAAAAeU2mA4t9+/aZIVe16ZEWwLX/g3bQ9i3oz5w5U3744QczIpR2sPZdnx7dXkdZ0tfrsK7aSdzpnK2dufX3I/r16yfbt2+XDRs2yMiRI6Vv376mr8PevXtNQKE1FjoS1Nq1a00zrYwENhp83HHHHfL444+b36c4ePCgmbT5kkOP+4UXXjAd2LVZ1tChQ02Qo8EIAAAAkJdluvO2Fr7//PNPM6Sr1lJo0KAjLznGjBkjX375pemjoM1+dNQo7fOQUfo6bY40bNgwqVChggledGhXpUO76o/W6XvqsLA6ryNI6Xs467UjtRb8jx49al4/fPhwufvuu9N93+eff96MKqXb6+TQIGb+/Pnm/zfffLMcOXJEJkyYYIKOyy67TFavXn1Bh24AAAAgrwnz+P4Ihcu0U/jy5cvNkLGhSoeb1d8AiRm1RMIjoyQ3S5jh31wMAAAAoVl21VY86fUVDrnO2wAAAAByXo4FFosWLZIiRYoEnBo0aJDt76/vkdr7a9oAAAAA5GAfi4t1/fXXm07RgegP26nsbJW1cuVK+fvvvwOuo48EAAAAkEsCi6JFi5rJLVWqVHHtvQEAAIBQRx8LAAAAANYILAAAAABYI7AAAAAAYI3AAgAAAEDu6bwNf9snxab7IyMAAABAbkGNBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAGoEFAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAAAABrBBYAAAAArBFYAAAAALBGYAEAAADAGoEFAAAAAGsR9rtAZng8HvM3KSnJ7aQAAAAAaXLKrE4ZNi0EFjns6NGj5m9MTIzbSQEAAAAy5MSJE1KsWLE0tyGwyGElS5Y0f/ft25du5iB3RfMaLCYmJkp0dLTbyUEWIE9DE/kaesjT0EOeBhetqdCgomLFiuluS2CRw8LD/69biwYV3CyhR/OUfA0t5GloIl9DD3kaesjT4JHRh+F03gYAAABgjcACAAAAgDUCixwWGRkpEydONH8ROsjX0EOehibyNfSQp6GHPM29wjwZGTsKAAAAANJAjQUAAAAAawQWAAAAAKwRWAAAAACwRmCRBZ5++mmpWrWqFCxYUFq0aCGff/55mtu/9dZbUrduXbN9o0aNZOXKlX7rtdvLhAkTpEKFClKoUCHp2LGj/Pjjj9l8FMjOPO3fv7+EhYX5TZ07d87mo4BNvu7YsUNuuukms73m1xNPPGG9TwR/nj788MMX3Kt6byN48/WFF16Qq6++WkqUKGEm/c5MuT3fq6GXp3yvBicCC0tvvvmmjB492oxe8PXXX0vjxo0lNjZWDh8+HHD7Tz/9VPr06SMDBw6ULVu2SM+ePc20fft27zYzZ86UJ598UubNmyebN2+WwoULm33+9ddfOXhkeVd25KnSD7wDBw54p8WLF+fQEeFi8vX06dNSvXp1mTFjhpQvXz5L9ongz1PVoEEDv3v1v//9bzYeBWzzdePGjeYzeMOGDRIfH29+sblTp07y66+/erfhezX08lTxvRqEdFQoXLzmzZt7hg8f7p0/d+6cp2LFip7p06cH3L53796erl27+i1r0aKF5+677zb/P3/+vKd8+fKexx57zLv+jz/+8ERGRnoWL16cbceB7MtT1a9fP0+PHj2yMdXI6nz1VaVKFc/s2bOzdJ8IzjydOHGip3HjxlmeVmSc7X119uxZT9GiRT0LFiww83yvhl6eKr5XgxM1FhbOnDkjX331lamic4SHh5t5jbAD0eW+2yuN2p3t9+7dKwcPHvTbRn9GXasNU9sngjtPfZ/AlC1bVurUqSNDhw6Vo0ePZtNRICvy1Y19IjjOvzaRqVixoqnduO2222Tfvn1ZkGLkVL5qzdTff/8tJUuWNPN8r4Zenjr4Xg0+BBYWfvvtNzl37pyUK1fOb7nO64dYILo8re2dv5nZJ4I7T53q2ldffVU+/PBDefTRR+Wjjz6SLl26mPdCcOarG/uE++dfC5vz58+X1atXy7PPPmsKpdrW+8SJE1mQauREvj744IMmMHQKsnyvhl6eKr5Xg1OE2wkA8oJbbrnF+3/t3H3ppZdKjRo1zNOWDh06uJo2AP+fFkwcep9qoFGlShVZsmSJ6UeF4Kb9Z9544w3z2aqdhBG6ecr3anCixsJC6dKlJV++fHLo0CG/5TqfWsdAXZ7W9s7fzOwTwZ2ngWgTC32v3bt3Z1HKkdX56sY+EXznv3jx4lK7dm3u1VyQr7NmzTKF0LVr15pCpoPv1dDL00D4Xg0OBBYWChQoIM2aNTPVcI7z58+b+ZYtWwZ8jS733V6tW7fOu321atXMjea7TVJSkhnFIrV9IrjzNJBffvnFtAXVoQ8RnPnqxj4RfOf/5MmTsmfPHu7VIM9XHfVpypQppgnb5Zdf7reO79XQy9NA+F4NEm73Hs/t3njjDTOyxPz58z3fffedZ/DgwZ7ixYt7Dh48aNb37dvXM27cOO/2mzZt8kRERHhmzZrl2blzpxmBJH/+/J5t27Z5t5kxY4bZx7vvvuvZunWrGfWgWrVqnj///NOVY8xrsjpPT5w44bn//vs98fHxnr1793rWr1/vadq0qadWrVqev/76y7XjzGsym6/JycmeLVu2mKlChQomD/X/P/74Y4b3idyXp2PGjPFs3LjR3Kt6b3fs2NFTunRpz+HDh105xrwos/mq35kFChTwLF261HPgwAHvpJ+9vtvwvRo6ecr3avAisMgCc+fO9VSuXNncBDqk2meffeZd17ZtWzMkmq8lS5Z4ateubbZv0KCB54MPPvBbr0PjPfTQQ55y5cqZG7FDhw6eXbt25djxIGvz9PTp055OnTp5ypQpYwIOHeZy0KBBFD6DPF/1y0qfvaScdLuM7hO5L09vvvlmE3To/i655BIzv3v37hw/rrwuM/mqn6mB8lUf8jj4Xg2tPOV7NXiF6T9u15oAAAAAyN3oYwEAAADAGoEFAAAAAGsEFgAAAACsEVgAAAAAsEZgAQAAAMAagQUAAAAAawQWAAAAAKwRWAAAAACwRmABAAAAwBqBBQAgU/r37y89e/aUYJSQkCBhYWHyzTffuJ0UAMhzCCwAACHhzJkzbicBAPI0AgsAwEVr166djBw5UkaNGiUlSpSQcuXKyQsvvCCnTp2SAQMGSNGiRaVmzZqyatUq72s2btxoahU++OADufTSS6VgwYJy5ZVXyvbt2/32/fbbb0uDBg0kMjJSqlatKo8//rjfel02ZcoUueOOOyQ6OloGDx4s1apVM+uaNGli3kPTp7744gu59tprpXTp0lKsWDFp27atfP3113770+1ffPFFueGGGyQqKkpq1aol7733nt82O3bskG7dupn302O7+uqrZc+ePd71+vp69eqZY6pbt64888wzWXi2ASC4EVgAAKwsWLDAFNg///xzE2QMHTpUevXqJa1atTKF906dOknfvn3l9OnTfq8bO3asCRa00F+mTBnp3r27/P3332bdV199Jb1795ZbbrlFtm3bJg8//LA89NBDMn/+fL99zJo1Sxo3bixbtmwx6zUNav369XLgwAFZtmyZmT9x4oT069dP/vvf/8pnn31mgobrrrvOLPc1adIk875bt24162+77TY5duyYWffrr79KmzZtTKDzn//8x6TxzjvvlLNnz5r1ixYtkgkTJsgjjzwiO3fulGnTppk06fkBgDzBAwBAJvTr18/To0cP8/+2bdt6rrrqKu+6s2fPegoXLuzp27evd9mBAwc8+nUTHx9v5jds2GDm33jjDe82R48e9RQqVMjz5ptvmvlbb73Vc+211/q979ixYz3169f3zlepUsXTs2dPv2327t1r9r1ly5Y0j+HcuXOeokWLelasWOFdpq8bP368d/7kyZNm2apVq8x8XFycp1q1ap4zZ84E3GeNGjU8r7/+ut+yKVOmeFq2bJlmWgAgVFBjAQCwos2ZHPny5ZNSpUpJo0aNvMu0eZQ6fPiw3+tatmzp/X/JkiWlTp065km/0r+tW7f2217nf/zxRzl37px32eWXX56hNB46dEgGDRpkaiq0KZQ2ZTp58qTs27cv1WMpXLiw2c5Jt3YI16ZP+fPnv2D/2vRLm0QNHDhQihQp4p2mTp3q11QKAEJZhNsJAADkbikL2tpXwXeZzqvz589n+Xtr4T8jtBnU0aNHZc6cOVKlShXTnEkDm5QdvgMdi5PuQoUKpbp/DVKU9i9p0aKF3zoNtgAgLyCwAAC4Qvs6VK5c2fz/999/lx9++MF0fFb6d9OmTX7b63zt2rXTLKgXKFDA/PWt1XBeqx2ptd+ESkxMlN9++y1T6dXaDO0vof1AUgYgWitTsWJF+emnn0y/DADIiwgsAACumDx5smk2pYXyf/3rX6YDuPP7GGPGjJErrrjCjPp08803S3x8vDz11FPpjrJUtmxZU7OwevVqqVSpkhmdSZs+aROo1157zTSdSkpKMh3H06qBCGTEiBEyd+5c06E8Li7O7FeDo+bNm5tmXNrx+5577jHLO3fuLMnJyfLll1+aoGn06NFW5woAcgP6WAAAXDFjxgy59957pVmzZnLw4EFZsWKFt8ahadOmsmTJEnnjjTekYcOGZrQlDUT0x/nSEhERIU8++aQ899xzpgahR48eZvlLL71kCvi6Xx2hSgMADUIyQ4MgHQ1Kmz3pcLWabm365NRe3HXXXWa42VdeecX0MdFtdBQrZwhcAAh1YdqD2+1EAADyDv0di/bt25uCfvHixd1ODgAgi1BjAQAAAMAagQUAAAAAazSFAgAAAGCNGgsAAAAA1ggsAAAAAFgjsAAAAABgjcACAAAAgDUCCwAAAADWCCwAAAAAWCOwAAAAAGCNwAIAAACANQILAAAAAGLr/wGZsSL2H/8SOwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
