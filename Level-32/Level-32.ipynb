{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T01:38:24.265627Z",
     "start_time": "2025-10-31T01:38:18.848013Z"
    }
   },
   "source": [
    "# Level-32 â€” Real-Time Incremental Learning (fully hardened)\n",
    "# Fixes: 1-D broadcasting, Series truth ambiguity, CAGR date calc (DatetimeIndex vs RangeIndex)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------- Config ----------------------------\n",
    "TICKER       = \"AAPL\"\n",
    "YEARS        = 3.0\n",
    "FREQ         = \"1D\"\n",
    "VOL_SPAN     = 50\n",
    "H_BARS       = 10\n",
    "CUSUM_GRID   = [0.003, 0.004, 0.006, 0.008, 0.010]\n",
    "UP_M, DN_M   = 3.0, 3.0\n",
    "MIN_EVENTS   = 400\n",
    "RNG_SEED     = 42\n",
    "ONLINE_BATCH = 50\n",
    "TC_BP        = 5\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# ---------------------------- Helpers ----------------------------\n",
    "def utc_now_date():\n",
    "    return datetime.now(timezone.utc).date()\n",
    "\n",
    "def load_prices(ticker, years, freq=\"1D\"):\n",
    "    end = utc_now_date()\n",
    "    start = (datetime.now(timezone.utc) - timedelta(days=int(365*years + 20))).date()\n",
    "    df = yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False)\n",
    "    if df.empty:\n",
    "        raise SystemExit(\"No data downloaded.\")\n",
    "    s = df[\"Adj Close\"] if \"Adj Close\" in df.columns else df[\"Close\"]\n",
    "    s = s.asfreq(\"B\").ffill()\n",
    "    s.name = \"Close\"\n",
    "    return s\n",
    "\n",
    "def ewma_vol(r, span=50):\n",
    "    return r.ewm(span=span, adjust=False).std()\n",
    "\n",
    "def to_1d_series(r, index=None):\n",
    "    if isinstance(r, pd.Series):\n",
    "        return r.astype(float).fillna(0.0)\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        r = r.iloc[:, 0]\n",
    "    arr = np.ravel(np.asarray(r, dtype=float))\n",
    "    if index is None:\n",
    "        index = pd.RangeIndex(len(arr))\n",
    "    return pd.Series(arr, index=index, dtype=float).fillna(0.0)\n",
    "\n",
    "def cusum_filter(r, threshold, index=None):\n",
    "    s = to_1d_series(r, index=index)\n",
    "    idx, vals = s.index, s.to_numpy()\n",
    "    s_pos = s_neg = 0.0\n",
    "    t_events = []\n",
    "    for i, x in enumerate(vals):\n",
    "        s_pos = max(0.0, s_pos + x)\n",
    "        s_neg = min(0.0, s_neg + x)\n",
    "        if s_pos > threshold:\n",
    "            s_pos = 0.0\n",
    "            t_events.append(idx[i])\n",
    "        elif s_neg < -threshold:\n",
    "            s_neg = 0.0\n",
    "            t_events.append(idx[i])\n",
    "    return pd.DatetimeIndex(t_events).unique().sort_values()\n",
    "\n",
    "def get_vertical_barriers(t_events, h, index):\n",
    "    if len(t_events) == 0:\n",
    "        return pd.Series(dtype=\"datetime64[ns]\")\n",
    "    out = {}\n",
    "    for t0 in t_events:\n",
    "        pos = index.get_indexer([t0])[0]\n",
    "        t1_pos = min(pos + h, len(index) - 1)\n",
    "        out[t0] = index[t1_pos]\n",
    "    return pd.Series(out)\n",
    "\n",
    "def get_triple_barrier_labels(close, t_events, vbar, up_m, dn_m, daily_vol):\n",
    "    trgt = daily_vol.reindex(t_events).fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    df = pd.DataFrame({\"t1\": vbar.reindex(t_events), \"trgt\": trgt}, index=t_events).dropna()\n",
    "    labels = []\n",
    "    for t0, row in df.iterrows():\n",
    "        t1 = row[\"t1\"]\n",
    "        try:\n",
    "            c0 = float(close.loc[t0].iloc[0]) if isinstance(close.loc[t0], pd.Series) else float(close.loc[t0])\n",
    "        except Exception:\n",
    "            continue\n",
    "        up_lvl = c0 * (1 + up_m * float(row[\"trgt\"]))\n",
    "        dn_lvl = c0 * (1 - dn_m * float(row[\"trgt\"]))\n",
    "        segment = close.loc[t0:t1]\n",
    "        if isinstance(segment, pd.DataFrame):\n",
    "            segment = segment.iloc[:, 0]\n",
    "        path = pd.Series(segment.astype(float), index=segment.index)\n",
    "        if path.empty:\n",
    "            continue\n",
    "        path_up = path >= up_lvl\n",
    "        path_dn = path <= dn_lvl\n",
    "        hit_up = path_up.idxmax() if path_up.to_numpy().any() else None\n",
    "        hit_dn = path_dn.idxmax() if path_dn.to_numpy().any() else None\n",
    "        if (hit_up is not None) and (hit_dn is not None):\n",
    "            lbl = 1 if hit_up <= hit_dn else 0\n",
    "            t_end = hit_up if lbl == 1 else hit_dn\n",
    "        elif hit_up is not None:\n",
    "            lbl, t_end = 1, hit_up\n",
    "        elif hit_dn is not None:\n",
    "            lbl, t_end = 0, hit_dn\n",
    "        else:\n",
    "            c1 = float(path.iloc[-1])\n",
    "            lbl, t_end = (1 if c1 > c0 else 0), t1\n",
    "        labels.append((t0, t_end, lbl, float(row[\"trgt\"])))\n",
    "    if not labels:\n",
    "        return pd.DataFrame(columns=[\"t1\", \"label\", \"trgt\"])\n",
    "    return pd.DataFrame(labels, columns=[\"t0\", \"t1\", \"label\", \"trgt\"]).set_index(\"t0\")\n",
    "\n",
    "def make_features(close):\n",
    "    r = close.pct_change().fillna(0.0)\n",
    "    f = pd.DataFrame(index=close.index)\n",
    "    f[\"r1\"] = r\n",
    "    f[\"r5\"] = close.pct_change(5)\n",
    "    f[\"r10\"] = close.pct_change(10)\n",
    "    f[\"mom5\"] = close / close.shift(5) - 1\n",
    "    f[\"mom10\"] = close / close.shift(10) - 1\n",
    "    f[\"vol10\"] = r.rolling(10).std()\n",
    "    f[\"vol20\"] = r.rolling(20).std()\n",
    "    f[\"z20\"] = (close - close.rolling(20).mean()) / (1e-12 + close.rolling(20).std())\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0).rolling(14).mean()\n",
    "    dn = (-delta.clip(upper=0)).rolling(14).mean()\n",
    "    rs = up / (1e-12 + dn)\n",
    "    f[\"rsi14\"] = 100 - 100 / (1 + rs)\n",
    "    return f.fillna(0.0)\n",
    "\n",
    "def adaptive_events_and_labels(close, rets, base_H, cusum_grid, vol_span, up_m, dn_m, min_events):\n",
    "    daily_vol = ewma_vol(to_1d_series(rets, index=close.index), span=vol_span).clip(lower=1e-8)\n",
    "    used_thr = None\n",
    "    events_idx = pd.DatetimeIndex([])\n",
    "    for thr in cusum_grid:\n",
    "        ev = cusum_filter(rets, thr, index=close.index)\n",
    "        if len(ev) >= min_events:\n",
    "            used_thr, events_idx = thr, ev\n",
    "            break\n",
    "    if used_thr is None:\n",
    "        used_thr = min(cusum_grid)\n",
    "        events_idx = cusum_filter(rets, used_thr, index=close.index)\n",
    "    vbar = get_vertical_barriers(events_idx, base_H, close.index)\n",
    "    labels = get_triple_barrier_labels(close, events_idx, vbar, up_m, dn_m, daily_vol).dropna()\n",
    "    if labels.empty:\n",
    "        raise SystemExit(\"No labeled events. Adjust thresholds.\")\n",
    "    print(f\"[Adaptive] events={len(labels)}  H={base_H} thrâ‰ˆ{used_thr}\")\n",
    "    return labels, daily_vol, events_idx, base_H, float(used_thr)\n",
    "\n",
    "def sharpe_ratio(x):\n",
    "    s = x.std()\n",
    "    return 0.0 if s == 0 or np.isnan(s) else float(np.sqrt(252) * x.mean() / s)\n",
    "\n",
    "def drawdown(x):\n",
    "    cum = (1 + x).cumprod()\n",
    "    return float((cum / cum.cummax() - 1).min())\n",
    "\n",
    "# ---------------------------- Main ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    close = load_prices(TICKER, YEARS, FREQ)\n",
    "    rets  = close.pct_change().fillna(0.0)\n",
    "\n",
    "    # 1) Events & Labels\n",
    "    labels, _, _, _, _ = adaptive_events_and_labels(\n",
    "        close, rets, H_BARS, CUSUM_GRID, VOL_SPAN, UP_M, DN_M, MIN_EVENTS\n",
    "    )\n",
    "\n",
    "    # 2) Features aligned\n",
    "    feats = make_features(close)\n",
    "    X = feats.reindex(labels.index).dropna()\n",
    "    y = labels.loc[X.index, \"label\"].astype(int)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = SGDClassifier(loss=\"log_loss\", penalty=\"l2\",\n",
    "                          learning_rate=\"optimal\", random_state=RNG_SEED)\n",
    "\n",
    "    proba_all = np.zeros(len(X), dtype=float)\n",
    "    signal    = np.zeros(len(X), dtype=float)\n",
    "\n",
    "    # strictly 1-D forward return, aligned to X.index\n",
    "    ret_next = close.pct_change().shift(-1).reindex(X.index).fillna(0.0)\n",
    "    if isinstance(ret_next, pd.DataFrame):\n",
    "        ret_next = ret_next.iloc[:, 0]\n",
    "    ret_next = ret_next.astype(float).to_numpy().ravel()\n",
    "\n",
    "    # online/rolling fit\n",
    "    for i in range(ONLINE_BATCH, len(X)):\n",
    "        Xb, yb = X_scaled[i - ONLINE_BATCH:i], y.iloc[i - ONLINE_BATCH:i]\n",
    "        if i == ONLINE_BATCH:\n",
    "            model.partial_fit(Xb, yb, classes=np.array([0, 1]))\n",
    "        else:\n",
    "            model.partial_fit(Xb, yb)\n",
    "        p = model.predict_proba(X_scaled[i:i + 1])[0, 1]\n",
    "        proba_all[i] = p\n",
    "        signal[i]    = 1.0 if p >= 0.55 else 0.0\n",
    "\n",
    "    # PnL with TC\n",
    "    pnl_gross = (signal * ret_next).ravel()\n",
    "    toggle    = np.abs(np.diff(signal, prepend=0.0))\n",
    "    tc        = toggle * (TC_BP / 1e4)\n",
    "    pnl_net   = pnl_gross - tc\n",
    "\n",
    "    # ðŸ”§ Index PnL by event dates to keep a DatetimeIndex for CAGR;\n",
    "    # if not DatetimeIndex, we fall back to N/252 years.\n",
    "    pnl_series = pd.Series(np.ravel(pnl_net), index=X.index)\n",
    "\n",
    "    sharpe = sharpe_ratio(pnl_series)\n",
    "    cum    = (1.0 + pnl_series).cumprod()\n",
    "\n",
    "    if isinstance(cum.index, pd.DatetimeIndex):\n",
    "        yrs = (cum.index[-1] - cum.index[0]).days / 365.25\n",
    "    else:\n",
    "        yrs = len(cum) / 252.0  # fallback\n",
    "\n",
    "    cagr = float(cum.iloc[-1] ** (1 / max(1e-9, yrs)) - 1.0)\n",
    "    dd   = drawdown(pnl_series)\n",
    "    hit  = float(((signal > 0) & (ret_next > 0)).sum() / max(1, (signal > 0).sum()))\n",
    "\n",
    "    print(\"\\n=== Real-Time Incremental Backtest (Level-32) ===\")\n",
    "    print(f\"Sharpe: {sharpe:.3f}  CAGR: {100*cagr:.2f}%  MaxDD: {100*dd:.2f}%  Hit%: {100*hit:.2f}%\")\n",
    "    print(f\"Avg turnover: {float(toggle.mean()):.3f}  Avg TC (bp): {float((tc * 1e4).mean()):.2f}\")\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\"proba\": proba_all, \"signal\": signal, \"ret_next\": ret_next, \"pnl_net\": pnl_net},\n",
    "        index=X.index\n",
    "    )\n",
    "    name = f\"{TICKER}_level32_online_backtest.csv\"\n",
    "    out.to_csv(name)\n",
    "    print(f\"\\nSaved: {name}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adaptive] events=627  H=10 thrâ‰ˆ0.003\n",
      "\n",
      "=== Real-Time Incremental Backtest (Level-32) ===\n",
      "Sharpe: 1.272  CAGR: 20.50%  MaxDD: -18.85%  Hit%: 55.05%\n",
      "Avg turnover: 0.198  Avg TC (bp): 0.99\n",
      "\n",
      "Saved: AAPL_level32_online_backtest.csv\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
