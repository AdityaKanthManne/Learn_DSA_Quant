{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-06T02:01:50.640050Z",
     "start_time": "2025-12-06T02:01:36.951207Z"
    }
   },
   "source": [
    "# level76_cornish_fisher_var.py\n",
    "# Parametric VaR / CVaR with Cornish–Fisher adjustment for skew & kurtosis.\n",
    "#\n",
    "# - Downloads adjusted close prices via yfinance\n",
    "# - Builds a portfolio (equal-weight or user-specified weights)\n",
    "# - Computes rolling normal VaR / ES and Cornish–Fisher adjusted VaR / ES\n",
    "# - Outputs CSV and JSON summary\n",
    "#\n",
    "# Usage examples:\n",
    "#   python level76_cornish_fisher_var.py\n",
    "#   python level76_cornish_fisher_var.py --symbols SPY,QQQ,TLT,GLD --weights 0.3,0.3,0.2,0.2\n",
    "#   python level76_cornish_fisher_var.py --alpha 0.99 --window 500\n",
    "#\n",
    "# All VaR/CVaR numbers are in *return space* (e.g. 0.03 = 3% loss).\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Sequence, Tuple, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# --------------------------- Config ---------------------------\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # Portfolio weights (if None → equal-weight)\n",
    "    weights: Optional[Tuple[float, ...]] = None\n",
    "\n",
    "    # VaR / CVaR settings\n",
    "    alpha: float = 0.95          # confidence level\n",
    "    window: int = 252            # rolling window length (days)\n",
    "\n",
    "    # Outputs\n",
    "    out_csv: str = \"level76_cornish_var.csv\"\n",
    "    out_json: str = \"level76_cornish_var_summary.json\"\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# --------------------------- Normal helpers ---------------------------\n",
    "\n",
    "def norm_pdf(x: float) -> float:\n",
    "    return float(np.exp(-0.5 * x * x) / np.sqrt(2.0 * np.pi))\n",
    "\n",
    "\n",
    "def norm_ppf(p: float) -> float:\n",
    "    \"\"\"\n",
    "    Approximate inverse CDF (quantile) of N(0,1) using a rational approximation.\n",
    "\n",
    "    Based on Peter J. Acklam's algorithm.\n",
    "    Good enough for risk work (|error| ~ 1e-9 in (1e-9,1-1e-9)).\n",
    "    \"\"\"\n",
    "    if not 0.0 < p < 1.0:\n",
    "        raise ValueError(\"p must be in (0,1)\")\n",
    "\n",
    "    # Coefficients\n",
    "    a = [\n",
    "        -3.969683028665376e+01,\n",
    "         2.209460984245205e+02,\n",
    "        -2.759285104469687e+02,\n",
    "         1.383577518672690e+02,\n",
    "        -3.066479806614716e+01,\n",
    "         2.506628277459239e+00,\n",
    "    ]\n",
    "    b = [\n",
    "        -5.447609879822406e+01,\n",
    "         1.615858368580409e+02,\n",
    "        -1.556989798598866e+02,\n",
    "         6.680131188771972e+01,\n",
    "        -1.328068155288572e+01,\n",
    "    ]\n",
    "    c = [\n",
    "        -7.784894002430293e-03,\n",
    "        -3.223964580411365e-01,\n",
    "        -2.400758277161838e+00,\n",
    "        -2.549732539343734e+00,\n",
    "         4.374664141464968e+00,\n",
    "         2.938163982698783e+00,\n",
    "    ]\n",
    "    d = [\n",
    "         7.784695709041462e-03,\n",
    "         3.224671290700398e-01,\n",
    "         2.445134137142996e+00,\n",
    "         3.754408661907416e+00,\n",
    "    ]\n",
    "\n",
    "    plow = 0.02425\n",
    "    phigh = 1.0 - plow\n",
    "\n",
    "    if p < plow:\n",
    "        q = np.sqrt(-2.0 * np.log(p))\n",
    "        num = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5])\n",
    "        den = ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1.0)\n",
    "        x = num / den\n",
    "    elif p > phigh:\n",
    "        q = np.sqrt(-2.0 * np.log(1.0 - p))\n",
    "        num = -(((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5])\n",
    "        den = ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1.0)\n",
    "        x = num / den\n",
    "    else:\n",
    "        q = p - 0.5\n",
    "        r = q * q\n",
    "        num = (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5]) * q\n",
    "        den = (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4])*r + 1.0)\n",
    "        x = num / den\n",
    "\n",
    "    return float(x)\n",
    "\n",
    "\n",
    "# --------------------------- Data Loader ---------------------------\n",
    "\n",
    "def _extract_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robustly extract a 1D close price Series for a symbol from a yfinance DataFrame.\n",
    "    Handles Series or DataFrame 'Close'.\n",
    "    \"\"\"\n",
    "    if \"Close\" not in px.columns:\n",
    "        raise RuntimeError(f\"'Close' column missing for {symbol}.\")\n",
    "\n",
    "    close_obj = px[\"Close\"]\n",
    "\n",
    "    if isinstance(close_obj, pd.Series):\n",
    "        close = pd.Series(close_obj.values, index=close_obj.index, name=symbol)\n",
    "    elif isinstance(close_obj, pd.DataFrame):\n",
    "        if close_obj.shape[1] < 1:\n",
    "            raise RuntimeError(f\"No close data columns for {symbol}.\")\n",
    "        col0 = close_obj.iloc[:, 0]\n",
    "        close = pd.Series(col0.values, index=col0.index, name=symbol)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected type for Close data.\")\n",
    "\n",
    "    close = close.astype(float)\n",
    "    return close\n",
    "\n",
    "\n",
    "def load_prices(symbols: Sequence[str], start: str) -> pd.DataFrame:\n",
    "    \"\"\"Download adjusted close prices for the given symbols.\"\"\"\n",
    "    frames: List[pd.Series] = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No price data downloaded for {s}.\")\n",
    "        close = _extract_close_series(px, s)\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"all\")\n",
    "    prices = prices.ffill().dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Daily log returns.\"\"\"\n",
    "    rets = np.log(prices).diff()\n",
    "    rets = rets.dropna(how=\"all\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# --------------------------- Portfolio & Tail Risk ---------------------------\n",
    "\n",
    "def build_weights(cfg: Config, symbols: Sequence[str]) -> np.ndarray:\n",
    "    if cfg.weights is None:\n",
    "        w = np.ones(len(symbols)) / float(len(symbols))\n",
    "        return w\n",
    "\n",
    "    if len(cfg.weights) != len(symbols):\n",
    "        raise ValueError(\n",
    "            f\"Length of weights ({len(cfg.weights)}) \"\n",
    "            f\"does not match number of symbols ({len(symbols)}).\"\n",
    "        )\n",
    "    w = np.array(cfg.weights, dtype=float)\n",
    "    s = float(np.sum(w))\n",
    "    if s != 0.0:\n",
    "        w = w / s\n",
    "    return w\n",
    "\n",
    "\n",
    "def portfolio_returns(rets: pd.DataFrame, weights: np.ndarray) -> pd.Series:\n",
    "    \"\"\"Compute portfolio returns as weighted sum of asset returns.\"\"\"\n",
    "    r = (rets * weights).sum(axis=1)\n",
    "    r.name = \"ret_port\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def cornish_fisher_z(z: float, skew: float, ex_kurt: float) -> float:\n",
    "    \"\"\"\n",
    "    Cornish–Fisher adjusted quantile.\n",
    "    z: normal quantile for the desired alpha\n",
    "    skew: sample skewness (3rd central moment / sigma^3)\n",
    "    ex_kurt: excess kurtosis (kurtosis - 3)\n",
    "    \"\"\"\n",
    "    g1 = skew\n",
    "    g2 = ex_kurt\n",
    "\n",
    "    z2 = z * z\n",
    "    z3 = z2 * z\n",
    "\n",
    "    term1 = (1.0 / 6.0) * (z2 - 1.0) * g1\n",
    "    term2 = (1.0 / 24.0) * (z3 - 3.0 * z) * g2\n",
    "    term3 = -(1.0 / 36.0) * (2.0 * z3 - 5.0 * z) * (g1 ** 2)\n",
    "\n",
    "    return float(z + term1 + term2 + term3)\n",
    "\n",
    "\n",
    "def compute_rolling_tail_metrics(\n",
    "    port_ret: pd.Series, window: int, alpha: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute rolling parametric normal VaR/ES and Cornish–Fisher VaR/ES.\n",
    "\n",
    "    We work on losses:\n",
    "      L_t = -ret_t  (positive = loss)\n",
    "    For each window:\n",
    "      μ_L, σ_L, skew_L, ex_kurt_L\n",
    "      z = Phi^{-1}(alpha)\n",
    "      z_cf = Cornish–Fisher adjusted\n",
    "      VaR_normal = μ_L + z * σ_L\n",
    "      ES_normal  = μ_L + σ_L * phi(z) / (1 - alpha)\n",
    "      VaR_cf     = μ_L + z_cf * σ_L\n",
    "      ES_cf      = μ_L + σ_L * phi(z_cf) / (1 - alpha)\n",
    "    \"\"\"\n",
    "    r = port_ret.dropna()\n",
    "    loss = -r\n",
    "\n",
    "    # Rolling stats\n",
    "    roll_mean = loss.rolling(window=window, min_periods=window).mean()\n",
    "    roll_std = loss.rolling(window=window, min_periods=window).std(ddof=1)\n",
    "\n",
    "    # Skewness: E[(L - mean)^3] / std^3\n",
    "    def _skew(x: np.ndarray) -> float:\n",
    "        if x.size < 3:\n",
    "            return np.nan\n",
    "        m = x.mean()\n",
    "        s = x.std(ddof=1)\n",
    "        if s == 0:\n",
    "            return 0.0\n",
    "        return float(np.mean((x - m) ** 3) / (s ** 3))\n",
    "\n",
    "    # Excess kurtosis: E[(L - mean)^4]/std^4 - 3\n",
    "    def _ex_kurt(x: np.ndarray) -> float:\n",
    "        if x.size < 4:\n",
    "            return np.nan\n",
    "        m = x.mean()\n",
    "        s = x.std(ddof=1)\n",
    "        if s == 0:\n",
    "            return 0.0\n",
    "        return float(np.mean((x - m) ** 4) / (s ** 4) - 3.0)\n",
    "\n",
    "    roll_skew = loss.rolling(window=window, min_periods=window).apply(\n",
    "        lambda x: _skew(x.to_numpy()), raw=False\n",
    "    )\n",
    "    roll_exkurt = loss.rolling(window=window, min_periods=window).apply(\n",
    "        lambda x: _ex_kurt(x.to_numpy()), raw=False\n",
    "    )\n",
    "\n",
    "    z = norm_ppf(alpha)\n",
    "    phi_z = norm_pdf(z)\n",
    "\n",
    "    # VaR / ES under normal assumption\n",
    "    var_normal = roll_mean + z * roll_std\n",
    "    es_normal = roll_mean + roll_std * (phi_z / (1.0 - alpha))\n",
    "\n",
    "    # Cornish–Fisher adjusted z\n",
    "    def _cf_var(x: pd.Series) -> float:\n",
    "        mu_l = x[\"mean\"]\n",
    "        sig_l = x[\"std\"]\n",
    "        skew_l = x[\"skew\"]\n",
    "        exk_l = x[\"exk\"]\n",
    "        if np.isnan(mu_l) or sig_l <= 0 or np.isnan(skew_l) or np.isnan(exk_l):\n",
    "            return np.nan\n",
    "        z_cf = cornish_fisher_z(z, skew_l, exk_l)\n",
    "        return float(mu_l + z_cf * sig_l)\n",
    "\n",
    "    def _cf_es(x: pd.Series) -> float:\n",
    "        mu_l = x[\"mean\"]\n",
    "        sig_l = x[\"std\"]\n",
    "        skew_l = x[\"skew\"]\n",
    "        exk_l = x[\"exk\"]\n",
    "        if np.isnan(mu_l) or sig_l <= 0 or np.isnan(skew_l) or np.isnan(exk_l):\n",
    "            return np.nan\n",
    "        z_cf = cornish_fisher_z(z, skew_l, exk_l)\n",
    "        phi_zcf = norm_pdf(z_cf)\n",
    "        return float(mu_l + sig_l * (phi_zcf / (1.0 - alpha)))\n",
    "\n",
    "    stats_df = pd.DataFrame(\n",
    "        {\n",
    "            \"mean\": roll_mean,\n",
    "            \"std\": roll_std,\n",
    "            \"skew\": roll_skew,\n",
    "            \"exk\": roll_exkurt,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    var_cf = stats_df.apply(_cf_var, axis=1)\n",
    "    es_cf = stats_df.apply(_cf_es, axis=1)\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"loss\": loss,\n",
    "            \"VaR_normal\": var_normal,\n",
    "            \"ES_normal\": es_normal,\n",
    "            \"VaR_cf\": var_cf,\n",
    "            \"ES_cf\": es_cf,\n",
    "            \"mean_loss\": roll_mean,\n",
    "            \"std_loss\": roll_std,\n",
    "            \"skew_loss\": roll_skew,\n",
    "            \"exk_loss\": roll_exkurt,\n",
    "        }\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------- Pipeline ---------------------------\n",
    "\n",
    "def run_pipeline(cfg: Config):\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "    symbols = list(rets.columns)\n",
    "\n",
    "    w = build_weights(cfg, symbols)\n",
    "    port_ret = portfolio_returns(rets, w)\n",
    "\n",
    "    tail_df = compute_rolling_tail_metrics(port_ret, cfg.window, cfg.alpha)\n",
    "    tail_df[\"ret_port\"] = port_ret.reindex(tail_df.index)\n",
    "    tail_df[\"equity\"] = (1.0 + tail_df[\"ret_port\"].fillna(0.0)).cumprod()\n",
    "\n",
    "    # Simple performance stats\n",
    "    r = tail_df[\"ret_port\"].dropna()\n",
    "    mu = float(r.mean()) if not r.empty else np.nan\n",
    "    sig = float(r.std()) if not r.empty else np.nan\n",
    "    ann_ret = (1.0 + mu) ** 252 - 1.0 if not np.isnan(mu) else np.nan\n",
    "    ann_vol = sig * np.sqrt(252.0) if not np.isnan(sig) else np.nan\n",
    "    sharpe = ann_ret / ann_vol if (not np.isnan(ann_ret) and ann_vol > 0) else np.nan\n",
    "\n",
    "    eq = (1.0 + r).cumprod()\n",
    "    peak = eq.cummax()\n",
    "    dd = eq / peak - 1.0\n",
    "    max_dd = float(dd.min()) if not dd.empty else np.nan\n",
    "\n",
    "    # Aggregated VaR / ES levels\n",
    "    valid_tail = tail_df.dropna(subset=[\"VaR_normal\", \"VaR_cf\"])\n",
    "    if valid_tail.empty:\n",
    "        med_var_norm = med_es_norm = med_var_cf = med_es_cf = np.nan\n",
    "        last_var_norm = last_es_norm = last_var_cf = last_es_cf = np.nan\n",
    "    else:\n",
    "        med_var_norm = float(valid_tail[\"VaR_normal\"].median())\n",
    "        med_es_norm = float(valid_tail[\"ES_normal\"].median())\n",
    "        med_var_cf = float(valid_tail[\"VaR_cf\"].median())\n",
    "        med_es_cf = float(valid_tail[\"ES_cf\"].median())\n",
    "        last_row = valid_tail.iloc[-1]\n",
    "        last_var_norm = float(last_row[\"VaR_normal\"])\n",
    "        last_es_norm = float(last_row[\"ES_normal\"])\n",
    "        last_var_cf = float(last_row[\"VaR_cf\"])\n",
    "        last_es_cf = float(last_row[\"ES_cf\"])\n",
    "\n",
    "    idx = tail_df.index\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"start_date\": str(idx.min().date()) if len(idx) else None,\n",
    "        \"end_date\": str(idx.max().date()) if len(idx) else None,\n",
    "        \"n_days\": int(len(idx)),\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": cfg.symbols,\n",
    "            \"weights\": w.tolist(),\n",
    "        },\n",
    "        \"stats\": {\n",
    "            \"ann_ret\": float(ann_ret) if not np.isnan(ann_ret) else np.nan,\n",
    "            \"ann_vol\": float(ann_vol) if not np.isnan(ann_vol) else np.nan,\n",
    "            \"sharpe\": float(sharpe) if not np.isnan(sharpe) else np.nan,\n",
    "            \"max_dd\": float(max_dd) if not np.isnan(max_dd) else np.nan,\n",
    "        },\n",
    "        \"tail_risk\": {\n",
    "            \"alpha\": cfg.alpha,\n",
    "            \"window\": cfg.window,\n",
    "            \"median_VaR_normal\": med_var_norm,\n",
    "            \"median_ES_normal\": med_es_norm,\n",
    "            \"median_VaR_cf\": med_var_cf,\n",
    "            \"median_ES_cf\": med_es_cf,\n",
    "            \"last_VaR_normal\": last_var_norm,\n",
    "            \"last_ES_normal\": last_es_norm,\n",
    "            \"last_VaR_cf\": last_var_cf,\n",
    "            \"last_ES_cf\": last_es_cf,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return tail_df, summary\n",
    "\n",
    "\n",
    "# --------------------------- I/O ---------------------------\n",
    "\n",
    "def save_outputs(tail_df: pd.DataFrame, summary: dict, cfg: Config) -> None:\n",
    "    tail_df.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary      → {cfg.out_json}\")\n",
    "\n",
    "    if summary[\"start_date\"] and summary[\"end_date\"]:\n",
    "        print(\n",
    "            f\"Period {summary['start_date']} → {summary['end_date']}, \"\n",
    "            f\"n_days={summary['n_days']}\"\n",
    "        )\n",
    "\n",
    "    stats = summary[\"stats\"]\n",
    "    tail = summary[\"tail_risk\"]\n",
    "\n",
    "    print(\n",
    "        \"Portfolio: \"\n",
    "        f\"AnnRet={stats['ann_ret']*100:.2f}%, \"\n",
    "        f\"AnnVol={stats['ann_vol']*100:.2f}%, \"\n",
    "        f\"Sharpe={stats['sharpe']:.2f}, \"\n",
    "        f\"MaxDD={stats['max_dd']*100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Tail risk @ alpha={tail['alpha']:.3f}, window={tail['window']}d:\"\n",
    "        f\"\\n  Normal VaR/ES (median): VaR={tail['median_VaR_normal']*100:.2f}%, \"\n",
    "        f\"ES={tail['median_ES_normal']*100:.2f}%\"\n",
    "        f\"\\n  CF-adjusted VaR/ES (median): VaR={tail['median_VaR_cf']*100:.2f}%, \"\n",
    "        f\"ES={tail['median_ES_cf']*100:.2f}%\"\n",
    "        f\"\\n  Last normal VaR/ES: VaR={tail['last_VaR_normal']*100:.2f}%, \"\n",
    "        f\"ES={tail['last_ES_normal']*100:.2f}%\"\n",
    "        f\"\\n  Last CF VaR/ES: VaR={tail['last_VaR_cf']*100:.2f}%, \"\n",
    "        f\"ES={tail['last_ES_cf']*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------- CLI ---------------------------\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-76: Parametric VaR / CVaR with Cornish–Fisher adjustment\"\n",
    "    )\n",
    "    p.add_argument(\n",
    "        \"--symbols\",\n",
    "        type=str,\n",
    "        default=\"SPY,QQQ,IWM,EFA,EEM,TLT,LQD,GLD\",\n",
    "        help=\"Comma-separated tickers\",\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--weights\", type=str, default=None,\n",
    "                   help=\"Comma-separated weights (same order as symbols). If omitted, equal-weight.\")\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.95,\n",
    "                   help=\"VaR/CVaR confidence level (e.g., 0.95)\")\n",
    "    p.add_argument(\"--window\", type=int, default=252,\n",
    "                   help=\"Rolling window length in days\")\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level76_cornish_var.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level76_cornish_var_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    symbols = tuple(s.strip() for s in a.symbols.split(\",\") if s.strip())\n",
    "\n",
    "    if a.weights is not None:\n",
    "        w_list = [float(x) for x in a.weights.split(\",\") if x.strip() != \"\"]\n",
    "        weights = tuple(w_list)\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "    return Config(\n",
    "        symbols=symbols,\n",
    "        start=a.start,\n",
    "        weights=weights,\n",
    "        alpha=a.alpha,\n",
    "        window=a.window,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------- Main ---------------------------\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    tail_df, summary = run_pipeline(cfg)\n",
    "    save_outputs(tail_df, summary, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / PyCharm shim: strip kernel args\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[OK] Saved daily series → level76_cornish_var.csv\n",
      "[OK] Saved summary      → level76_cornish_var_summary.json\n",
      "Period 2010-01-05 → 2025-12-05, n_days=4006\n",
      "Portfolio: AnnRet=8.43%, AnnVol=11.96%, Sharpe=0.70, MaxDD=-27.96%\n",
      "Tail risk @ alpha=0.950, window=252d:\n",
      "  Normal VaR/ES (median): VaR=1.03%, ES=1.30%\n",
      "  CF-adjusted VaR/ES (median): VaR=1.04%, ES=1.24%\n",
      "  Last normal VaR/ES: VaR=1.27%, ES=1.60%\n",
      "  Last CF VaR/ES: VaR=0.83%, ES=3.44%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
