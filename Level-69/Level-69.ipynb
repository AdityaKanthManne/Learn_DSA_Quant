{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T03:38:51.549209Z",
     "start_time": "2025-12-05T03:38:44.767015Z"
    }
   },
   "source": [
    "# level69_regime_hrp.py\n",
    "# Volatility-Regime Switching HRP vs Static HRP vs Equal-Weight\n",
    "# Universe: SPY, QQQ, IWM, EFA, EEM, TLT, LQD, GLD\n",
    "#\n",
    "# Regimes based on trailing annualized volatility of SPY:\n",
    "#   - vol < vol_low  -> \"low\"  (growth-heavy: 70% growth, 30% defensive)\n",
    "#   - vol > vol_high -> \"high\" (defensive-heavy: 30% growth, 70% defensive)\n",
    "#   - else           -> \"mid\"  (balanced: 50% / 50%)\n",
    "#\n",
    "# Outputs:\n",
    "#   - level69_regime_hrp_portfolio.csv\n",
    "#   - level69_regime_hrp_summary.json\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Sequence, Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# --------------------------- Config ---------------------------\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # Covariance / rebalancing\n",
    "    cov_lookback: int = 252      # trading days for covariance estimation\n",
    "    min_lookback: int = 126      # minimum days before starting\n",
    "    rebalance_freq: str = \"ME\"   # month-end\n",
    "\n",
    "    # Volatility regime settings\n",
    "    vol_anchor: str = \"SPY\"      # which symbol's vol to use for regimes\n",
    "    vol_lookback: int = 60       # days for realized vol\n",
    "    vol_low: float = 0.12        # 12% annualized\n",
    "    vol_high: float = 0.20       # 20% annualized\n",
    "\n",
    "    # Growth vs defensive buckets\n",
    "    growth_symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\")\n",
    "    defensive_symbols: Tuple[str, ...] = (\"TLT\", \"LQD\", \"GLD\")\n",
    "\n",
    "    # Outputs\n",
    "    out_csv: str = \"level69_regime_hrp_portfolio.csv\"\n",
    "    out_json: str = \"level69_regime_hrp_summary.json\"\n",
    "\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# --------------------------- Data Loader ---------------------------\n",
    "\n",
    "def load_prices(symbols: Sequence[str], start: str) -> pd.DataFrame:\n",
    "    \"\"\"Download adjusted close prices for a list of symbols from yfinance.\"\"\"\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No price data downloaded for {s}.\")\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"'Close' column missing for {s}.\")\n",
    "\n",
    "        close = px[\"Close\"].copy()\n",
    "        close.name = s  # avoid rename(func) issues\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"all\")\n",
    "    prices = prices.ffill().dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Log returns of price series.\"\"\"\n",
    "    rets = np.log(prices).diff()\n",
    "    rets = rets.dropna(how=\"all\")\n",
    "    return rets\n",
    "\n",
    "\n",
    "# --------------------------- Portfolio Helpers ---------------------------\n",
    "\n",
    "def equal_weight(symbols: Sequence[str]) -> pd.Series:\n",
    "    n = len(symbols)\n",
    "    w = np.ones(n) / n\n",
    "    return pd.Series(w, index=list(symbols))\n",
    "\n",
    "\n",
    "def cov_to_corr(cov: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert covariance matrix to correlation matrix.\"\"\"\n",
    "    if not isinstance(cov, pd.DataFrame):\n",
    "        cov = pd.DataFrame(cov)\n",
    "    diag = np.diag(cov.values)\n",
    "    diag = np.where(diag <= 0, 1e-12, diag)\n",
    "    std = np.sqrt(diag)\n",
    "    denom = np.outer(std, std)\n",
    "    corr = cov.values / denom\n",
    "    corr[~np.isfinite(corr)] = 0.0\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    return pd.DataFrame(corr, index=cov.index, columns=cov.columns)\n",
    "\n",
    "\n",
    "def correl_to_dist(corr: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Distance matrix from correlation: d_ij = sqrt(0.5 * (1 - rho_ij)).\"\"\"\n",
    "    if not isinstance(corr, pd.DataFrame):\n",
    "        corr = pd.DataFrame(corr)\n",
    "    d = np.sqrt(0.5 * (1.0 - corr.values))\n",
    "    np.fill_diagonal(d, 0.0)\n",
    "    return pd.DataFrame(d, index=corr.index, columns=corr.columns)\n",
    "\n",
    "\n",
    "def single_linkage_order(dist: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"\n",
    "    Naive single-linkage hierarchical clustering to produce a leaf order\n",
    "    (quasi-diagonalization) without external libraries.\n",
    "    \"\"\"\n",
    "    n = dist.shape[0]\n",
    "    D = dist.values.astype(float)\n",
    "    np.fill_diagonal(D, np.inf)\n",
    "\n",
    "    clusters: Dict[int, List[int]] = {i: [i] for i in range(n)}\n",
    "    next_id = n\n",
    "\n",
    "    while len(clusters) > 1:\n",
    "        ids = list(clusters.keys())\n",
    "        best = None\n",
    "        best_pair = None\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i + 1, len(ids)):\n",
    "                ci = ids[i]\n",
    "                cj = ids[j]\n",
    "                members_i = clusters[ci]\n",
    "                members_j = clusters[cj]\n",
    "                sub = D[np.ix_(members_i, members_j)]\n",
    "                d_ij = float(sub.min())\n",
    "                if (best is None) or (d_ij < best):\n",
    "                    best = d_ij\n",
    "                    best_pair = (ci, cj)\n",
    "\n",
    "        if best_pair is None:\n",
    "            break\n",
    "\n",
    "        a, b = best_pair\n",
    "        new_members = clusters[a] + clusters[b]\n",
    "        del clusters[a]\n",
    "        del clusters[b]\n",
    "        clusters[next_id] = new_members\n",
    "        next_id += 1\n",
    "\n",
    "    final_members = list(clusters.values())[0]\n",
    "    return final_members\n",
    "\n",
    "\n",
    "def hrp_weights(cov: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hierarchical Risk Parity weights (Lopez de Prado style), long-only.\n",
    "    \"\"\"\n",
    "    if not isinstance(cov, pd.DataFrame):\n",
    "        cov = pd.DataFrame(cov)\n",
    "    cols = list(cov.columns)\n",
    "    n = len(cols)\n",
    "\n",
    "    corr = cov_to_corr(cov)\n",
    "    dist = correl_to_dist(corr)\n",
    "\n",
    "    order = single_linkage_order(dist)\n",
    "    cov_reordered = cov.values[order][:, order]\n",
    "\n",
    "    diag = np.diag(cov_reordered)\n",
    "    diag = np.where(diag <= 0, 1e-8, diag)\n",
    "    inv_var = 1.0 / diag\n",
    "\n",
    "    weights = np.ones(n)\n",
    "    clusters = [np.arange(n)]\n",
    "\n",
    "    while clusters:\n",
    "        cluster = clusters.pop(0)\n",
    "        if len(cluster) <= 1:\n",
    "            continue\n",
    "\n",
    "        split = len(cluster) // 2\n",
    "        left = cluster[:split]\n",
    "        right = cluster[split:]\n",
    "\n",
    "        inv_var_left = inv_var[left]\n",
    "        inv_var_right = inv_var[right]\n",
    "\n",
    "        w_left = inv_var_left / inv_var_left.sum()\n",
    "        w_right = inv_var_right / inv_var_right.sum()\n",
    "\n",
    "        cov_left = cov_reordered[np.ix_(left, left)]\n",
    "        cov_right = cov_reordered[np.ix_(right, right)]\n",
    "\n",
    "        var_left = float(w_left @ cov_left @ w_left)\n",
    "        var_right = float(w_right @ cov_right @ w_right)\n",
    "        if var_left + var_right == 0:\n",
    "            alpha = 0.5\n",
    "        else:\n",
    "            alpha = 1.0 - var_left / (var_left + var_right)\n",
    "\n",
    "        weights[left] *= alpha\n",
    "        weights[right] *= (1.0 - alpha)\n",
    "\n",
    "        clusters.append(left)\n",
    "        clusters.append(right)\n",
    "\n",
    "    w_final = np.zeros(n)\n",
    "    for pos, asset_idx in enumerate(order):\n",
    "        w_final[asset_idx] = weights[pos]\n",
    "\n",
    "    return pd.Series(w_final, index=cols)\n",
    "\n",
    "\n",
    "# --------------------------- Regime Logic ---------------------------\n",
    "\n",
    "def compute_rebalance_dates(rets: pd.DataFrame, freq: str) -> pd.DatetimeIndex:\n",
    "    \"\"\"Compute rebalance dates (here: month-end using 'ME').\"\"\"\n",
    "    if freq != \"ME\":\n",
    "        raise ValueError(\"This script expects rebalance_freq 'ME' (month-end).\")\n",
    "    return rets.resample(\"ME\").last().index\n",
    "\n",
    "\n",
    "def classify_regime(\n",
    "    anchor_rets: pd.Series,\n",
    "    vol_lookback: int,\n",
    "    vol_low: float,\n",
    "    vol_high: float\n",
    ") -> Tuple[float, str]:\n",
    "    \"\"\"\n",
    "    Compute trailing realized annualized volatility and classify into regime.\n",
    "    Returns (vol_annual, regime_str).\n",
    "    \"\"\"\n",
    "    if anchor_rets.shape[0] < vol_lookback:\n",
    "        return np.nan, \"unknown\"\n",
    "\n",
    "    window = anchor_rets.tail(vol_lookback)\n",
    "    vol_daily = float(window.std())\n",
    "    vol_annual = vol_daily * np.sqrt(252.0)\n",
    "\n",
    "    if vol_annual < vol_low:\n",
    "        regime = \"low\"\n",
    "    elif vol_annual > vol_high:\n",
    "        regime = \"high\"\n",
    "    else:\n",
    "        regime = \"mid\"\n",
    "\n",
    "    return vol_annual, regime\n",
    "\n",
    "\n",
    "def regime_mix(regime: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return (growth_weight, defensive_weight) based on regime.\n",
    "    \"\"\"\n",
    "    if regime == \"low\":\n",
    "        return 0.70, 0.30\n",
    "    elif regime == \"high\":\n",
    "        return 0.30, 0.70\n",
    "    else:  # \"mid\" or unknown\n",
    "        return 0.50, 0.50\n",
    "\n",
    "\n",
    "# --------------------------- Backtest Engine ---------------------------\n",
    "\n",
    "def run_backtest(prices: pd.DataFrame, cfg: Config) -> Tuple[pd.DataFrame, dict]:\n",
    "    rets = compute_returns(prices)\n",
    "\n",
    "    symbols = list(cfg.symbols)\n",
    "    growth = list(cfg.growth_symbols)\n",
    "    defensive = list(cfg.defensive_symbols)\n",
    "\n",
    "    # safety: ensure growth+defensive ⊆ symbols\n",
    "    for s in growth + defensive:\n",
    "        if s not in symbols:\n",
    "            raise ValueError(f\"{s} not in price universe.\")\n",
    "\n",
    "    if cfg.vol_anchor not in symbols:\n",
    "        raise ValueError(f\"vol_anchor {cfg.vol_anchor} not in symbols.\")\n",
    "\n",
    "    rebal_dates = compute_rebalance_dates(rets, cfg.rebalance_freq)\n",
    "    idx = rets.index\n",
    "\n",
    "    # Weight matrices\n",
    "    w_dyn = pd.DataFrame(index=idx, columns=symbols, dtype=float)\n",
    "    w_hrp_static = pd.DataFrame(index=idx, columns=symbols, dtype=float)\n",
    "    w_ew_static = pd.DataFrame(index=idx, columns=symbols, dtype=float)\n",
    "\n",
    "    # To store regime at rebal dates\n",
    "    regime_series = pd.Series(index=idx, dtype=object)\n",
    "    vol_series = pd.Series(index=idx, dtype=float)\n",
    "\n",
    "    for d in rebal_dates:\n",
    "        # trailing windows for covariance and volatility\n",
    "        window_cov = rets.loc[:d].tail(cfg.cov_lookback)\n",
    "        if window_cov.shape[0] < cfg.min_lookback:\n",
    "            continue\n",
    "\n",
    "        cov = window_cov.cov()\n",
    "        if cov.isnull().any().any():\n",
    "            continue\n",
    "\n",
    "        # Static HRP & Equal weight at this date\n",
    "        w_hrp_d = hrp_weights(cov)\n",
    "        w_ew_d = equal_weight(symbols)\n",
    "\n",
    "        # Regime classification on anchor symbol\n",
    "        anchor_rets = rets[cfg.vol_anchor].loc[:d]\n",
    "        vol_ann, regime = classify_regime(\n",
    "            anchor_rets,\n",
    "            cfg.vol_lookback,\n",
    "            cfg.vol_low,\n",
    "            cfg.vol_high,\n",
    "        )\n",
    "\n",
    "        # HRP within growth / defensive buckets\n",
    "        cov_growth = cov.loc[growth, growth]\n",
    "        cov_def = cov.loc[defensive, defensive]\n",
    "\n",
    "        w_growth = hrp_weights(cov_growth)\n",
    "        w_def = hrp_weights(cov_def)\n",
    "\n",
    "        gw, dw = regime_mix(regime)\n",
    "\n",
    "        # Combine into full-universe weight vector\n",
    "        w_dyn_full = pd.Series(0.0, index=symbols)\n",
    "        for s in growth:\n",
    "            w_dyn_full[s] = gw * w_growth[s]\n",
    "        for s in defensive:\n",
    "            w_dyn_full[s] = dw * w_def[s]\n",
    "\n",
    "        # normalize to sum 1 in case of any numerical drift\n",
    "        ssum = float(w_dyn_full.sum())\n",
    "        if ssum <= 0:\n",
    "            w_dyn_full = equal_weight(symbols)\n",
    "        else:\n",
    "            w_dyn_full /= ssum\n",
    "\n",
    "        # assign at rebalance date\n",
    "        w_dyn.loc[d] = w_dyn_full\n",
    "        w_hrp_static.loc[d] = w_hrp_d.reindex(symbols)\n",
    "        w_ew_static.loc[d] = w_ew_d.reindex(symbols)\n",
    "\n",
    "        vol_series.loc[d] = vol_ann\n",
    "        regime_series.loc[d] = regime\n",
    "\n",
    "    # Forward-fill weights and regime to all daily dates\n",
    "    w_dyn = w_dyn.ffill().dropna()\n",
    "    w_hrp_static = w_hrp_static.ffill().dropna()\n",
    "    w_ew_static = w_ew_static.ffill().dropna()\n",
    "\n",
    "    regime_series = regime_series.ffill()\n",
    "    vol_series = vol_series.ffill()\n",
    "\n",
    "    common_idx = w_dyn.index.intersection(w_hrp_static.index).intersection(\n",
    "        w_ew_static.index\n",
    "    )\n",
    "    rets = rets.reindex(common_idx).dropna(how=\"any\")\n",
    "    prices = prices.reindex(common_idx)\n",
    "    w_dyn = w_dyn.reindex(common_idx)\n",
    "    w_hrp_static = w_hrp_static.reindex(common_idx)\n",
    "    w_ew_static = w_ew_static.reindex(common_idx)\n",
    "    regime_series = regime_series.reindex(common_idx)\n",
    "    vol_series = vol_series.reindex(common_idx)\n",
    "\n",
    "    # Portfolio daily returns\n",
    "    ret_dyn = (w_dyn * rets).sum(axis=1).rename(\"ret_dyn\")\n",
    "    ret_hrp = (w_hrp_static * rets).sum(axis=1).rename(\"ret_hrp\")\n",
    "    ret_ew = (w_ew_static * rets).sum(axis=1).rename(\"ret_ew\")\n",
    "\n",
    "    out = pd.DataFrame(index=common_idx)\n",
    "    out[symbols] = prices\n",
    "    out[[f\"ret_{s}\" for s in symbols]] = rets.add_prefix(\"ret_\")\n",
    "\n",
    "    out[[f\"w_dyn_{s}\" for s in symbols]] = w_dyn.add_prefix(\"w_dyn_\")\n",
    "    out[[f\"w_hrp_{s}\" for s in symbols]] = w_hrp_static.add_prefix(\"w_hrp_\")\n",
    "    out[[f\"w_ew_{s}\" for s in symbols]] = w_ew_static.add_prefix(\"w_ew_\")\n",
    "\n",
    "    out[ret_dyn.name] = ret_dyn\n",
    "    out[ret_hrp.name] = ret_hrp\n",
    "    out[ret_ew.name] = ret_ew\n",
    "\n",
    "    out[\"eq_dyn\"] = (1.0 + ret_dyn).cumprod()\n",
    "    out[\"eq_hrp\"] = (1.0 + ret_hrp).cumprod()\n",
    "    out[\"eq_ew\"] = (1.0 + ret_ew).cumprod()\n",
    "\n",
    "    out[\"regime\"] = regime_series\n",
    "    out[\"vol_ann_anchor\"] = vol_series\n",
    "\n",
    "    def stats_from_returns(r: pd.Series) -> dict:\n",
    "        if r.empty:\n",
    "            return dict(ann_ret=np.nan, ann_vol=np.nan,\n",
    "                        sharpe=np.nan, max_dd=np.nan)\n",
    "        daily_ret = r\n",
    "        ann_ret = (1.0 + daily_ret.mean()) ** 252 - 1.0\n",
    "        ann_vol = float(daily_ret.std() * np.sqrt(252))\n",
    "        sharpe = ann_ret / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "        eq = (1.0 + daily_ret).cumprod()\n",
    "        peak = eq.cummax()\n",
    "        dd = eq / peak - 1.0\n",
    "        max_dd = float(dd.min()) if not dd.empty else np.nan\n",
    "\n",
    "        return dict(\n",
    "            ann_ret=float(ann_ret),\n",
    "            ann_vol=float(ann_vol),\n",
    "            sharpe=float(sharpe),\n",
    "            max_dd=float(max_dd),\n",
    "        )\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"start_date\": str(common_idx.min().date()) if len(common_idx) else None,\n",
    "        \"end_date\": str(common_idx.max().date()) if len(common_idx) else None,\n",
    "        \"n_days\": int(len(common_idx)),\n",
    "        \"DynamicRegimeHRP\": stats_from_returns(ret_dyn),\n",
    "        \"StaticHRP\": stats_from_returns(ret_hrp),\n",
    "        \"EqualWeight\": stats_from_returns(ret_ew),\n",
    "    }\n",
    "\n",
    "    return out, summary\n",
    "\n",
    "\n",
    "# --------------------------- I/O ---------------------------\n",
    "\n",
    "def save_outputs(out: pd.DataFrame, summary: dict, cfg: Config) -> None:\n",
    "    out.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    if summary[\"start_date\"] and summary[\"end_date\"]:\n",
    "        print(\n",
    "            f\"Period {summary['start_date']} → {summary['end_date']}, \"\n",
    "            f\"n_days={summary['n_days']}\"\n",
    "        )\n",
    "\n",
    "    for name in [\"DynamicRegimeHRP\", \"StaticHRP\", \"EqualWeight\"]:\n",
    "        s = summary[name]\n",
    "        print(\n",
    "            f\"{name}: AnnRet={s['ann_ret']*100:.2f}%, \"\n",
    "            f\"AnnVol={s['ann_vol']*100:.2f}%, \"\n",
    "            f\"Sharpe={s['sharpe']:.2f}, \"\n",
    "            f\"MaxDD={s['max_dd']*100:.2f}%\"\n",
    "        )\n",
    "\n",
    "\n",
    "# --------------------------- CLI ---------------------------\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-69: Volatility-Regime Switching HRP vs Static HRP vs Equal-Weight\"\n",
    "    )\n",
    "    p.add_argument(\n",
    "        \"--symbols\",\n",
    "        type=str,\n",
    "        default=\"SPY,QQQ,IWM,EFA,EEM,TLT,LQD,GLD\",\n",
    "        help=\"Comma-separated tickers (default: SPY,QQQ,IWM,EFA,EEM,TLT,LQD,GLD)\",\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--cov-lookback\", type=int, default=252)\n",
    "    p.add_argument(\"--min-lookback\", type=int, default=126)\n",
    "    p.add_argument(\n",
    "        \"--rebalance-freq\",\n",
    "        type=str,\n",
    "        default=\"ME\",\n",
    "        help=\"Rebalance frequency (use 'ME' for month-end).\",\n",
    "    )\n",
    "    p.add_argument(\"--vol-anchor\", type=str, default=\"SPY\")\n",
    "    p.add_argument(\"--vol-lookback\", type=int, default=60)\n",
    "    p.add_argument(\"--vol-low\", type=float, default=0.12)\n",
    "    p.add_argument(\"--vol-high\", type=float, default=0.20)\n",
    "    p.add_argument(\n",
    "        \"--growth-symbols\",\n",
    "        type=str,\n",
    "        default=\"SPY,QQQ,IWM,EFA,EEM\",\n",
    "        help=\"Comma-separated growth tickers.\",\n",
    "    )\n",
    "    p.add_argument(\n",
    "        \"--defensive-symbols\",\n",
    "        type=str,\n",
    "        default=\"TLT,LQD,GLD\",\n",
    "        help=\"Comma-separated defensive tickers.\",\n",
    "    )\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level69_regime_hrp_portfolio.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level69_regime_hrp_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    a = p.parse_args()\n",
    "    symbols = tuple(s.strip() for s in a.symbols.split(\",\") if s.strip())\n",
    "    growth = tuple(s.strip() for s in a.growth_symbols.split(\",\") if s.strip())\n",
    "    defensive = tuple(s.strip() for s in a.defensive_symbols.split(\",\") if s.strip())\n",
    "\n",
    "    return Config(\n",
    "        symbols=symbols,\n",
    "        start=a.start,\n",
    "        cov_lookback=a.cov_lookback,\n",
    "        min_lookback=a.min_lookback,\n",
    "        rebalance_freq=a.rebalance_freq,\n",
    "        vol_anchor=a.vol_anchor,\n",
    "        vol_lookback=a.vol_lookback,\n",
    "        vol_low=a.vol_low,\n",
    "        vol_high=a.vol_high,\n",
    "        growth_symbols=growth,\n",
    "        defensive_symbols=defensive,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------- Main ---------------------------\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows.\")\n",
    "\n",
    "    out, summary = run_backtest(prices, cfg)\n",
    "    save_outputs(out, summary, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm shim to ignore kernel-related args like \"-f kernel-xxx.json\"\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4006 price rows.\n",
      "[OK] Saved daily series → level69_regime_hrp_portfolio.csv\n",
      "[OK] Saved summary → level69_regime_hrp_summary.json\n",
      "Period 2010-07-31 → 2025-12-31, n_days=3895\n",
      "DynamicRegimeHRP: AnnRet=6.63%, AnnVol=10.72%, Sharpe=0.62, MaxDD=-28.71%\n",
      "StaticHRP: AnnRet=5.79%, AnnVol=7.93%, Sharpe=0.73, MaxDD=-25.93%\n",
      "EqualWeight: AnnRet=8.64%, AnnVol=11.78%, Sharpe=0.73, MaxDD=-27.96%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
