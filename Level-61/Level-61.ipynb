{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T03:38:37.712224Z",
     "start_time": "2025-12-04T03:38:24.792932Z"
    }
   },
   "source": [
    "# level61_regime_riskparity.py\n",
    "# Level-61: Regime-Aware Volatility-Targeted Risk-Parity Portfolio\n",
    "#\n",
    "# Idea:\n",
    "#   - Multi-asset universe: SPY, QQQ, IWM, EFA, EEM, TLT, LQD, GLD\n",
    "#   - Baseline weights: inverse volatility (poor-man's risk parity)\n",
    "#   - Volatility target at portfolio level (e.g. 10% annualized)\n",
    "#   - Regime filter:\n",
    "#        * Build an \"equity basket\" from risky assets (SPY, QQQ, IWM, EFA, EEM)\n",
    "#        * If equity vol > threshold OR lookback return < threshold -> risk-off\n",
    "#        * In risk-off: shrink risky weights and rotate capital to defensive sleeve (TLT, LQD, GLD)\n",
    "#   - Rebalance on a fixed schedule (e.g. monthly)\n",
    "#\n",
    "# Usage examples:\n",
    "#   python level61_regime_riskparity.py\n",
    "#   python level61_regime_riskparity.py --start 2010-01-01 --vol-target 0.10 --rebalance-freq M\n",
    "#   python level61_regime_riskparity.py --vol-target 0.08 --tc-bps 5\n",
    "#\n",
    "# Outputs:\n",
    "#   - level61_regime_riskparity.csv        (daily prices, returns, weights, portfolio series)\n",
    "#   - level61_regime_riskparity_summary.json  (performance metrics & config)\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "    start: str = \"2010-01-01\"\n",
    "    vol_lookback: int = 60         # days for vol & cov estimation\n",
    "    rebalance_freq: str = \"M\"      # \"M\" (month-end), \"W-FRI\", etc.\n",
    "    vol_target: float = 0.10       # target annualized portfolio volatility\n",
    "    max_leverage: float = 2.0      # cap leverage\n",
    "    risk_off_vol: float = 0.25     # equity basket annual vol threshold\n",
    "    risk_off_mom: float = -0.10    # equity basket lookback return threshold\n",
    "    risk_off_shrink: float = 0.5   # risky sleeve shrink factor in risk-off\n",
    "    tc_bps: float = 10.0           # round-trip transaction cost in bps\n",
    "    out_csv: str = \"level61_regime_riskparity.csv\"\n",
    "    out_json: str = \"level61_regime_riskparity_summary.json\"\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# ----------------------------- Data Loading -----------------------------\n",
    "\n",
    "\n",
    "def load_prices(cfg: Config) -> pd.DataFrame:\n",
    "    tickers = list(cfg.symbols)\n",
    "    px = yf.download(\n",
    "        tickers,\n",
    "        start=cfg.start,\n",
    "        auto_adjust=True,\n",
    "        progress=False,\n",
    "    )\n",
    "    if px.empty:\n",
    "        raise RuntimeError(\"No data downloaded. Check tickers or internet connection.\")\n",
    "\n",
    "    # yfinance with multiple tickers returns a MultiIndex on columns\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        # Prefer \"Close\" when auto_adjust=True (already adjusted)\n",
    "        if \"Close\" not in px.columns.levels[0]:\n",
    "            raise RuntimeError(\"Expected 'Close' in yfinance output.\")\n",
    "        close = px[\"Close\"].copy()\n",
    "    else:\n",
    "        # Single-ticker case, keep as DataFrame with one column\n",
    "        close = px[[\"Close\"]].copy()\n",
    "        close.columns = tickers[:1]\n",
    "\n",
    "    close = close.dropna(how=\"all\")\n",
    "    close = close[tickers]  # ensure column order\n",
    "    return close\n",
    "\n",
    "\n",
    "def compute_returns(close: pd.DataFrame) -> pd.DataFrame:\n",
    "    rets = close.pct_change().dropna()\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- Helpers -----------------------------\n",
    "\n",
    "\n",
    "def annualize_vol(daily_vol: float) -> float:\n",
    "    return float(daily_vol * np.sqrt(252.0))\n",
    "\n",
    "\n",
    "def portfolio_vol(weights: np.ndarray, cov: np.ndarray) -> float:\n",
    "    return float(np.sqrt(weights @ cov @ weights))\n",
    "\n",
    "\n",
    "def inverse_vol_weights(vol_vec: pd.Series) -> pd.Series:\n",
    "    \"\"\"Inverse-volatility weights (normalized).\"\"\"\n",
    "    vol_vec = vol_vec.replace(0.0, np.nan)\n",
    "    inv = 1.0 / vol_vec\n",
    "    inv = inv.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    if inv.sum() <= 0:\n",
    "        # fallback: equal weights\n",
    "        return pd.Series(1.0 / len(inv), index=inv.index)\n",
    "    w = inv / inv.sum()\n",
    "    return w\n",
    "\n",
    "\n",
    "def equity_basket_stats(\n",
    "    hist_rets: pd.DataFrame,\n",
    "    risky_cols: List[str],\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Build an equal-weight equity basket from risky_cols and compute:\n",
    "      - annualized vol\n",
    "      - total return over the lookback window\n",
    "    \"\"\"\n",
    "    cols = [c for c in risky_cols if c in hist_rets.columns]\n",
    "    if len(cols) == 0:\n",
    "        return 0.0, 0.0\n",
    "    basket = hist_rets[cols].mean(axis=1)\n",
    "    if basket.empty:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    vol_ann = annualize_vol(basket.std())\n",
    "    cum_ret = (1.0 + basket).prod() - 1.0\n",
    "    return vol_ann, float(cum_ret)\n",
    "\n",
    "\n",
    "def apply_risk_off_overlay(\n",
    "    w: pd.Series,\n",
    "    risky_cols: List[str],\n",
    "    defensive_cols: List[str],\n",
    "    shrink: float,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    shrink risky weights by 'shrink', reallocate freed capital to defensive sleeve.\n",
    "    \"\"\"\n",
    "    w = w.copy()\n",
    "    risky_cols = [c for c in risky_cols if c in w.index]\n",
    "    defensive_cols = [c for c in defensive_cols if c in w.index]\n",
    "\n",
    "    if len(risky_cols) == 0 or len(defensive_cols) == 0:\n",
    "        return w  # nothing to do\n",
    "\n",
    "    risky_before = float(w[risky_cols].sum())\n",
    "    if risky_before <= 0:\n",
    "        return w\n",
    "\n",
    "    # shrink risky sleeve\n",
    "    w[risky_cols] *= shrink\n",
    "    risky_after = float(w[risky_cols].sum())\n",
    "    freed = risky_before - risky_after\n",
    "\n",
    "    # reallocate freed + existing defensive proportionally within defensive sleeve\n",
    "    def_before = float(w[defensive_cols].sum())\n",
    "    new_def_total = def_before + freed\n",
    "\n",
    "    if new_def_total <= 0:\n",
    "        # if defensive was zero, allocate freed equally\n",
    "        add_each = freed / len(defensive_cols)\n",
    "        for c in defensive_cols:\n",
    "            w[c] += add_each\n",
    "    else:\n",
    "        # scale existing defensive weights\n",
    "        if def_before > 0:\n",
    "            scale = new_def_total / def_before\n",
    "            w[defensive_cols] *= scale\n",
    "        else:\n",
    "            # no initial defensive; spread new_def_total equally\n",
    "            add_each = new_def_total / len(defensive_cols)\n",
    "            for c in defensive_cols:\n",
    "                w[c] = add_each\n",
    "\n",
    "    # numerical cleanup\n",
    "    total = float(w.sum())\n",
    "    if total != 0.0:\n",
    "        w = w / total\n",
    "    return w\n",
    "\n",
    "\n",
    "# ----------------------------- Weight Construction -----------------------------\n",
    "\n",
    "\n",
    "def build_rebalance_schedule(\n",
    "    rets: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Rebalance at the chosen frequency using the returns index.\n",
    "    \"\"\"\n",
    "    if cfg.rebalance_freq.upper().startswith(\"M\"):\n",
    "        # Month end\n",
    "        rebal_dates = rets.resample(\"M\").last().index\n",
    "    else:\n",
    "        # Pass directly to resample (e.g. 'W-FRI')\n",
    "        rebal_dates = rets.resample(cfg.rebalance_freq).last().index\n",
    "    # Ensure rebal dates are within rets index range\n",
    "    rebal_dates = rebal_dates[rebal_dates >= rets.index[0]]\n",
    "    return rebal_dates\n",
    "\n",
    "\n",
    "def compute_weights(\n",
    "    rets: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each rebalance date:\n",
    "      1) Use last vol_lookback days to compute asset vol & cov.\n",
    "      2) Get inverse-vol baseline weights.\n",
    "      3) Compute equity basket stats and decide risk-on / risk-off.\n",
    "      4) In risk-off, shrink risky sleeve and rotate to defensive.\n",
    "      5) Scale to hit vol_target with leverage cap.\n",
    "    \"\"\"\n",
    "    risky_cols = [\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\"]\n",
    "    defensive_cols = [\"TLT\", \"LQD\", \"GLD\"]\n",
    "\n",
    "    rebal_dates = build_rebalance_schedule(rets, cfg)\n",
    "    all_dates = rets.index\n",
    "\n",
    "    weights_list = []\n",
    "\n",
    "    for dt in rebal_dates:\n",
    "        # lookback window: including dt, using previous vol_lookback days\n",
    "        window = rets.loc[:dt].tail(cfg.vol_lookback)\n",
    "        if window.shape[0] < cfg.vol_lookback // 2:\n",
    "            # skip if too little history\n",
    "            continue\n",
    "\n",
    "        # asset vol (daily), then convert to annual\n",
    "        vol_daily = window.std()\n",
    "        vol_ann = vol_daily * np.sqrt(252.0)\n",
    "        w_base = inverse_vol_weights(vol_ann)\n",
    "        w_base = w_base.reindex(rets.columns).fillna(0.0)\n",
    "\n",
    "        # equity basket stats for regime detection\n",
    "        eq_vol_ann, eq_cum_ret = equity_basket_stats(window, risky_cols)\n",
    "        risk_off = (eq_vol_ann > cfg.risk_off_vol) or (eq_cum_ret < cfg.risk_off_mom)\n",
    "\n",
    "        w_adj = w_base.copy()\n",
    "        if risk_off:\n",
    "            w_adj = apply_risk_off_overlay(\n",
    "                w_adj,\n",
    "                risky_cols=risky_cols,\n",
    "                defensive_cols=defensive_cols,\n",
    "                shrink=cfg.risk_off_shrink,\n",
    "            )\n",
    "\n",
    "        # target vol scaling with leverage cap\n",
    "        cov = window.cov() * 252.0  # annualized covariance\n",
    "        w_vec = w_adj.values\n",
    "        try:\n",
    "            port_vol = portfolio_vol(w_vec, cov.values)\n",
    "        except Exception:\n",
    "            port_vol = 0.0\n",
    "\n",
    "        if port_vol > 0:\n",
    "            lev = cfg.vol_target / port_vol\n",
    "        else:\n",
    "            lev = 0.0\n",
    "        lev = float(min(cfg.max_leverage, max(0.0, lev)))\n",
    "\n",
    "        w_final = w_adj * lev\n",
    "\n",
    "        rec = {\n",
    "            \"date\": dt,\n",
    "            \"risk_off\": int(risk_off),\n",
    "            \"eq_vol_ann\": float(eq_vol_ann),\n",
    "            \"eq_cum_ret\": float(eq_cum_ret),\n",
    "        }\n",
    "        for col in rets.columns:\n",
    "            rec[f\"w_{col}\"] = float(w_final.get(col, 0.0))\n",
    "\n",
    "        weights_list.append(rec)\n",
    "\n",
    "    if not weights_list:\n",
    "        raise RuntimeError(\"No rebalance weights computed (check lookback and start date).\")\n",
    "\n",
    "    weights_df = pd.DataFrame(weights_list).set_index(\"date\")\n",
    "    # align to trading calendar: forward-fill weights over daily dates\n",
    "    weights_daily = (\n",
    "        weights_df[[c for c in weights_df.columns if c.startswith(\"w_\")]]\n",
    "        .reindex(all_dates)\n",
    "        .ffill()\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "    meta_daily = (\n",
    "        weights_df[[\"risk_off\", \"eq_vol_ann\", \"eq_cum_ret\"]]\n",
    "        .reindex(all_dates)\n",
    "        .ffill()\n",
    "    )\n",
    "    return weights_daily, meta_daily\n",
    "\n",
    "\n",
    "# ----------------------------- Backtest -----------------------------\n",
    "\n",
    "\n",
    "def backtest(\n",
    "    rets: pd.DataFrame,\n",
    "    weights_daily: pd.DataFrame,\n",
    "    meta_daily: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute daily portfolio returns with and without transaction costs.\n",
    "    Transaction cost model:\n",
    "      - tc_bps is round-trip cost (e.g. 10 bps)\n",
    "      - per rebalance, slippage = 0.5 * tc_bps * turnover\n",
    "      - turnover_t = sum(|w_t - w_{t-1}|), portfolio cost = turnover_t * (tc_bps * 1e-4 / 2)\n",
    "    \"\"\"\n",
    "    # Ensure alignment\n",
    "    common_idx = rets.index.intersection(weights_daily.index)\n",
    "    rets = rets.loc[common_idx]\n",
    "    weights_daily = weights_daily.loc[common_idx]\n",
    "    meta_daily = meta_daily.loc[common_idx]\n",
    "\n",
    "    # Extract pure weights matrix (no \"risk_off\" columns)\n",
    "    w_cols = [c for c in weights_daily.columns if c.startswith(\"w_\")]\n",
    "    asset_cols = [c.replace(\"w_\", \"\") for c in w_cols]\n",
    "\n",
    "    W = weights_daily[w_cols].copy()\n",
    "    W.columns = asset_cols\n",
    "    W = W.reindex(columns=rets.columns).fillna(0.0)\n",
    "\n",
    "    # raw portfolio returns\n",
    "    port_ret = (W * rets).sum(axis=1)\n",
    "\n",
    "    # transaction costs\n",
    "    turnover = W.diff().abs().sum(axis=1).fillna(0.0)\n",
    "    # cost per day\n",
    "    tc_per_unit = cfg.tc_bps * 1e-4 / 2.0\n",
    "    cost = turnover * tc_per_unit\n",
    "\n",
    "    port_ret_tc = port_ret - cost\n",
    "\n",
    "    equity = (1.0 + port_ret).cumprod()\n",
    "    equity_tc = (1.0 + port_ret_tc).cumprod()\n",
    "\n",
    "    out = pd.DataFrame(index=common_idx)\n",
    "    out[\"port_ret\"] = port_ret\n",
    "    out[\"port_ret_tc\"] = port_ret_tc\n",
    "    out[\"equity\"] = equity\n",
    "    out[\"equity_tc\"] = equity_tc\n",
    "    out[\"turnover\"] = turnover\n",
    "    out[\"tc_cost\"] = cost\n",
    "\n",
    "    # bring through meta\n",
    "    out[\"risk_off\"] = meta_daily[\"risk_off\"].reindex(common_idx)\n",
    "    out[\"eq_vol_ann\"] = meta_daily[\"eq_vol_ann\"].reindex(common_idx)\n",
    "    out[\"eq_cum_ret\"] = meta_daily[\"eq_cum_ret\"].reindex(common_idx)\n",
    "\n",
    "    # also include underlying prices and weights if desired\n",
    "    for col in rets.columns:\n",
    "        out[f\"ret_{col}\"] = rets[col]\n",
    "        out[f\"w_{col}\"] = W[col]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------- Metrics -----------------------------\n",
    "\n",
    "\n",
    "def max_drawdown(series: pd.Series) -> float:\n",
    "    running_max = series.cummax()\n",
    "    dd = series / running_max - 1.0\n",
    "    return float(dd.min())\n",
    "\n",
    "\n",
    "def summary_stats(df: pd.DataFrame, cfg: Config) -> dict:\n",
    "    port_ret = df[\"port_ret_tc\"]\n",
    "    if port_ret.empty:\n",
    "        raise RuntimeError(\"No returns to summarize.\")\n",
    "\n",
    "    ann_ret = (1.0 + port_ret).prod() ** (252.0 / len(port_ret)) - 1.0\n",
    "    ann_vol = annualize_vol(port_ret.std())\n",
    "    sharpe = float(ann_ret / ann_vol) if ann_vol > 0 else 0.0\n",
    "\n",
    "    eq_tc = df[\"equity_tc\"]\n",
    "    mdd = max_drawdown(eq_tc)\n",
    "\n",
    "    risk_off_days = int(df[\"risk_off\"].fillna(0).sum())\n",
    "    total_days = len(df)\n",
    "\n",
    "    stats = {\n",
    "        \"start\": str(df.index[0].date()),\n",
    "        \"end\": str(df.index[-1].date()),\n",
    "        \"n_days\": total_days,\n",
    "        \"ann_return\": float(ann_ret),\n",
    "        \"ann_vol\": float(ann_vol),\n",
    "        \"sharpe\": sharpe,\n",
    "        \"max_drawdown\": float(mdd),\n",
    "        \"risk_off_days\": risk_off_days,\n",
    "        \"risk_off_ratio\": float(risk_off_days / total_days),\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "# ----------------------------- I/O -----------------------------\n",
    "\n",
    "\n",
    "def save_outputs(df: pd.DataFrame, stats: dict, cfg: Config) -> None:\n",
    "    df.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"stats\": stats,\n",
    "    }\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "    print(\n",
    "        f\"Period {stats['start']} → {stats['end']}, \"\n",
    "        f\"AnnRet={stats['ann_return']:.2%}, \"\n",
    "        f\"AnnVol={stats['ann_vol']:.2%}, \"\n",
    "        f\"Sharpe={stats['sharpe']:.2f}, \"\n",
    "        f\"MaxDD={stats['max_drawdown']:.2%}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-61: Regime-Aware Risk-Parity Portfolio\")\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--vol-lookback\", type=int, default=60)\n",
    "    p.add_argument(\"--rebalance-freq\", type=str, default=\"M\")\n",
    "    p.add_argument(\"--vol-target\", type=float, default=0.10)\n",
    "    p.add_argument(\"--max-leverage\", type=float, default=2.0)\n",
    "    p.add_argument(\"--risk-off-vol\", type=float, default=0.25)\n",
    "    p.add_argument(\"--risk-off-mom\", type=float, default=-0.10)\n",
    "    p.add_argument(\"--risk-off-shrink\", type=float, default=0.5)\n",
    "    p.add_argument(\"--tc-bps\", type=float, default=10.0)\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level61_regime_riskparity.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level61_regime_riskparity_summary.json\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    args = p.parse_args()\n",
    "\n",
    "    return Config(\n",
    "        start=args.start,\n",
    "        vol_lookback=args.vol_lookback,\n",
    "        rebalance_freq=args.rebalance_freq,\n",
    "        vol_target=args.vol_target,\n",
    "        max_leverage=args.max_leverage,\n",
    "        risk_off_vol=args.risk_off_vol,\n",
    "        risk_off_mom=args.risk_off_mom,\n",
    "        risk_off_shrink=args.risk_off_shrink,\n",
    "        tc_bps=args.tc_bps,\n",
    "        out_csv=args.csv,\n",
    "        out_json=args.json,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- Main -----------------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    cfg = parse_args()\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    close = load_prices(cfg)\n",
    "    rets = compute_returns(close)\n",
    "    print(f\"[INFO] Got {len(close)} price rows, {len(rets)} return rows.\")\n",
    "\n",
    "    weights_daily, meta_daily = compute_weights(rets, cfg)\n",
    "    print(f\"[INFO] Computed weights on {weights_daily.index[0].date()} → {weights_daily.index[-1].date()}\")\n",
    "\n",
    "    out_df = backtest(rets, weights_daily, meta_daily, cfg)\n",
    "    stats = summary_stats(out_df, cfg)\n",
    "    save_outputs(out_df, stats, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / PyCharm shim: strip kernel args like \"-f kernel-xxxx.json\"\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4005 price rows, 4004 return rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_19980\\2445177517.py:198: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rebal_dates = rets.resample(\"M\").last().index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Computed weights on 2010-01-05 → 2025-12-03\n",
      "[OK] Saved daily series → level61_regime_riskparity.csv\n",
      "[OK] Saved summary → level61_regime_riskparity_summary.json\n",
      "Period 2010-01-05 → 2025-12-03, AnnRet=9.46%, AnnVol=13.42%, Sharpe=0.70, MaxDD=-41.18%\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
