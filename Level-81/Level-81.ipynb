{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-19T04:30:08.991583Z",
     "start_time": "2025-12-19T04:29:41.906424Z"
    }
   },
   "source": [
    "# level81_systemic_risk_covar_tcopula.py",
    "# Level-81: Systemic Risk via t-Copula CoVaR / ΔCoVaR (SciPy optional)\n",
    "#\n",
    "# What you get:\n",
    "# 1) Fit a t-copula to multivariate daily log-returns (nu over a grid + corr shrink)\n",
    "# 2) Simulate joint returns from the fitted t-copula + empirical marginals\n",
    "# 3) Compute:\n",
    "#    - Unconditional portfolio VaR/ES\n",
    "#    - Asset VaR (for conditioning)\n",
    "#    - CoVaR: Portfolio VaR(alpha) conditional on asset i being in distress (loss >= VaR_beta)\n",
    "#    - CoVaR-normal: Portfolio VaR(alpha) conditional on asset i being in a \"normal\" state (around median)\n",
    "#    - ΔCoVaR = CoVaR_distress - CoVaR_normal\n",
    "#\n",
    "# Fixes included (same class of issues you hit before):\n",
    "# - No np.trapzoid typo (uses np.trapezoid if available, else np.trapz)\n",
    "# - Robust yfinance Close extraction (handles MultiIndex columns)\n",
    "# - No DataFrame.rename(str) misuse (Series.name = symbol)\n",
    "#\n",
    "# Outputs:\n",
    "#   - level81_covar_panel.csv          (daily prices/returns + portfolio series)\n",
    "#   - level81_covar_summary.json       (fit + VaR/ES + CoVaR tables)\n",
    "#\n",
    "# Run:\n",
    "#   python level81_systemic_risk_covar_tcopula.py\n",
    "#   python level81_systemic_risk_covar_tcopula.py --sims 200000 --alpha 0.99 --beta 0.95\n",
    "#   python level81_systemic_risk_covar_tcopula.py --weights 0.25 0.25 0.2 0.1 0.1 0.05 0.03 0.02\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# ----------------------------- SciPy optional -----------------------------\n",
    "try:\n",
    "    from scipy import stats  # type: ignore\n",
    "    SCIPY_OK = True\n",
    "except Exception:\n",
    "    SCIPY_OK = False\n",
    "\n",
    "\n",
    "# ----------------------------- Config -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    symbols: Tuple[str, ...] = (\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\")\n",
    "    start: str = \"2010-01-01\"\n",
    "\n",
    "    # copula calibration\n",
    "    nu_grid: Tuple[int, ...] = (4, 6, 8, 10, 15, 20)\n",
    "    corr_shrink: float = 0.05\n",
    "\n",
    "    # simulation + risk\n",
    "    sims: int = 100000\n",
    "    seed: int = 42\n",
    "    alpha: float = 0.99   # portfolio VaR/ES confidence\n",
    "    beta: float = 0.95    # distress threshold for asset conditioning (asset loss >= VaR_beta)\n",
    "\n",
    "    # \"normal state\" window around the asset median (filter |u-0.5| <= normal_band)\n",
    "    normal_band: float = 0.05\n",
    "\n",
    "    weights: Optional[List[float]] = None\n",
    "    notional: float = 1_000_000.0\n",
    "\n",
    "    out_csv: str = \"level81_covar_panel.csv\"\n",
    "    out_json: str = \"level81_covar_summary.json\"\n",
    "\n",
    "\n",
    "# ----------------------------- Helpers -----------------------------\n",
    "def trapz_compat(y: np.ndarray, x: np.ndarray) -> float:\n",
    "    if hasattr(np, \"trapezoid\"):\n",
    "        return float(np.trapezoid(y, x))\n",
    "    return float(np.trapz(y, x))\n",
    "\n",
    "\n",
    "def ensure_pos_def_corr(corr: np.ndarray, shrink: float = 0.05) -> np.ndarray:\n",
    "    n = corr.shape[0]\n",
    "    corr = (1.0 - shrink) * corr + shrink * np.eye(n)\n",
    "    corr = 0.5 * (corr + corr.T)\n",
    "\n",
    "    vals, vecs = np.linalg.eigh(corr)\n",
    "    vals = np.clip(vals, 1e-8, None)\n",
    "    corr_pd = vecs @ np.diag(vals) @ vecs.T\n",
    "\n",
    "    d = np.sqrt(np.diag(corr_pd))\n",
    "    corr_pd = corr_pd / np.outer(d, d)\n",
    "    corr_pd = np.clip(corr_pd, -0.9999, 0.9999)\n",
    "    np.fill_diagonal(corr_pd, 1.0)\n",
    "    return corr_pd\n",
    "\n",
    "\n",
    "def rank_to_uniform(x: np.ndarray) -> np.ndarray:\n",
    "    n, k = x.shape\n",
    "    u = np.empty((n, k), dtype=float)\n",
    "    for j in range(k):\n",
    "        order = np.argsort(x[:, j])\n",
    "        ranks = np.empty(n, dtype=float)\n",
    "        ranks[order] = np.arange(1, n + 1, dtype=float)\n",
    "        u[:, j] = ranks / (n + 1.0)\n",
    "    return np.clip(u, 1e-12, 1.0 - 1e-12)\n",
    "\n",
    "\n",
    "# ----------------------------- Robust yfinance loader -----------------------------\n",
    "def _safe_close_series(px: pd.DataFrame, symbol: str) -> pd.Series:\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        for key in [(\"Close\", symbol), (symbol, \"Close\"), (\"Adj Close\", symbol), (symbol, \"Adj Close\")]:\n",
    "            if key in px.columns:\n",
    "                s = px[key].copy()\n",
    "                s.name = symbol\n",
    "                return s\n",
    "        cols = [c for c in px.columns if (symbol in c and (\"Close\" in c or \"Adj Close\" in c))]\n",
    "        if cols:\n",
    "            s = px[cols[0]].copy()\n",
    "            s.name = symbol\n",
    "            return s\n",
    "        raise RuntimeError(f\"Could not locate Close column for {symbol} in MultiIndex columns.\")\n",
    "    if \"Close\" in px.columns:\n",
    "        s = px[\"Close\"].copy()\n",
    "        s.name = symbol\n",
    "        return s\n",
    "    if \"Adj Close\" in px.columns:\n",
    "        s = px[\"Adj Close\"].copy()\n",
    "        s.name = symbol\n",
    "        return s\n",
    "    raise RuntimeError(f\"'Close' column missing for {symbol}. Columns: {list(px.columns)}\")\n",
    "\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px is None or px.empty:\n",
    "            raise RuntimeError(f\"No data returned for symbol: {s}\")\n",
    "        close = _safe_close_series(px, s)\n",
    "        frames.append(close)\n",
    "    prices = pd.concat(frames, axis=1).sort_index().dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    rets = np.log(prices).diff().dropna()\n",
    "    rets = rets.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return rets\n",
    "\n",
    "\n",
    "# ----------------------------- Student-t pieces (SciPy optional) -----------------------------\n",
    "def t_log_pdf_np(x: np.ndarray, nu: float) -> np.ndarray:\n",
    "    a = math.lgamma((nu + 1.0) / 2.0) - math.lgamma(nu / 2.0)\n",
    "    b = -0.5 * math.log(nu * math.pi)\n",
    "    c = -((nu + 1.0) / 2.0) * np.log1p((x * x) / nu)\n",
    "    return a + b + c\n",
    "\n",
    "\n",
    "def t_cdf_scalar_np(x: float, nu: float, n_steps: int = 4001) -> float:\n",
    "    if x == 0.0:\n",
    "        return 0.5\n",
    "    sign = 1.0 if x > 0 else -1.0\n",
    "    ax = abs(x)\n",
    "    xs = np.linspace(0.0, ax, int(n_steps))\n",
    "    f = np.exp(t_log_pdf_np(xs, nu))\n",
    "    area = trapz_compat(f, xs)\n",
    "    cdf = 0.5 + sign * area\n",
    "    return float(np.clip(cdf, 1e-12, 1.0 - 1e-12))\n",
    "\n",
    "\n",
    "def t_ppf_scalar_np(u: float, nu: float) -> float:\n",
    "    u = float(np.clip(u, 1e-12, 1.0 - 1e-12))\n",
    "    if u == 0.5:\n",
    "        return 0.0\n",
    "    if u < 0.5:\n",
    "        return -t_ppf_scalar_np(1.0 - u, nu)\n",
    "\n",
    "    lo, hi = 0.0, 10.0\n",
    "    while t_cdf_scalar_np(hi, nu) < u:\n",
    "        hi *= 2.0\n",
    "        if hi > 200.0:\n",
    "            break\n",
    "\n",
    "    for _ in range(80):\n",
    "        mid = 0.5 * (lo + hi)\n",
    "        cmid = t_cdf_scalar_np(mid, nu)\n",
    "        if cmid < u:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    return 0.5 * (lo + hi)\n",
    "\n",
    "\n",
    "def t_cdf(x: np.ndarray, nu: float) -> np.ndarray:\n",
    "    if SCIPY_OK:\n",
    "        return stats.t.cdf(x, df=nu)  # type: ignore\n",
    "    out = np.empty_like(x, dtype=float)\n",
    "    it = np.nditer(x, flags=[\"multi_index\"])\n",
    "    while not it.finished:\n",
    "        out[it.multi_index] = t_cdf_scalar_np(float(it[0]), nu)\n",
    "        it.iternext()\n",
    "    return out\n",
    "\n",
    "\n",
    "def t_ppf(u: np.ndarray, nu: float) -> np.ndarray:\n",
    "    u = np.clip(u, 1e-12, 1.0 - 1e-12)\n",
    "    if SCIPY_OK:\n",
    "        return stats.t.ppf(u, df=nu)  # type: ignore\n",
    "    out = np.empty_like(u, dtype=float)\n",
    "    it = np.nditer(u, flags=[\"multi_index\"])\n",
    "    while not it.finished:\n",
    "        out[it.multi_index] = t_ppf_scalar_np(float(it[0]), nu)\n",
    "        it.iternext()\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------- Copula calibration -----------------------------\n",
    "def pseudo_log_likelihood_tcopula(U: np.ndarray, corr: np.ndarray, nu: float) -> float:\n",
    "    Z = t_ppf(U, nu)  # T x N\n",
    "    corr = ensure_pos_def_corr(corr, shrink=0.0)\n",
    "    L = np.linalg.cholesky(ensure_pos_def_corr(corr, shrink=0.10))\n",
    "    Y = np.linalg.solve(L, Z.T).T\n",
    "    q = np.sum(Y * Y, axis=1)\n",
    "    n = Z.shape[1]\n",
    "    logdet = 2.0 * np.sum(np.log(np.diag(L)))\n",
    "    mv_part = -0.5 * logdet - ((nu + n) / 2.0) * np.log1p(q / nu)\n",
    "\n",
    "    if SCIPY_OK:\n",
    "        uni_sum = np.sum(stats.t.logpdf(Z, df=nu), axis=1)  # type: ignore\n",
    "    else:\n",
    "        uni_sum = np.sum(t_log_pdf_np(Z, nu), axis=1)\n",
    "\n",
    "    return float(np.sum(mv_part - uni_sum))\n",
    "\n",
    "\n",
    "def calibrate_tcopula(rets: pd.DataFrame, nu_grid: Tuple[int, ...], corr_shrink: float) -> Dict:\n",
    "    X = rets.values\n",
    "    U = rank_to_uniform(X)\n",
    "\n",
    "    best = {\"nu\": None, \"pll\": -np.inf, \"corr\": None}\n",
    "    for nu in nu_grid:\n",
    "        Z = t_ppf(U, float(nu))\n",
    "        corr = np.corrcoef(Z, rowvar=False)\n",
    "        corr = ensure_pos_def_corr(corr, shrink=corr_shrink)\n",
    "        pll = pseudo_log_likelihood_tcopula(U, corr, float(nu))\n",
    "        if pll > best[\"pll\"]:\n",
    "            best = {\"nu\": int(nu), \"pll\": float(pll), \"corr\": corr}\n",
    "    return best\n",
    "\n",
    "\n",
    "# ----------------------------- Simulation -----------------------------\n",
    "def simulate_tcopula_returns(hist_rets: pd.DataFrame, corr: np.ndarray, nu: float, sims: int, seed: int) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = hist_rets.shape[1]\n",
    "    corr = ensure_pos_def_corr(corr, shrink=0.0)\n",
    "    L = np.linalg.cholesky(corr)\n",
    "\n",
    "    hist_sorted = np.sort(hist_rets.values, axis=0)\n",
    "    T = hist_sorted.shape[0]\n",
    "\n",
    "    g = rng.standard_normal(size=(sims, n))\n",
    "    z = g @ L.T\n",
    "\n",
    "    # scale mixture for t\n",
    "    w = rng.gamma(shape=nu / 2.0, scale=2.0, size=(sims, 1))\n",
    "    y = z / np.sqrt(w / nu)\n",
    "\n",
    "    U = t_cdf(y, nu)\n",
    "    idx = np.floor(U * (T - 1)).astype(int)\n",
    "    idx = np.clip(idx, 0, T - 1)\n",
    "\n",
    "    sim = np.empty_like(U, dtype=float)\n",
    "    for j in range(n):\n",
    "        sim[:, j] = hist_sorted[idx[:, j], j]\n",
    "    return sim\n",
    "\n",
    "\n",
    "# ----------------------------- Risk metrics -----------------------------\n",
    "def var_es_from_pnl(pnl: np.ndarray, alpha: float) -> Dict[str, float]:\n",
    "    losses = -pnl\n",
    "    v = float(np.quantile(losses, alpha))\n",
    "    tail = losses[losses >= v]\n",
    "    es = float(np.mean(tail)) if tail.size else v\n",
    "    return {\"VaR\": v, \"ES\": es}\n",
    "\n",
    "\n",
    "def asset_var_from_returns(r: np.ndarray, beta: float) -> float:\n",
    "    # asset loss = -return * notional (per $1), but for conditioning we can use return threshold directly.\n",
    "    # distress event is \"loss >= VaR_beta\" -> return <= q_{1-beta} (left tail)\n",
    "    return float(np.quantile(r, 1.0 - beta))\n",
    "\n",
    "\n",
    "def covar_delta(\n",
    "    sim_rets: np.ndarray,\n",
    "    w: np.ndarray,\n",
    "    notional: float,\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    normal_band: float\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    For each asset i:\n",
    "      distress set: r_i <= q_{1-beta}(r_i)\n",
    "      normal set: |u_i - 0.5| <= normal_band where u_i = rank(u) approx using simulated CDF via ranks\n",
    "    Return per asset: CoVaR_distress, CoES_distress, CoVaR_normal, CoES_normal, DeltaCoVaR, DeltaCoES\n",
    "    \"\"\"\n",
    "    sims, n = sim_rets.shape\n",
    "    pnl_port = notional * (sim_rets @ w)\n",
    "\n",
    "    # compute simulated uniforms (rank-based) per column for \"normal\" conditioning\n",
    "    U_sim = rank_to_uniform(sim_rets)\n",
    "\n",
    "    out = {}\n",
    "    for j in range(n):\n",
    "        rj = sim_rets[:, j]\n",
    "        thr = asset_var_from_returns(rj, beta=beta)\n",
    "\n",
    "        distress_mask = (rj <= thr)\n",
    "        normal_mask = (np.abs(U_sim[:, j] - 0.5) <= normal_band)\n",
    "\n",
    "        # ensure we have some mass\n",
    "        if distress_mask.sum() < 100:\n",
    "            # relax slightly if too few points\n",
    "            distress_mask = (U_sim[:, j] <= (1.0 - beta) * 1.25)\n",
    "\n",
    "        if normal_mask.sum() < 100:\n",
    "            normal_mask = (np.abs(U_sim[:, j] - 0.5) <= max(normal_band, 0.10))\n",
    "\n",
    "        pnl_d = pnl_port[distress_mask]\n",
    "        pnl_n = pnl_port[normal_mask]\n",
    "\n",
    "        rd = var_es_from_pnl(pnl_d, alpha)\n",
    "        rn = var_es_from_pnl(pnl_n, alpha)\n",
    "\n",
    "        out[str(j)] = {\n",
    "            \"distress_prob\": float(distress_mask.mean()),\n",
    "            \"normal_prob\": float(normal_mask.mean()),\n",
    "            \"asset_return_threshold_distress\": float(thr),\n",
    "            \"CoVaR_distress\": float(rd[\"VaR\"]),\n",
    "            \"CoES_distress\": float(rd[\"ES\"]),\n",
    "            \"CoVaR_normal\": float(rn[\"VaR\"]),\n",
    "            \"CoES_normal\": float(rn[\"ES\"]),\n",
    "            \"DeltaCoVaR\": float(rd[\"VaR\"] - rn[\"VaR\"]),\n",
    "            \"DeltaCoES\": float(rd[\"ES\"] - rn[\"ES\"]),\n",
    "        }\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline -----------------------------\n",
    "def run_pipeline(cfg: Config) -> Tuple[pd.DataFrame, Dict]:\n",
    "    print(f\"[INFO] SciPy available: {SCIPY_OK}\")\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_log_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows, assets={rets.shape[1]}\")\n",
    "\n",
    "    n_assets = rets.shape[1]\n",
    "    if cfg.weights is None:\n",
    "        w = np.ones(n_assets, dtype=float) / n_assets\n",
    "    else:\n",
    "        w = np.asarray(cfg.weights, dtype=float)\n",
    "        if w.size != n_assets:\n",
    "            raise ValueError(f\"--weights length must be {n_assets}, got {w.size}\")\n",
    "        s = float(np.sum(w))\n",
    "        if abs(s) < 1e-12:\n",
    "            raise ValueError(\"weights sum to zero\")\n",
    "        w = w / s\n",
    "\n",
    "    print(f\"[INFO] Calibrating t-copula nu over grid: {cfg.nu_grid} ...\")\n",
    "    calib = calibrate_tcopula(rets, cfg.nu_grid, cfg.corr_shrink)\n",
    "    nu_hat = float(calib[\"nu\"])\n",
    "    corr_hat = calib[\"corr\"]\n",
    "    print(f\"[INFO] Best nu={int(nu_hat)} (pseudo-LL={calib['pll']:.2f})\")\n",
    "\n",
    "    print(f\"[INFO] Simulating {cfg.sims} joint scenarios ...\")\n",
    "    sim = simulate_tcopula_returns(rets, corr_hat, nu_hat, cfg.sims, cfg.seed)\n",
    "\n",
    "    # Unconditional portfolio risk\n",
    "    pnl_sim = cfg.notional * (sim @ w)\n",
    "    port_risk = var_es_from_pnl(pnl_sim, cfg.alpha)\n",
    "\n",
    "    # Asset VaR (return threshold)\n",
    "    asset_thr = {}\n",
    "    for j, sym in enumerate(rets.columns):\n",
    "        thr = asset_var_from_returns(sim[:, j], cfg.beta)\n",
    "        asset_thr[sym] = float(thr)\n",
    "\n",
    "    # CoVaR / ΔCoVaR\n",
    "    covar_raw = covar_delta(\n",
    "        sim_rets=sim,\n",
    "        w=w,\n",
    "        notional=cfg.notional,\n",
    "        alpha=cfg.alpha,\n",
    "        beta=cfg.beta,\n",
    "        normal_band=cfg.normal_band,\n",
    "    )\n",
    "\n",
    "    # Map index->symbol for readability\n",
    "    covar_table = {}\n",
    "    for j, sym in enumerate(rets.columns):\n",
    "        covar_table[sym] = covar_raw[str(j)]\n",
    "\n",
    "    # Panel output\n",
    "    cols = list(rets.columns)\n",
    "    panel = pd.DataFrame(index=rets.index)\n",
    "    panel[cols] = prices.reindex(panel.index)\n",
    "    panel[[f\"ret_{c}\" for c in cols]] = rets.add_prefix(\"ret_\")\n",
    "    panel[\"port_ret\"] = rets.values @ w\n",
    "    panel[\"pnl\"] = cfg.notional * panel[\"port_ret\"]\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"scipy_available\": bool(SCIPY_OK),\n",
    "        \"data_window\": {\n",
    "            \"start\": str(rets.index.min().date()),\n",
    "            \"end\": str(rets.index.max().date()),\n",
    "            \"n_returns\": int(len(rets)),\n",
    "        },\n",
    "        \"calibration\": {\n",
    "            \"nu\": int(nu_hat),\n",
    "            \"pseudo_ll\": float(calib[\"pll\"]),\n",
    "            \"corr_shrink\": float(cfg.corr_shrink),\n",
    "        },\n",
    "        \"portfolio\": {\n",
    "            \"symbols\": list(cfg.symbols),\n",
    "            \"weights\": [float(x) for x in w.tolist()],\n",
    "            \"notional\": float(cfg.notional),\n",
    "        },\n",
    "        \"unconditional_portfolio_risk\": {\n",
    "            \"alpha\": float(cfg.alpha),\n",
    "            \"VaR\": float(port_risk[\"VaR\"]),\n",
    "            \"ES\": float(port_risk[\"ES\"]),\n",
    "        },\n",
    "        \"conditioning\": {\n",
    "            \"beta_distress\": float(cfg.beta),\n",
    "            \"normal_band\": float(cfg.normal_band),\n",
    "            \"asset_return_threshold_distress_lefttail\": asset_thr,\n",
    "        },\n",
    "        \"CoVaR_DeltaCoVaR\": covar_table,\n",
    "    }\n",
    "\n",
    "    return panel, summary\n",
    "\n",
    "\n",
    "def save_outputs(panel: pd.DataFrame, summary: Dict, cfg: Config) -> None:\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    panel.to_csv(cfg.out_csv)\n",
    "    with open(cfg.out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Saved panel → {cfg.out_csv}\")\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    pr = summary[\"unconditional_portfolio_risk\"]\n",
    "    print(f\"[RISK] Portfolio alpha={pr['alpha']}: VaR=${pr['VaR']:.2f}, ES=${pr['ES']:.2f}\")\n",
    "\n",
    "    # Print top systemic contributors by ΔCoVaR\n",
    "    rows = []\n",
    "    for sym, d in summary[\"CoVaR_DeltaCoVaR\"].items():\n",
    "        rows.append((sym, d[\"DeltaCoVaR\"], d[\"CoVaR_distress\"], d[\"CoVaR_normal\"], d[\"distress_prob\"]))\n",
    "    rows.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"[CoVaR] Top ΔCoVaR contributors (higher = more systemic impact):\")\n",
    "    for sym, ddc, cd, cn, prob in rows[:8]:\n",
    "        print(f\"  {sym:>4s}  ΔCoVaR=${ddc:>10.2f} | CoVaR(dist)=${cd:>10.2f} | CoVaR(norm)=${cn:>10.2f} | P(dist)={prob:.3f}\")\n",
    "\n",
    "\n",
    "# ----------------------------- CLI -----------------------------\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(description=\"Level-81: t-Copula CoVaR / ΔCoVaR (SciPy optional)\")\n",
    "\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--symbols\", nargs=\"+\", default=list(Config.symbols))\n",
    "\n",
    "    p.add_argument(\"--nu-grid\", nargs=\"+\", type=int, default=list(Config.nu_grid))\n",
    "    p.add_argument(\"--corr-shrink\", type=float, default=0.05)\n",
    "\n",
    "    p.add_argument(\"--sims\", type=int, default=100000)\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.99)\n",
    "    p.add_argument(\"--beta\", type=float, default=0.95)\n",
    "    p.add_argument(\"--normal-band\", type=float, default=0.05)\n",
    "\n",
    "    p.add_argument(\"--weights\", nargs=\"+\", type=float, default=None)\n",
    "    p.add_argument(\"--notional\", type=float, default=1_000_000.0)\n",
    "\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level81_covar_panel.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level81_covar_summary.json\")\n",
    "\n",
    "    a = p.parse_args()\n",
    "    return Config(\n",
    "        symbols=tuple(a.symbols),\n",
    "        start=a.start,\n",
    "        nu_grid=tuple(a.nu_grid),\n",
    "        corr_shrink=float(a.corr_shrink),\n",
    "        sims=int(a.sims),\n",
    "        seed=int(a.seed),\n",
    "        alpha=float(a.alpha),\n",
    "        beta=float(a.beta),\n",
    "        normal_band=float(a.normal_band),\n",
    "        weights=None if a.weights is None else list(float(x) for x in a.weights),\n",
    "        notional=float(a.notional),\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    panel, summary = run_pipeline(cfg)\n",
    "    save_outputs(panel, summary, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter/PyCharm cell shim: strip \"-f kernel.json\" etc.\n",
    "    import sys\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SciPy available: True\n",
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4015 price rows, 4014 return rows, assets=8\n",
      "[INFO] Calibrating t-copula nu over grid: (4, 6, 8, 10, 15, 20) ...\n",
      "[INFO] Best nu=20 (pseudo-LL=40689.60)\n",
      "[INFO] Simulating 100000 joint scenarios ...\n",
      "[OK] Saved panel → level81_covar_panel.csv\n",
      "[OK] Saved summary → level81_covar_summary.json\n",
      "[RISK] Portfolio alpha=0.99: VaR=$19627.60, ES=$26851.91\n",
      "[CoVaR] Top ΔCoVaR contributors (higher = more systemic impact):\n",
      "   SPY  ΔCoVaR=$  37317.56 | CoVaR(dist)=$  44523.61 | CoVaR(norm)=$   7206.05 | P(dist)=0.050\n",
      "   EFA  ΔCoVaR=$  36624.98 | CoVaR(dist)=$  44422.68 | CoVaR(norm)=$   7797.69 | P(dist)=0.050\n",
      "   QQQ  ΔCoVaR=$  35988.41 | CoVaR(dist)=$  44541.28 | CoVaR(norm)=$   8552.87 | P(dist)=0.050\n",
      "   EEM  ΔCoVaR=$  35843.46 | CoVaR(dist)=$  44420.34 | CoVaR(norm)=$   8576.87 | P(dist)=0.050\n",
      "   IWM  ΔCoVaR=$  35727.20 | CoVaR(dist)=$  44527.69 | CoVaR(norm)=$   8800.49 | P(dist)=0.050\n",
      "   LQD  ΔCoVaR=$  13883.85 | CoVaR(dist)=$  31663.55 | CoVaR(norm)=$  17779.70 | P(dist)=0.050\n",
      "   GLD  ΔCoVaR=$  12854.66 | CoVaR(dist)=$  30865.31 | CoVaR(norm)=$  18010.65 | P(dist)=0.050\n",
      "   TLT  ΔCoVaR=$   2386.69 | CoVaR(dist)=$  20484.41 | CoVaR(norm)=$  18097.71 | P(dist)=0.050\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
