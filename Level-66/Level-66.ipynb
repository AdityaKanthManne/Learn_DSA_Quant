{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T02:02:48.676525Z",
     "start_time": "2025-12-05T02:02:43.569075Z"
    }
   },
   "source": [
    "# level66_black_litterman_portfolio.py\n",
    "#\n",
    "# Level-66:\n",
    "# Black–Litterman Tactical ETF Portfolio\n",
    "#  - Prior: equilibrium returns from equal-weight \"market\" portfolio\n",
    "#  - Views: cross-sectional momentum (top/bottom assets)\n",
    "#  - Covariance: Ledoit–Wolf shrinkage\n",
    "#  - Monthly rebalancing, views effective from next trading day\n",
    "#\n",
    "# Usage (examples):\n",
    "#   python level66_black_litterman_portfolio.py\n",
    "#   python level66_black_litterman_portfolio.py --start 2010-01-01 --lookback 252\n",
    "#\n",
    "# Outputs:\n",
    "#   - level66_black_litterman_portfolio.csv\n",
    "#   - level66_black_litterman_summary.json\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "\n",
    "# ----------------------------- Config ----------------------------- #\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Asset universe\n",
    "    symbols: Tuple[str, ...] = (\n",
    "        \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\", \"TLT\", \"LQD\", \"GLD\"\n",
    "    )\n",
    "\n",
    "    # Data / rolling estimation\n",
    "    start: str = \"2010-01-01\"\n",
    "    lookback: int = 252           # trading days for covariance & momentum\n",
    "    rebalance_freq: str = \"ME\"    # 'ME' = month end\n",
    "\n",
    "    # Black–Litterman parameters\n",
    "    risk_aversion: float = 3.0    # δ\n",
    "    tau: float = 0.025            # τ scaling for prior covariance of π\n",
    "    view_strength_ann: float = 0.03  # annualized view adjustment (~3% per year)\n",
    "    view_top_k: int = 2           # # of strongest winners to overweight\n",
    "    view_bottom_k: int = 2        # # of worst losers to underweight\n",
    "    omega_scale: float = 1.0      # scales Ω = diag( diag(P τΣ Pᵀ) * omega_scale )\n",
    "\n",
    "    # Output paths\n",
    "    out_csv: str = \"level66_black_litterman_portfolio.csv\"\n",
    "    out_json: str = \"level66_black_litterman_summary.json\"\n",
    "\n",
    "    # Random seed (for any randomness if added later)\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# ----------------------------- Data Loading ----------------------------- #\n",
    "\n",
    "def load_prices(symbols: Tuple[str, ...], start: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily adjusted close prices for each symbol using yfinance.\n",
    "    Handles both Series and DataFrame returns from yfinance.\n",
    "    \"\"\"\n",
    "    frames: List[pd.Series] = []\n",
    "    for s in symbols:\n",
    "        px = yf.download(s, start=start, auto_adjust=True, progress=False)\n",
    "        if px.empty:\n",
    "            raise RuntimeError(f\"No data returned for symbol {s}. Check ticker or internet.\")\n",
    "        if \"Close\" not in px.columns:\n",
    "            raise RuntimeError(f\"'Close' column missing for {s}.\")\n",
    "\n",
    "        close_obj = px[\"Close\"]\n",
    "        if isinstance(close_obj, pd.Series):\n",
    "            close = close_obj.rename(s)\n",
    "        else:\n",
    "            # If it's a DataFrame (multi-column), take first column\n",
    "            col0 = close_obj.columns[0]\n",
    "            close = pd.Series(close_obj[col0].values, index=close_obj.index, name=s)\n",
    "\n",
    "        frames.append(close)\n",
    "\n",
    "    prices = pd.concat(frames, axis=1).sort_index()\n",
    "    prices = prices.dropna(how=\"any\")\n",
    "    return prices\n",
    "\n",
    "\n",
    "def compute_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Daily log returns.\"\"\"\n",
    "    return np.log(prices).diff().dropna()\n",
    "\n",
    "\n",
    "# ----------------------------- Black–Litterman Core ----------------------------- #\n",
    "\n",
    "def equilibrium_returns(cov: pd.DataFrame, risk_aversion: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Equilibrium (implied) returns:\n",
    "        π = δ Σ w_mkt\n",
    "    Here we approximate market weights as equal-weight.\n",
    "    \"\"\"\n",
    "    n = cov.shape[0]\n",
    "    w_mkt = np.ones(n) / n\n",
    "    pi = risk_aversion * cov.values @ w_mkt\n",
    "    return pi\n",
    "\n",
    "\n",
    "def build_momentum_views(\n",
    "    hist_rets: pd.DataFrame,\n",
    "    cov: pd.DataFrame,\n",
    "    cfg: Config\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Construct Black–Litterman views from cross-sectional momentum.\n",
    "\n",
    "    - Use trailing simple returns over hist_rets for momentum.\n",
    "    - Top view_top_k assets: positive view (raise expected return).\n",
    "    - Bottom view_bottom_k assets: negative view (lower expected return).\n",
    "    - Views are absolute on assets: each view is on one asset's expected return.\n",
    "\n",
    "    Returns:\n",
    "        P: (V x N) view pick matrix\n",
    "        Q: (V,) view expected returns (same units as π, i.e., daily)\n",
    "        Omega: (V x V) diagonal view covariance matrix\n",
    "\n",
    "    If no views (e.g., not enough assets), returns (None, None, None).\n",
    "    \"\"\"\n",
    "    cols = hist_rets.columns.tolist()\n",
    "    n = len(cols)\n",
    "    if n == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    # Trailing simple returns (momentum) over the lookback window\n",
    "    mom = (1.0 + hist_rets).prod(axis=0) - 1.0\n",
    "    mom = mom.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    # Rank assets by momentum\n",
    "    ranked = mom.sort_values(ascending=False)\n",
    "    top_assets = ranked.index[:cfg.view_top_k].tolist()\n",
    "    bottom_assets = ranked.index[-cfg.view_bottom_k:].tolist()\n",
    "\n",
    "    assets_with_views = top_assets + bottom_assets\n",
    "    if len(assets_with_views) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    # Build P and Q\n",
    "    V = len(assets_with_views)\n",
    "    P = np.zeros((V, n))\n",
    "    Q = np.zeros(V)\n",
    "\n",
    "    # Convert annualized view strength to daily (approx.)\n",
    "    view_strength_daily = cfg.view_strength_ann / 252.0\n",
    "\n",
    "    for idx, asset in enumerate(assets_with_views):\n",
    "        j = cols.index(asset)\n",
    "        P[idx, j] = 1.0\n",
    "        if asset in top_assets:\n",
    "            Q[idx] = view_strength_daily  # raise expected return\n",
    "        else:\n",
    "            Q[idx] = -view_strength_daily  # lower expected return\n",
    "\n",
    "    # Build Ω as scaled diag(P τΣ Pᵀ)\n",
    "    tau_cov = cfg.tau * cov.values\n",
    "    # (V x N) @ (N x N) @ (N x V) => (V x V)\n",
    "    view_cov = P @ tau_cov @ P.T\n",
    "    omega_diag = np.diag(view_cov).copy()\n",
    "    # Avoid zero variances\n",
    "    omega_diag = np.where(omega_diag <= 0, 1e-8, omega_diag)\n",
    "    omega_diag *= cfg.omega_scale\n",
    "    Omega = np.diag(omega_diag)\n",
    "\n",
    "    return P, Q, Omega\n",
    "\n",
    "\n",
    "def black_litterman_posterior(\n",
    "    cov: pd.DataFrame,\n",
    "    pi: np.ndarray,\n",
    "    P: np.ndarray,\n",
    "    Q: np.ndarray,\n",
    "    Omega: np.ndarray,\n",
    "    cfg: Config,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute posterior expected returns μ using the Black–Litterman formula:\n",
    "\n",
    "      μ = [(τΣ)^(-1) + Pᵀ Ω^(-1) P]^(-1) [ (τΣ)^(-1) π + Pᵀ Ω^(-1) Q ]\n",
    "    \"\"\"\n",
    "    tau_cov = cfg.tau * cov.values\n",
    "    inv_tau_cov = np.linalg.inv(tau_cov)\n",
    "\n",
    "    if P is None or Q is None or Omega is None:\n",
    "        # No views => posterior equals prior\n",
    "        return pi.copy()\n",
    "\n",
    "    inv_Omega = np.linalg.inv(Omega)\n",
    "\n",
    "    # A = (τΣ)^(-1) + Pᵀ Ω^(-1) P\n",
    "    A = inv_tau_cov + P.T @ inv_Omega @ P\n",
    "    # b = (τΣ)^(-1) π + Pᵀ Ω^(-1) Q\n",
    "    b = inv_tau_cov @ pi + P.T @ inv_Omega @ Q\n",
    "\n",
    "    mu = np.linalg.solve(A, b)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def bl_weights(\n",
    "    cov: pd.DataFrame,\n",
    "    mu: np.ndarray,\n",
    "    cfg: Config,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert posterior expected returns μ and covariance Σ into portfolio\n",
    "    weights via mean-variance formula:\n",
    "\n",
    "      w* ∝ Σ^(-1) μ / δ\n",
    "\n",
    "    Then:\n",
    "      - enforce long-only (clip negatives to 0)\n",
    "      - renormalize to sum to 1\n",
    "    \"\"\"\n",
    "    cols = cov.index.tolist()\n",
    "    Sigma = cov.values\n",
    "    n = Sigma.shape[0]\n",
    "\n",
    "    if n == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    # Mean-variance solution\n",
    "    w_raw = np.linalg.solve(Sigma, mu) / cfg.risk_aversion\n",
    "    w = pd.Series(w_raw, index=cols)\n",
    "\n",
    "    # Long-only, renormalized\n",
    "    w = w.clip(lower=0.0)\n",
    "    s = float(w.sum())\n",
    "    if s <= 0:\n",
    "        w = pd.Series(np.ones(n) / n, index=cols)\n",
    "    else:\n",
    "        w /= s\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "# ----------------------------- Rolling Construction ----------------------------- #\n",
    "\n",
    "def build_bl_weights_rolling(\n",
    "    rets: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute Black–Litterman weights on a rolling basis with monthly rebalancing.\n",
    "\n",
    "    Steps each month-end:\n",
    "      1) Take trailing lookback window of daily returns up to month-end.\n",
    "      2) Estimate Σ via Ledoit–Wolf.\n",
    "      3) Compute equilibrium π = δ Σ w_mkt (equal-weight market).\n",
    "      4) Build momentum-based views (P, Q, Ω).\n",
    "      5) Compute posterior μ via Black–Litterman.\n",
    "      6) Convert μ, Σ into BL weights (long-only).\n",
    "      7) Weights become effective from next trading day after month-end.\n",
    "    \"\"\"\n",
    "    idx = rets.index\n",
    "    cols = rets.columns.tolist()\n",
    "    n = len(cols)\n",
    "\n",
    "    # Month-end dates from returns index\n",
    "    month_ends = rets.resample(cfg.rebalance_freq).last().index\n",
    "\n",
    "    lw = LedoitWolf()\n",
    "\n",
    "    eff_dates: List[pd.Timestamp] = []\n",
    "    eff_weights: List[pd.Series] = []\n",
    "\n",
    "    for me in month_ends:\n",
    "        # Historical returns up to (and including) month-end\n",
    "        hist = rets.loc[:me].tail(cfg.lookback)\n",
    "        if hist.shape[0] < cfg.lookback:\n",
    "            # Not enough history yet\n",
    "            continue\n",
    "\n",
    "        # Ledoit–Wolf covariance\n",
    "        lw.fit(hist.values)\n",
    "        Sigma = pd.DataFrame(lw.covariance_, index=cols, columns=cols)\n",
    "\n",
    "        # Prior equilibrium returns\n",
    "        pi = equilibrium_returns(Sigma, cfg.risk_aversion)\n",
    "\n",
    "        # Build momentum views\n",
    "        P, Q, Omega = build_momentum_views(hist, Sigma, cfg)\n",
    "\n",
    "        # Posterior expected returns\n",
    "        mu = black_litterman_posterior(Sigma, pi, P, Q, Omega, cfg)\n",
    "\n",
    "        # Convert to weights\n",
    "        w_bl = bl_weights(Sigma, mu, cfg)\n",
    "\n",
    "        # Effective from next trading day after month-end\n",
    "        pos = idx.searchsorted(me, side=\"right\")\n",
    "        if pos >= len(idx):\n",
    "            continue\n",
    "        eff_date = idx[pos]\n",
    "\n",
    "        eff_dates.append(eff_date)\n",
    "        eff_weights.append(w_bl)\n",
    "\n",
    "    if not eff_dates:\n",
    "        raise RuntimeError(\"No effective rebalance dates found (likely not enough history).\")\n",
    "\n",
    "    weights_rebal = pd.DataFrame(eff_weights, index=pd.Index(eff_dates, name=\"date\"))\n",
    "    weights_rebal = weights_rebal.sort_index()\n",
    "\n",
    "    # Reindex daily and forward-fill\n",
    "    weights_daily = weights_rebal.reindex(idx).ffill()\n",
    "    weights_daily = weights_daily.reindex(columns=cols)\n",
    "    return weights_daily\n",
    "\n",
    "\n",
    "def compute_turnover(weights: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Daily turnover:\n",
    "      turnover_t = 0.5 * Σ_i |w_{i,t} - w_{i,t-1}|\n",
    "    \"\"\"\n",
    "    W = weights.fillna(0.0)\n",
    "    diff = W.diff().abs()\n",
    "    turnover = 0.5 * diff.sum(axis=1)\n",
    "    return turnover\n",
    "\n",
    "\n",
    "def build_portfolio(\n",
    "    prices: pd.DataFrame,\n",
    "    rets: pd.DataFrame,\n",
    "    cfg: Config,\n",
    ") -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Build BL portfolio series:\n",
    "      - daily portfolio return\n",
    "      - equity curve\n",
    "      - drawdown\n",
    "      - leverage (sum of weights)\n",
    "      - turnover\n",
    "      - weights DataFrame\n",
    "    \"\"\"\n",
    "    weights_daily = build_bl_weights_rolling(rets, cfg)\n",
    "\n",
    "    # Portfolio returns\n",
    "    port_ret = (weights_daily * rets).sum(axis=1)\n",
    "    port_ret.name = \"ret_port\"\n",
    "\n",
    "    # Equity curve\n",
    "    equity = (1.0 + port_ret).cumprod()\n",
    "    equity.name = \"equity\"\n",
    "\n",
    "    # Drawdown\n",
    "    peak = equity.cummax()\n",
    "    drawdown = equity / peak - 1.0\n",
    "    drawdown.name = \"drawdown\"\n",
    "\n",
    "    # Leverage (sum of weights, typically ~1)\n",
    "    leverage = weights_daily.sum(axis=1)\n",
    "    leverage.name = \"leverage\"\n",
    "\n",
    "    # Turnover\n",
    "    turnover = compute_turnover(weights_daily)\n",
    "    turnover.name = \"turnover\"\n",
    "\n",
    "    return {\n",
    "        \"ret_port\": port_ret,\n",
    "        \"equity\": equity,\n",
    "        \"drawdown\": drawdown,\n",
    "        \"leverage\": leverage,\n",
    "        \"turnover\": turnover,\n",
    "        \"weights\": weights_daily,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------- Metrics & I/O ----------------------------- #\n",
    "\n",
    "def summary_stats(rets: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Annualized return, volatility, Sharpe (rf=0).\n",
    "    \"\"\"\n",
    "    r = rets.dropna()\n",
    "    if len(r) == 0:\n",
    "        return {\"ann_ret\": 0.0, \"ann_vol\": 0.0, \"sharpe\": 0.0}\n",
    "\n",
    "    mu_daily = float(r.mean())\n",
    "    vol_daily = float(r.std(ddof=0))\n",
    "\n",
    "    ann_ret = (1.0 + mu_daily) ** 252 - 1.0\n",
    "    ann_vol = vol_daily * math.sqrt(252.0)\n",
    "    sharpe = ann_ret / ann_vol if ann_vol > 0 else 0.0\n",
    "\n",
    "    return {\"ann_ret\": ann_ret, \"ann_vol\": ann_vol, \"sharpe\": sharpe}\n",
    "\n",
    "\n",
    "def save_outputs(\n",
    "    out_df: pd.DataFrame,\n",
    "    stats_all: Dict[str, float],\n",
    "    max_dd: float,\n",
    "    avg_turnover_daily: float,\n",
    "    cfg: Config,\n",
    ") -> None:\n",
    "    os.makedirs(os.path.dirname(cfg.out_csv) or \".\", exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cfg.out_json) or \".\", exist_ok=True)\n",
    "\n",
    "    out_df.to_csv(cfg.out_csv, index=True, date_format=\"%Y-%m-%d\")\n",
    "    print(f\"[OK] Saved daily series → {cfg.out_csv}\")\n",
    "\n",
    "    summary = {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"portfolio\": {\n",
    "            \"ann_ret\": stats_all[\"ann_ret\"],\n",
    "            \"ann_vol\": stats_all[\"ann_vol\"],\n",
    "            \"sharpe\": stats_all[\"sharpe\"],\n",
    "            \"max_drawdown\": max_dd,\n",
    "            \"avg_turnover_daily\": avg_turnover_daily,\n",
    "            \"avg_turnover_annualized\": avg_turnover_daily * 252.0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(cfg.out_json, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[OK] Saved summary → {cfg.out_json}\")\n",
    "\n",
    "    print(\n",
    "        \"BL Portfolio: AnnRet={:.2%}, AnnVol={:.2%}, Sharpe={:.2f}, \"\n",
    "        \"MaxDD={:.2%}, AvgDailyTurnover={:.2%}\".format(\n",
    "            summary[\"portfolio\"][\"ann_ret\"],\n",
    "            summary[\"portfolio\"][\"ann_vol\"],\n",
    "            summary[\"portfolio\"][\"sharpe\"],\n",
    "            summary[\"portfolio\"][\"max_drawdown\"],\n",
    "            summary[\"portfolio\"][\"avg_turnover_daily\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------- Pipeline ----------------------------- #\n",
    "\n",
    "def run_pipeline(cfg: Config) -> None:\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    print(f\"[INFO] Downloading prices for {cfg.symbols} from {cfg.start} ...\")\n",
    "    prices = load_prices(cfg.symbols, cfg.start)\n",
    "    rets = compute_returns(prices)\n",
    "    print(f\"[INFO] Got {len(prices)} price rows, {len(rets)} return rows.\")\n",
    "\n",
    "    port = build_portfolio(prices, rets, cfg)\n",
    "\n",
    "    ret_port = port[\"ret_port\"]\n",
    "    equity = port[\"equity\"]\n",
    "    drawdown = port[\"drawdown\"]\n",
    "    leverage = port[\"leverage\"]\n",
    "    turnover = port[\"turnover\"]\n",
    "    weights = port[\"weights\"]\n",
    "\n",
    "    stats_all = summary_stats(ret_port)\n",
    "    max_dd = float(drawdown.min(skipna=True)) if len(drawdown) else 0.0\n",
    "    avg_turnover_daily = float(turnover.dropna().mean()) if len(turnover.dropna()) else 0.0\n",
    "\n",
    "    # Build output DataFrame aligned to returns index\n",
    "    out_idx = rets.index\n",
    "    out = pd.DataFrame(index=out_idx)\n",
    "\n",
    "    # Prices and returns\n",
    "    # FIX: cast cfg.symbols to list (or use prices.columns) so pandas treats it as multiple columns\n",
    "    out[list(cfg.symbols)] = prices.reindex(out_idx)\n",
    "    out[[f\"ret_{c}\" for c in rets.columns]] = rets.add_prefix(\"ret_\")\n",
    "\n",
    "    # Portfolio series\n",
    "    out[\"ret_port\"] = ret_port\n",
    "    out[\"equity\"] = equity\n",
    "    out[\"drawdown\"] = drawdown\n",
    "    out[\"leverage\"] = leverage\n",
    "    out[\"turnover\"] = turnover\n",
    "\n",
    "    # Weights (prefixed with 'w_')\n",
    "    w_prefixed = weights.add_prefix(\"w_\").reindex(out_idx)\n",
    "    for col in w_prefixed.columns:\n",
    "        out[col] = w_prefixed[col]\n",
    "\n",
    "    save_outputs(out, stats_all, max_dd, avg_turnover_daily, cfg)\n",
    "\n",
    "\n",
    "# ----------------------------- CLI ----------------------------- #\n",
    "\n",
    "def parse_args() -> Config:\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Level-66: Black–Litterman Tactical ETF Portfolio (Momentum Views + Shrinkage Covariance)\"\n",
    "    )\n",
    "    p.add_argument(\"--start\", type=str, default=\"2010-01-01\")\n",
    "    p.add_argument(\"--lookback\", type=int, default=252)\n",
    "    p.add_argument(\"--csv\", type=str, default=\"level66_black_litterman_portfolio.csv\")\n",
    "    p.add_argument(\"--json\", type=str, default=\"level66_black_litterman_summary.json\")\n",
    "    p.add_argument(\"--risk-aversion\", type=float, default=3.0)\n",
    "    p.add_argument(\"--tau\", type=float, default=0.025)\n",
    "    p.add_argument(\"--view-strength-ann\", type=float, default=0.03)\n",
    "    p.add_argument(\"--view-top-k\", type=int, default=2)\n",
    "    p.add_argument(\"--view-bottom-k\", type=int, default=2)\n",
    "    p.add_argument(\"--omega-scale\", type=float, default=1.0)\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    a = p.parse_args()\n",
    "\n",
    "    return Config(\n",
    "        start=a.start,\n",
    "        lookback=a.lookback,\n",
    "        out_csv=a.csv,\n",
    "        out_json=a.json,\n",
    "        risk_aversion=a.risk_aversion,\n",
    "        tau=a.tau,\n",
    "        view_strength_ann=a.view_strength_ann,\n",
    "        view_top_k=a.view_top_k,\n",
    "        view_bottom_k=a.view_bottom_k,\n",
    "        omega_scale=a.omega_scale,\n",
    "        seed=a.seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = parse_args()\n",
    "    run_pipeline(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Jupyter / IPython shim to strip kernel args like \"-f kernel-xxxx.json\"\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [sys.argv[0]] + [\n",
    "        arg\n",
    "        for arg in sys.argv[1:]\n",
    "        if arg != \"-f\" and not (arg.endswith(\".json\") and \"kernel\" in arg)\n",
    "    ]\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading prices for ('SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'LQD', 'GLD') from 2010-01-01 ...\n",
      "[INFO] Got 4006 price rows, 4005 return rows.\n",
      "[OK] Saved daily series → level66_black_litterman_portfolio.csv\n",
      "[OK] Saved summary → level66_black_litterman_summary.json\n",
      "BL Portfolio: AnnRet=8.89%, AnnVol=10.80%, Sharpe=0.82, MaxDD=-25.45%, AvgDailyTurnover=0.76%\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
